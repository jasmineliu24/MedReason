{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.azure import (\n",
    "    create_azure_batch_data,\n",
    "    prepare_azure_batch_data,\n",
    "    merge_azure_batch_data,\n",
    "    parse_azure_batch_result,\n",
    "    process_azure_result_to_task_result,\n",
    "    cost_calculation_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 52 files in dataset_raw\n"
     ]
    }
   ],
   "source": [
    "path_dir = \"dataset_raw\"\n",
    "list_path_file = os.listdir(path_dir)\n",
    "list_task_name = [file.split(\"/\")[-1].replace(\".SFT.json\", \"\") for file in list_path_file if file.endswith(\".SFT.json\")]\n",
    "dict_task_path = {task_name: os.path.join(path_dir, path_file) for task_name, path_file in zip(list_task_name, list_path_file)}\n",
    "dict_task_path = dict(sorted(dict_task_path.items(), key=lambda x: int(x[0].split(\".\")[0] if \"-\" not in x[0].split(\".\")[0] else x[0].split(\"-\")[0])))\n",
    "print(f\"Searching {len(dict_task_path)} files in {path_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-3.ADE-Drug dosage': 'dataset_raw/1-3.ADE-Drug dosage.SFT.json',\n",
       " '1-2.ADE-ADE relation': 'dataset_raw/1-2.ADE-ADE relation.SFT.json',\n",
       " '1-1.ADE-ADE identification': 'dataset_raw/1-1.ADE-ADE identification.SFT.json',\n",
       " '5.BrainMRI-AIS': 'dataset_raw/29.EHRQA.sub_department.SFT.json',\n",
       " '6.Brateca.mortality': 'dataset_raw/6.Brateca.mortality.SFT.json',\n",
       " '6.Brateca.hospitalization': 'dataset_raw/6.Brateca.hospitalization.SFT.json',\n",
       " '7.Cantemist.NER': 'dataset_raw/102.iCorpus.SFT.json',\n",
       " '7.Cantemist.CODING': 'dataset_raw/100.GraSSCo_PHI.SFT.json',\n",
       " '7.Cantemist.Norm': 'dataset_raw/7.Cantemist.NER.SFT.json',\n",
       " '8.CARES.icd10_chapter': 'dataset_raw/8.CARES.icd10_chapter.SFT.json',\n",
       " '8.CARES.icd10_block': 'dataset_raw/29.EHRQA.primary_department.SFT.json',\n",
       " '8.CARES.area': 'dataset_raw/8.CARES.icd10_block.SFT.json',\n",
       " '8.CARES.icd10_sub_block': 'dataset_raw/23.cMedQA.SFT.json',\n",
       " '9.CHIP-CDEE': 'dataset_raw/9.CHIP-CDEE.SFT.json',\n",
       " '12.C-EMRS': 'dataset_raw/107.MIMIC-IV BHC.SFT.json',\n",
       " '19.ClinicalNotes-UPMC': 'dataset_raw/108.MIMIC-IV DiReCT.Dis.SFT.json',\n",
       " '22.CLIP': 'dataset_raw/19.ClinicalNotes-UPMC.SFT.json',\n",
       " '23.cMedQA': 'dataset_raw/5.BrainMRI-AIS.SFT.json',\n",
       " '26.DialMed': 'dataset_raw/12.C-EMRS.SFT.json',\n",
       " '28.MIE': 'dataset_raw/22.CLIP.SFT.json',\n",
       " '29.EHRQA.qa': 'dataset_raw/26.DialMed.SFT.json',\n",
       " '29.EHRQA.sub_department': 'dataset_raw/28.MIE.SFT.json',\n",
       " '29.EHRQA.primary_department': 'dataset_raw/29.EHRQA.qa.SFT.json',\n",
       " '31.Ex4CDS': 'dataset_raw/31.Ex4CDS.SFT.json',\n",
       " '33.GOUT-CC.consensus': 'dataset_raw/33.GOUT-CC.consensus.SFT.json',\n",
       " '43.IMCS-V2-NER': 'dataset_raw/43.IMCS-V2-NER.SFT.json',\n",
       " '81.CHIP-CDN': 'dataset_raw/81.CHIP-CDN.SFT.json',\n",
       " '82.CHIP-CTC': 'dataset_raw/82.CHIP-CTC.SFT.json',\n",
       " '83.CHIP-MDCFNPC': 'dataset_raw/83.CHIP-MDCFNPC.SFT.json',\n",
       " '84.MedDG': 'dataset_raw/84.MedDG.SFT.json',\n",
       " '85.IMCS-V2-SR': 'dataset_raw/85.IMCS-V2-SR.SFT.json',\n",
       " '86.IMCS-V2-MRG': 'dataset_raw/86.IMCS-V2-MRG.SFT.json',\n",
       " '87.IMCS-V2-DAC': 'dataset_raw/87.IMCS-V2-DAC.SFT.json',\n",
       " '91-1.CAS.label': 'dataset_raw/91-1.CAS.label.SFT.json',\n",
       " '91-2.CAS.evidence': 'dataset_raw/91-2.CAS.evidence.SFT.json',\n",
       " '96.RuCCoN.NER': 'dataset_raw/96.RuCCoN.NER.SFT.json',\n",
       " '97.CLISTER': 'dataset_raw/97.CLISTER.SFT.json',\n",
       " '98.BRONCO150.NER_status': 'dataset_raw/7.Cantemist.CODING.SFT.json',\n",
       " '99.CARDIO:DE': 'dataset_raw/99.CARDIO:DE.SFT.json',\n",
       " '100.GraSSCo_PHI': 'dataset_raw/excluded',\n",
       " '101.IFMIR.IncidentType': 'dataset_raw/101.IFMIR.IncidentType.SFT.json',\n",
       " '101.IFMIR.NER_factuality': 'dataset_raw/101.IFMIR.NER_factuality.SFT.json',\n",
       " '101.IFMIR.NER': 'dataset_raw/101.IFMIR.NER.SFT.json',\n",
       " '102.iCorpus': 'dataset_raw/example',\n",
       " '103.icliniq-10k': 'dataset_raw/103.icliniq-10k.SFT.json',\n",
       " '104.HealthCareMagic-100k': 'dataset_raw/104.HealthCareMagic-100k.SFT.json',\n",
       " '105.MIMIC-IV CDM': 'dataset_raw/106.MIMIC-III Outcome.LoS.SFT.json',\n",
       " '106.MIMIC-III Outcome.LoS': 'dataset_raw/7.Cantemist.Norm.SFT.json',\n",
       " '106.MIMIC-III Outcome.Mortality': 'dataset_raw/98.BRONCO150.NER_status.SFT.json',\n",
       " '107.MIMIC-IV BHC': 'dataset_raw/108.MIMIC-IV DiReCT.PDD.SFT.json',\n",
       " '108.MIMIC-IV DiReCT.PDD': 'dataset_raw/106.MIMIC-III Outcome.Mortality.SFT.json',\n",
       " '108.MIMIC-IV DiReCT.Dis': 'dataset_raw/105.MIMIC-IV CDM.SFT.json'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_task_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "task_name = \"1-1.ADE-ADE identification\"\n",
    "prompt_mode = 'direct-5-shot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dict_task_path[task_name], \"r\") as file:\n",
    "    list_dict_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Prepare 5 examples\n"
     ]
    }
   ],
   "source": [
    "if \"shot\" in prompt_mode:\n",
    "    num_example = int(regex.findall(r\"\\d+\", prompt_mode)[0])\n",
    "    path_file_example = f\"dataset_raw/example/{task_name}.example.json\"\n",
    "    with open(path_file_example, \"r\", encoding=\"utf-8\") as f:\n",
    "        list_dict_example = json.load(f)\n",
    "    examples = list_dict_example[:num_example]\n",
    "    print(f\" - Prepare {num_example} examples\")\n",
    "else:\n",
    "    examples = []\n",
    "    print(\" - No example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 13307\n",
      " - Max token output: 3072\n"
     ]
    }
   ],
   "source": [
    "list_dict_data_batch = prepare_azure_batch_data(\n",
    "    task_name=task_name,\n",
    "    model_name=model_name,\n",
    "    prompt_mode=prompt_mode,\n",
    "    split=['test'],\n",
    "    list_dict_data=list_dict_data,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': \"1-1.ADE-ADE identification|gpt-35-turbo-batch|direct-5-shot|['test']|0\",\n",
       " 'method': 'POST',\n",
       " 'url': '/chat/completions',\n",
       " 'body': {'model': 'gpt-35-turbo-batch',\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Given the clinical text, determine whether the text mentions adverse drug effects.\\nReturn your answer in the following format. DO NOT GIVE ANY EXPLANATION:\\nadverse drug effect: label\\nThe optional list for \"label\" is [\"Yes\", \"No\"].\\n\\nExamples:\\nInput:\\nSevere sulfadiazine hypersensitivity in a child with reactivated congenital toxoplasmic chorioretinitis.\\nOutput:\\nadverse drug effect: Yes\\n\\nInput:\\nMarked hyperkalemia was observed during and immediately after an infusion of arginine monohydrochloride in two patients with severe hepatic disease and moderate renal insufficiency.\\nOutput:\\nadverse drug effect: Yes\\n\\nInput:\\nMany new serotonergic antidepressants have been introduced over the past decade.\\nOutput:\\nadverse drug effect: No\\n\\nInput:\\nUntreated tumors displayed continued growth.\\nOutput:\\nadverse drug effect: No\\n\\nInput:\\nIncreasing the olanzapine dosage severely aggravated the symptoms of RLS.\\nOutput:\\nadverse drug effect: Yes\\n\\nRefer to the provided examples, please generate the output for the following input.\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Input:\\nBecause of the difficulty of case collection, understanding of the association of MAHA and anal squamous cell carcinoma remains vague.'}],\n",
       "  'temperature': 0,\n",
       "  'top_p': 0,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'max_tokens': 3072,\n",
       "  'seed': 42}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_data_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Given the clinical text, determine whether the text mentions adverse drug effects.\\nReturn your answer in the following format. DO NOT GIVE ANY EXPLANATION:\\nadverse drug effect: label\\nThe optional list for \"label\" is [\"Yes\", \"No\"].\\n\\nExamples:\\nInput:\\nSevere sulfadiazine hypersensitivity in a child with reactivated congenital toxoplasmic chorioretinitis.\\nOutput:\\nadverse drug effect: Yes\\n\\nInput:\\nMarked hyperkalemia was observed during and immediately after an infusion of arginine monohydrochloride in two patients with severe hepatic disease and moderate renal insufficiency.\\nOutput:\\nadverse drug effect: Yes\\n\\nInput:\\nMany new serotonergic antidepressants have been introduced over the past decade.\\nOutput:\\nadverse drug effect: No\\n\\nInput:\\nUntreated tumors displayed continued growth.\\nOutput:\\nadverse drug effect: No\\n\\nInput:\\nIncreasing the olanzapine dosage severely aggravated the symptoms of RLS.\\nOutput:\\nadverse drug effect: Yes\\n\\nRefer to the provided examples, please generate the output for the following input.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'Input:\\nBecause of the difficulty of case collection, understanding of the association of MAHA and anal squamous cell carcinoma remains vague.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_data_batch[0]['body']['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the clinical text, determine whether the text mentions adverse drug effects.\n",
      "Return your answer in the following format. DO NOT GIVE ANY EXPLANATION:\n",
      "adverse drug effect: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      "\n",
      "Examples:\n",
      "Input:\n",
      "Severe sulfadiazine hypersensitivity in a child with reactivated congenital toxoplasmic chorioretinitis.\n",
      "Output:\n",
      "adverse drug effect: Yes\n",
      "\n",
      "Input:\n",
      "Marked hyperkalemia was observed during and immediately after an infusion of arginine monohydrochloride in two patients with severe hepatic disease and moderate renal insufficiency.\n",
      "Output:\n",
      "adverse drug effect: Yes\n",
      "\n",
      "Input:\n",
      "Many new serotonergic antidepressants have been introduced over the past decade.\n",
      "Output:\n",
      "adverse drug effect: No\n",
      "\n",
      "Input:\n",
      "Untreated tumors displayed continued growth.\n",
      "Output:\n",
      "adverse drug effect: No\n",
      "\n",
      "Input:\n",
      "Increasing the olanzapine dosage severely aggravated the symptoms of RLS.\n",
      "Output:\n",
      "adverse drug effect: Yes\n",
      "\n",
      "Refer to the provided examples, please generate the output for the following input.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list_dict_data_batch[0]['body']['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "ANAMNESIS\n",
      "Mujer de 67 años con antecedentes personales de hipotiroidismo en tratamiento con levotiroxina y fumadora activa de 12.5 paquetes/año. Consulta en Urgencias por sensación progresiva de “acorchamiento y hormigueos” en ambos miembros superiores e inferiores, así como una dificultad progresiva para la deambulación de 4 meses de evolución, asociando asimismo alteración de la memoria reciente desde el último mes\n",
      "\n",
      "EXPLORACIÓN FÍSICA\n",
      "Presentaba una exploración cardiopulmonar y abdominal normal. En la exploración neurológica destaca balance motor por grupos musculares conservado; arreflexia rotuliana y aquilea e hiporreflexia bicipital; tetrahipoestesia asimétrica (táctil, algésica, vibratoria y posicional) en patrón de “guante y calcetín altos” de predominio izquierdo; Romberg positivo y marcha con leve aumento de base de sustentación que impresiona ataxia sensitiva.\n",
      "\n",
      "PRUEBAS COMPLEMENTARIAS\n",
      "En las exploraciones complementarias, hemograma, bioquímica y coagulación no presentaban alteraciones. El análisis de virus hepatitis B y C, VIH, las serologías de enfermedad de Lyme y Treponema pallidum fueron negativas. El estudio lipídico, de\n",
      "vitaminas, proteinograma y anticuerpos antinucleares fueron normales. Se objetivó positividad para los anticuerpos onconeuronales anfifisina, anti-Hu y anti-SOX-1.\n",
      "\n",
      "Se realizó una punción lumbar. El estudio bacteriológico, de micobacterias, de Herpes virus 1 y 2, Ebstein Barr, Citomegalovirus y Varicela-Zoster fue negativo.\n",
      "\n",
      "El estudio de electroneurografía-electromiografía (ENG-EMG) demostró ausencia de potenciales sensitivos en miembros inferiores y algunos nervios de miembros superiores; siendo las respuestas presentes de amplitud muy reducida, con marcado alargamiento de latencias y disminución severa de la velocidad de conducción. Estudio de conductividad motora y electromiográfico sin hallazgos patológicos, hallazgos compatibles con polineuropatía sensitiva severa de características mixtas.\n",
      "\n",
      "En la tomografía axial computerizada (TAC) cerebral no se apreciaron alteraciones significativas. En la TAC toraco-abdomino-pélvica se observaron una adenopatía parahiliar derecha de 2.5 cm y una adenopatía subcarinal de características patológicas.\n",
      "\n",
      "En el PET-TAC se observaron depósitos patológicos que coincidían con los hallazgos del TAC.\n",
      "\n",
      "Se realizó una ecobroncoscopia lineal con toma de biopsia de adenopatía subcarinal.\n",
      "\n",
      "La resonancia mágnetica (RM) cervico-dorso-lumbar mostró pequeñas hernias discales dorsales y lumbares sin afectación del canal medular ni de la cola de caballo.\n",
      "La RM cerebral mostró en T2 hiperintensidad en ambos lóbulos temporales alcanzando hipocampo y corteza siendo sugestivo de encefalitis límbica.\n",
      "\n",
      "ANATOMÍA PATOLÓGICA\n",
      "Carcinoma microcítico de pulmón. Inmunohistoquímica: positivo para TTF1, cromogranina y sinaptofisina, negativo para CK7, CK20 y p40.\n",
      "\n",
      "JUICIO DIAGNÓSTICO\n",
      "Encefalitis límbica y polineuropatía sensitiva paraneoplásicas secundarias a carcinoma microcítico de pulmón cTxN2 M0 (enfermedad limitada).\n",
      "\n",
      "TRATAMIENTO Y EVOLUCIÓN\n",
      "Ante el juicio diagnóstico, y con la colaboración del Servicio de Neurología, se inició tratamiento sintomático secuencial con gammaglobulina (0.4 mg/kg/día) y corticoides (metilprednisolona 1 g/día) intravenosos durante 5 días respectivamente, con escasa mejoría de la clínica. Debido a las molestias ocasionadas por las parestesias se inició tratamiento oral con pregabalina a dosis de 50-0-75 mg.\n",
      "\n",
      "Se decidió comenzar con tratamiento con cisplatino-etopósido más radioterapia concomitante (59.4 Gy en 30 sesiones) a partir del segundo ciclo. Se completó un total de cinco ciclos observándose una respuesta parcial radiológica por criterios RECIST (Response Evaluation Criteria In Solid Tumors).\n",
      "\n",
      "Tres meses después de la finalización del tratamiento con quimioterapia la paciente refiere empeoramiento progresivo de la clínica polineuropática, presentando también episodios súbitos de fuertes reacciones de miedo, llanto y ansiedad, congruentes con crisis epilépticas focales límbicas, por lo que se decide administrar nueva tanda de gammaglobulinas iv (0,4 mg/kg/día) e iniciar tratamiento antiepiléptico con levetirazetam 500 mg cada 12h y lacosamida 100 mg cada 12h, consiguiendo mejoría sintomática cognitiva y control de las crisis. Posteriormente ante mayor progresión de la clínica polineuropática se decide tratamiento de 2ª línea con rituximab iv (1000 mg separados entre sí 14 días), manteniéndose clínicamente estable.\n",
      "\n",
      "Después de nueve meses libre de progresión, se objetiva en el TAC de control un aumento de tejido de partes blandas perihiliar derecho y un nódulo de 7 mm en lóbulo inferior derecho no presente en el TAC previo, hipermetabólico en el PET-TC. Por lo tanto, ante una progresión de enfermedad se decide reiniciar quimioterapia con carboplatinoetopósido al ser una paciente platino sensible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list_dict_data_batch[0]['body']['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2097 to azure/input/gpt-35-turbo-batch/direct/1-1.ADE-ADE identification.batch.jsonl\n"
     ]
    }
   ],
   "source": [
    "list_dict_data_batch = create_azure_batch_data(\n",
    "    task_name=task_name,\n",
    "    model_name=model_name,\n",
    "    prompt_mode=prompt_mode,\n",
    "    split=\"test\",\n",
    "    temperature=0,\n",
    "    top_p=0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    max_token_input=100 * 1024,\n",
    "    max_token_output=3072,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': '1-1.ADE-ADE identification|gpt-35-turbo-batch|direct|test|18869',\n",
       " 'method': 'POST',\n",
       " 'url': '/chat/completions',\n",
       " 'body': {'model': 'gpt-35-turbo-batch',\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Given the clinical text, determine whether the text mentions adverse drug effects.\\nReturn your answer in the following format. DO NOT GIVE ANY EXPLANATION:\\nadverse drug effect: label\\nThe optional list for \"label\" is [\"Yes\", \"No\"].'},\n",
       "   {'role': 'user',\n",
       "    'content': 'We present a patient who developed spontaneous pulmonary hemorrhage during thrombolytic therapy.'}],\n",
       "  'temperature': 0,\n",
       "  'top_p': 0,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'max_tokens': 3072,\n",
       "  'seed': 42}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_data_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification, with 2097 testing samples\n",
      " - Loading tokenizer of gpt-35-turbo\n"
     ]
    }
   ],
   "source": [
    "split = \"test\"\n",
    "path_file_task = f\"dataset_fine/all/{task_name}.SFT.json\"\n",
    "with open(path_file_task, \"r\") as f:\n",
    "    list_dict_data = json.load(f)\n",
    "list_dict_data = [ dict_data for dict_data in list_dict_data if dict_data[\"split\"] == split ]\n",
    "print(f\"Task: {task_name}, with {len(list_dict_data)} testing samples\")\n",
    "exp_name = f\"{task_name}|{model_name}|{prompt_mode}|{split}\"\n",
    "list_dict_data_batch = prepare_azure_batch_data(\n",
    "    task_name= task_name,\n",
    "    model_name=model_name,\n",
    "    prompt_mode=prompt_mode,\n",
    "    split=split,\n",
    "    list_dict_data=list_dict_data,\n",
    "    examples=[],\n",
    "    temperature=0,\n",
    "    top_p=0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    max_token_input=100 * 1024,\n",
    "    max_token_output=3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': '1-1.ADE-ADE identification|gpt-35-turbo-batch|direct|test|18869',\n",
       " 'method': 'POST',\n",
       " 'url': '/chat/completions',\n",
       " 'body': {'model': 'gpt-35-turbo-batch',\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Given the clinical text, determine whether the text mentions adverse drug effects.\\nReturn your answer in the following format. DO NOT GIVE ANY EXPLANATION:\\nadverse drug effect: label\\nThe optional list for \"label\" is [\"Yes\", \"No\"].'},\n",
       "   {'role': 'user',\n",
       "    'content': 'We present a patient who developed spontaneous pulmonary hemorrhage during thrombolytic therapy.'}],\n",
       "  'temperature': 0,\n",
       "  'top_p': 0,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'max_tokens': 3072,\n",
       "  'seed': 42}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_data_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcess all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 49 files in dataset_raw\n"
     ]
    }
   ],
   "source": [
    "path_dir = \"dataset_raw\"\n",
    "list_path_file = os.listdir(path_dir)\n",
    "list_task_name = [file.split(\"/\")[-1].replace(\".SFT.json\", \"\") for file in list_path_file if file.endswith(\".SFT.json\")]\n",
    "dict_task_path = {task_name: os.path.join(path_dir, path_file) for task_name, path_file in zip(list_task_name, list_path_file)}\n",
    "dict_task_path = dict(sorted(dict_task_path.items(), key=lambda x: int(x[0].split(\".\")[0] if \"-\" not in x[0].split(\".\")[0] else x[0].split(\"-\")[0])))\n",
    "print(f\"Searching {len(dict_task_path)} files in {path_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batch data jsonl for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_task(dict_task_path, model_name, prompt_mode, split=\"test\"):\n",
    "    for task_name, path_file_task in dict_task_path.items():\n",
    "        list_dict_data_batch = create_azure_batch_data(\n",
    "            task_name=task_name,\n",
    "            model_name=model_name,\n",
    "            prompt_mode=prompt_mode,\n",
    "            split=split,\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            max_token_input=100 * 1024,\n",
    "            max_token_output=2*1024,\n",
    "        )\n",
    "        print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 2097 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 428 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 193 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 303 to azure/input/gpt-35-turbo-batch/direct-5-shot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 384 to azure/input/gpt-35-turbo-batch/direct-5-shot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 1911 to azure/input/gpt-35-turbo-batch/direct-5-shot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 238 to azure/input/gpt-35-turbo-batch/direct-5-shot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 1771 to azure/input/gpt-35-turbo-batch/direct-5-shot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 6184 to azure/input/gpt-35-turbo-batch/direct-5-shot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 1199 to azure/input/gpt-35-turbo-batch/direct-5-shot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 2235 to azure/input/gpt-35-turbo-batch/direct-5-shot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 411 to azure/input/gpt-35-turbo-batch/direct-5-shot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 441 to azure/input/gpt-35-turbo-batch/direct-5-shot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 843 to azure/input/gpt-35-turbo-batch/direct-5-shot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 2374 to azure/input/gpt-35-turbo-batch/direct-5-shot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 2000 to azure/input/gpt-35-turbo-batch/direct-5-shot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 6146 to azure/input/gpt-35-turbo-batch/direct-5-shot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 11785 to azure/input/gpt-35-turbo-batch/direct-5-shot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 2747 to azure/input/gpt-35-turbo-batch/direct-5-shot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct-5-shot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct-5-shot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 22059 to azure/input/gpt-35-turbo-batch/direct-5-shot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct-5-shot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct-5-shot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 866 to azure/input/gpt-35-turbo-batch/direct-5-shot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 854 to azure/input/gpt-35-turbo-batch/direct-5-shot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 400 to azure/input/gpt-35-turbo-batch/direct-5-shot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct-5-shot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct-5-shot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 329 to azure/input/gpt-35-turbo-batch/direct-5-shot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5834 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 220 to azure/input/gpt-35-turbo-batch/direct-5-shot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 733 to azure/input/gpt-35-turbo-batch/direct-5-shot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 16384\n",
      " - Max token output: 3072\n",
      " - Save 11217 to azure/input/gpt-35-turbo-batch/direct-5-shot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 2097 to azure/input/gpt-4o-batch/direct-5-shot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 428 to azure/input/gpt-4o-batch/direct-5-shot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 193 to azure/input/gpt-4o-batch/direct-5-shot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 303 to azure/input/gpt-4o-batch/direct-5-shot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 3170 to azure/input/gpt-4o-batch/direct-5-shot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 3183 to azure/input/gpt-4o-batch/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 384 to azure/input/gpt-4o-batch/direct-5-shot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 1911 to azure/input/gpt-4o-batch/direct-5-shot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 238 to azure/input/gpt-4o-batch/direct-5-shot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 1771 to azure/input/gpt-4o-batch/direct-5-shot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 6184 to azure/input/gpt-4o-batch/direct-5-shot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 1199 to azure/input/gpt-4o-batch/direct-5-shot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 2235 to azure/input/gpt-4o-batch/direct-5-shot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 411 to azure/input/gpt-4o-batch/direct-5-shot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 441 to azure/input/gpt-4o-batch/direct-5-shot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 843 to azure/input/gpt-4o-batch/direct-5-shot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 2374 to azure/input/gpt-4o-batch/direct-5-shot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 2000 to azure/input/gpt-4o-batch/direct-5-shot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 6146 to azure/input/gpt-4o-batch/direct-5-shot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 11785 to azure/input/gpt-4o-batch/direct-5-shot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 2747 to azure/input/gpt-4o-batch/direct-5-shot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct-5-shot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct-5-shot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 22059 to azure/input/gpt-4o-batch/direct-5-shot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct-5-shot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct-5-shot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 866 to azure/input/gpt-4o-batch/direct-5-shot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 854 to azure/input/gpt-4o-batch/direct-5-shot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 400 to azure/input/gpt-4o-batch/direct-5-shot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct-5-shot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct-5-shot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 380 to azure/input/gpt-4o-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 329 to azure/input/gpt-4o-batch/direct-5-shot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5834 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 220 to azure/input/gpt-4o-batch/direct-5-shot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 733 to azure/input/gpt-4o-batch/direct-5-shot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 3072\n",
      " - Save 11217 to azure/input/gpt-4o-batch/direct-5-shot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2097 to azure/input/gpt-35-turbo-batch/direct/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 428 to azure/input/gpt-35-turbo-batch/direct/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 193 to azure/input/gpt-35-turbo-batch/direct/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 303 to azure/input/gpt-35-turbo-batch/direct/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/direct/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/direct/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 384 to azure/input/gpt-35-turbo-batch/direct/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1911 to azure/input/gpt-35-turbo-batch/direct/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 238 to azure/input/gpt-35-turbo-batch/direct/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1771 to azure/input/gpt-35-turbo-batch/direct/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6184 to azure/input/gpt-35-turbo-batch/direct/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1199 to azure/input/gpt-35-turbo-batch/direct/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2235 to azure/input/gpt-35-turbo-batch/direct/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 411 to azure/input/gpt-35-turbo-batch/direct/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 441 to azure/input/gpt-35-turbo-batch/direct/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 843 to azure/input/gpt-35-turbo-batch/direct/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2374 to azure/input/gpt-35-turbo-batch/direct/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2000 to azure/input/gpt-35-turbo-batch/direct/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6146 to azure/input/gpt-35-turbo-batch/direct/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11785 to azure/input/gpt-35-turbo-batch/direct/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2747 to azure/input/gpt-35-turbo-batch/direct/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 22059 to azure/input/gpt-35-turbo-batch/direct/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 866 to azure/input/gpt-35-turbo-batch/direct/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 854 to azure/input/gpt-35-turbo-batch/direct/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 400 to azure/input/gpt-35-turbo-batch/direct/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/direct/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 329 to azure/input/gpt-35-turbo-batch/direct/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5834 to azure/input/gpt-35-turbo-batch/direct/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 220 to azure/input/gpt-35-turbo-batch/direct/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 733 to azure/input/gpt-35-turbo-batch/direct/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11217 to azure/input/gpt-35-turbo-batch/direct/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, determine whether the text mentions adverse drug effects.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "adverse drug effect: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2097 to azure/input/gpt-35-turbo-batch/cot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, identify all the drugs and their corresponding adverse effect mentioned in the text.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "drug: ..., adverse effect: ...;\n",
      "...\n",
      "drug: ..., adverse effect: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 428 to azure/input/gpt-35-turbo-batch/cot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, identify all the drugs and their corresponding dosage information mentioned in the text.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "drug: ..., dosage: ...;\n",
      "...\n",
      "drug: ..., dosage: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 193 to azure/input/gpt-35-turbo-batch/cot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a brain Magnetic Resonance Imaging (MRI) radiology report, determine whether the patient has acute ischemic stroke (AIS).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "AIS: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 303 to azure/input/gpt-35-turbo-batch/cot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the clinical outcome for this patient is survival or death. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Survival: status\n",
      "The optional list for \"status\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/cot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the patient will require more than seven days of hospitalization.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Hospitalization > 7 days: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/cot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text related to cancer in Spanish, extract all entities about tumor morphology mentioned in the text. \n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: tumor morphology;\n",
      "...\n",
      "entity: ..., type: tumor morphology;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/cot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical document in Spanish, identify the entities of tumor morphology and determine the corresponding morphology codes. Specifically, the entities of tumor morphology can be linked to an morphology codes from CIE-O (Clasificación Internacional de Enfermedades para Oncología, i.e., the Spanish equivalent of ICD-O, version 3.1).\n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "- \"Morphology code\": The morphology code is a code from CIE-O that represents the morphology of the tumor. This code is used to classify the tumor morphology in a standardized way. A code consists of a four-digit morphology code indicating the tumor's histological type, followed by a slash and a single digit indicating the tumor's behavior.\n",
      "Assuming the number of normalized morphology codes is N, return the N normalized codes in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Morphology code: code 1, code 2, ..., code N\n",
      "The optional list for \"code\" is the normalized code from CIE-O.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/cot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text related to cancer in Spanish, extract all entities about tumor morphology and identify its corresponding morphology codes. Specifically, every entity of tumor morphology is linked to an morphology codes from CIE-O (Clasificación Internacional de Enfermedades para Oncología, i.e., the Spanish equivalent of ICD-O, version 3.1).\n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "- \"Morphology code\": The morphology code is a code from CIE-O that represents the morphology of the tumor. This code is used to classify the tumor morphology in a standardized way. A code consists of a four-digit morphology code indicating the tumor's histological type, followed by a slash and a single digit indicating the tumor's behavior.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., code: ...;\n",
      "...\n",
      "entity: ..., code: ...;\n",
      "The optional list for \"code\" is the normalized code from CIE-O.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/cot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine which anatomical area of the body the report refers to. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "anatomical area: label\n",
      "The optional list for \"label\" is ['Columna', 'Neuro', 'Musculoskeletal', 'Body'].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/cot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate blocks of the ICD-10 corresponding to the conditions mentioned in the report. Specifically, the block is the second level of the ICD-10 classification and represents a group of related diseases. Each block is identified by a code containing a character and two digits, which indicates its chapter and detailed block.\n",
      "This report may contain multiple conditions and is related to multiple blocks. Assuming the number of appropriate blocks is N, return the codes of N appropriate blocks in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 block: code 1, code 2, ..., code N\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/cot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate chapters of ICD-10 corresponding to the conditions mentioned in the report. Specifically, the chapter is the highest level of the ICD-10 classification and each chapter represents a group of related diseases. Each chapter is identified by a Roman numeral from I to XXII, including the following chapters:\n",
      "- \"I\": Certain infectious and parasitic diseases (A00–B99)\n",
      "- \"II\": Neoplasms (C00–D49)\n",
      "- \"III\": Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism (D50–D89)\n",
      "- \"IV\": Endocrine, nutritional, and metabolic diseases (E00–E89)\n",
      "- \"V\": Mental, Behavioral and Neurodevelopmental disorders (F01–F99)\n",
      "- \"VI\": Diseases of the nervous system (G00–G99)\n",
      "- \"VII\": Diseases of the eye and adnexa (H00–H59)\n",
      "- \"VIII\": Diseases of the ear and mastoid process (H60–H95)\n",
      "- \"IX\": Diseases of the circulatory system (I00–I99)\n",
      "- \"X\": Diseases of the respiratory system (J00–J99)\n",
      "- \"XI\": Diseases of the digestive system (K00–K95)\n",
      "- \"XII\": Diseases of the skin and subcutaneous tissue (L00–L99)\n",
      "- \"XIII\": Diseases of the musculoskeletal system and connective tissue (M00–M99)\n",
      "- \"XIV\": Diseases of the genitourinary system (N00–N99)\n",
      "- \"XV\": Pregnancy, childbirth, and the puerperium (O00–O9A)\n",
      "- \"XVI\": Certain conditions originating in the perinatal period (P00–P96)\n",
      "- \"XVII\": Congenital malformations, deformations, and chromosomal abnormalities (Q00–Q99)\n",
      "- \"XVIII\": Symptoms, signs, and abnormal clinical and laboratory findings, not elsewhere classified (R00–R99)\n",
      "- \"XIX\": Injury, poisoning, and certain other consequences of external causes (S00–T88)\n",
      "- \"XX\": External causes of morbidity (V00–Y99)\n",
      "- \"XXI\": Factors influencing health status and contact with health services (Z00–Z99)\n",
      "- \"XXII\": Codes for special purposes (U00–U85)\n",
      "This report may contain multiple conditions and is related to multiple chapters. Assuming the number of appropriate chapters is N, return the codes of N appropriate chapters in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 chapter: code 1, code 2, ..., code N\n",
      "The optional list for \"code\" is [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\", \"X\", \"XI\", \"XII\", \"XIII\", \"XIV\", \"XV\", \"XVI\", \"XVII\", \"XVIII\", \"XIX\", \"XX\", \"XXI\", \"XXII\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/cot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate sub-blocks of the ICD-10 corresponding to the conditions mentioned in the report. Specifically, the sub-block is the third level of the ICD-10 classification and represents a group of related diseases. Each sub-block is identified by a code containing a character and two digits, which indicates its chapter, block, and detailed sub-block.\n",
      "This report may contain multiple conditions and is related to multiple sub-blocks. Assuming the number of appropriate sub-blocks is N, return the codes of N appropriate sub-blocks in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 sub-block: code 1, code_2, ..., code N\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/cot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text from electronic healthcare records in Chinese, extract all the clinical findings and their attributes. 具体而言，给定一段现病史或者医学影像所见报告，要求从中抽取临床发现事件的四个属性: 解剖部位、主体词、描述词，以及发生状态:\n",
      "1. 主体词(subject)：指患者的电子病历中的疾病名称或者由疾病引发的症状，也包括患者的一般情况如饮食，二便，睡眠等。主体词尽可能完整并是专有名词，比如“麻木， 疼痛，发烧，囊肿”等；专有名词，如“头晕”，晕只能发生在头部，“胸闷”，闷只能发生在胸部，所以不进行拆分，保留完整的专有名词。涉及泛化的症状不做标注，如“无其他不适”，句子中的“不适”不需要标注，只针对具体的进行标注。注意：有较小比例的主体词会映射到ICD标准术语，所使用的ICD的版本为“国际疾病分类 ICD-10北京临床版v601.xIsx”\n",
      "2. 描述词(description)：对主体词的发生时序特征、轻重程度、形态颜色等多个维度的刻画，也包括疾病的起病缓急、突发\n",
      "3. 解剖部位(location)：指主体词发生在患者的身体部位，也包括组织，细胞，系统等，也包括部位的方向和数量\n",
      "4. 发生状态(status)：“肯定”，“否定”或“不确定”，表示该主体词在患者的电子病历中的存在状态\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "subject: ..., description: [..., ...], location: [..., ...], status: ...;\n",
      "...\n",
      "subject: ..., description: [..., ...], location: [..., ...], status: ...;\n",
      "The optional list for \"status\" is [\"肯定\", \"否定\", \"不确定\"]; If there is not a description or location, they should be \"[]\"; if there are multiple descriptions or locations, they should be separated by commas in the list, like [..., ...].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 384 to azure/input/gpt-35-turbo-batch/cot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a clinical electronic health record in Chinese, diagnose the disease this patient has.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "diagnosis: disease\n",
      "The optional list for \"disease\" is [\"胃息肉\", \"泌尿道感染\", \"慢性阻塞性肺病\", \"痛风\", \"胃溃疡\", \"高血压\", \"哮喘\", \"胃炎\", \"心律失常\", \"糖尿病\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1911 to azure/input/gpt-35-turbo-batch/cot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a sentence from clinical notes, determine whether the provided concept is Affirmed or Negated. Specifically, if the concept is mentioned in the sentence and it is negated, then the label is \"No\". If the concept is mentioned in the sentence and it is affirmed, then the label is \"Yes\". \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "affirmed: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 238 to azure/input/gpt-35-turbo-batch/cot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the discharge summary of a patient, identify the clinical action items for physicians from hospital discharge notes. Specifically, the clinical action items include the following types:\n",
      "- \"Patient Instructions\": Post-discharge instructions that are directed to the patient, so the PCP (primary care provider) can ensure the patient understands and performs them, such as: 'No driving until post-op visit and you are no longer taking pain medications.'\n",
      "- \"Appointment\": Appointments to be made by the PCPs, or monitored to ensure the patient attends them, such as: 'The patient requires a neurology consult at XYZ for evaluation.'\n",
      "- \"Medications\": Medications that the PCP either needs to ensure that the patient is taking correctly (e.g., time-limited medications) or new medications that may need dose adjustment, such as: 'The patient was instructed to hold ASA and refrain from NSAIDs for 2 weeks.'\n",
      "- \"Lab\": Laboratory tests that either have results pending or need to be ordered by the PCP, such as: 'We ask that the patients’ family physician repeat these tests in 2 weeks to ensure  resolution.'\n",
      "- \"Procedure\": Procedures that the PCP needs to either order, ensure another caregiver orders, or ensure the patient undergoes, such as: 'Please follow-up for EGD with GI.'\n",
      "- \"Imaging\": Imaging studies that either have results pending or need to be ordered by the PCP, such as: 'Superior segment of the left lower lobe: rounded density which could have been related to infection, but follow-up for resolution recommended to exclude possible malignancy.'\n",
      "- \"Other\": Other actionable information that is important to relay to the PCP but does not fall under existing aspects (e.g., the need to closely observe the patient’s diet, or fax results to another provider), such as: 'Since the patient has been struggling to gain weight this past year, we will monitor his nutritional status and  trend weights closely.'\n",
      "Assuming the number of action items is N, return the N recognized action items in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "action items: item 1, item 2, ..., item N\n",
      "The optional list for \"item\" is [\"Patient Instructions\", \"Appointment\", \"Medications\", \"Lab\", \"Procedure\", \"Imaging\", \"Other\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1771 to azure/input/gpt-35-turbo-batch/cot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the anser from a doctor's perspective in Chinese.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6184 to azure/input/gpt-35-turbo-batch/cot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, where the recommended medications from the doctor are masked as \"[MASK]\", predict those recommended medications. Note that the number of medications is equal to the number of \"[MASK]\", assumed to be N. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "medication: label 1, label 2, ..., label N\n",
      "The optional list for \"label\" is: [\"酮康唑\", \"板蓝根\", \"右美沙芬\", \"莫沙必利\", \"风寒感冒颗粒\", \"双黄连口服液\", \"蒲地蓝消炎口服液\", \"水飞蓟素\", \"米诺环素\", \"氯雷他定\", \"布地奈德\", \"苏黄止咳胶囊\", \"胶体果胶铋\", \"哈西奈德\", \"谷胱甘肽\", \"二硫化硒\", \"泰诺\", \"硫磺皂\", \"对乙酰氨基酚\", \"奥司他韦\", \"甘草酸苷\", \"红霉素\", \"西替利嗪\", \"克拉霉素\", \"氢化可的松\", \"复方甲氧那明胶囊\", \"三九胃泰\", \"替诺福韦\", \"健胃消食片\", \"炉甘石洗剂\", \"蒙脱石\", \"曲美布汀\", \"阿奇霉素\", \"扶正化瘀胶囊\", \"依巴斯汀\", \"感冒灵\", \"他克莫司\", \"氨溴索\", \"康复新液\", \"多烯磷脂酰胆碱\", \"恩替卡韦\", \"桉柠蒎肠溶软胶囊\", \"曲安奈德\", \"甘草片\", \"左氧氟沙星\", \"奥美拉唑\", \"铝镁化合物\", \"复方消化酶\", \"头孢类\", \"甲氧氯普胺\", \"地塞米松\", \"美沙拉秦\", \"双环醇\", \"肠炎宁\", \"抗病毒颗粒\", \"阿莫西林\", \"川贝枇杷露\", \"谷氨酰胺\", \"山莨菪碱\", \"阿达帕林\", \"孟鲁司特\", \"糠酸莫米松\", \"快克\", \"布洛芬\", \"益生菌\", \"通窍鼻炎颗粒\", \"阿昔洛韦\", \"生理氯化钠溶液\", \"连花清瘟胶囊\", \"黄连素\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1199 to azure/input/gpt-35-turbo-batch/cot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, extract the following types of medical entities:\n",
      "1. \"symptom\": This type of entity refers to the symptoms mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"symptom\" is [\"行动不便\", \"战栗抽搐\", \"心慌\", \"背痛\", \"头晕\", \"呃逆\", \"腹部不适\", \"高血压\", \"高血糖\", \"呼吸困难\", \"胸闷\", \"高血脂\", \"恶心\", \"呕吐\", \"胸痛\", \"乏力\", \"出汗\", \"发热\", \"休克\", \"晕厥\", \"感冒\",\"咳嗽\", \"流涕\", \"头痛\", \"胃部不适\", \"僵硬\", \"发绀\", \"糖尿病\", \"贫血\", \"水肿\", \"心绞痛\", \"甲亢\", \"早搏\", \"心律不齐\", \"房间隔缺损\", \"房颤\", \"心衰\", \"心肌梗死\", \"先天性心脏病\", \"心肌缺血\", \"室间隔缺损\", \"心肌炎\", \"冠心病\", \"心肌病\", \"心脏肥大\"].\n",
      "- The optional list of \"status\" for \"symptom\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the symptom appeared in the patient, the symptom was not presented in the patient, the symptom was diagnosed by the doctor, the symptom was excluded by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "2. \"surgery\": This type of entity refers to the surgery operations mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"surgery\" is [\"介入\", \"射频消融\", \"搭桥\", \"支架\"].\n",
      "- The optional list of \"status\" for \"surgery\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the surgery was done on the patient, the surgery was not done on the patient, the surgery was recommended by the doctor, the surgery was deprecated by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "3. \"examination\": This type of entity refers to the medical tests mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"examination\" is [\"心电图\", \"彩超\", \"心肌酶\", \"体检\", \"造影\", \"超声\", \"ct\", \"血常规\", \"甲状腺功能\", \"胸片\", \"b超\", \"肾功能\", \"平板\", \"cta\", \"测血压\", \"核磁共振\"].\n",
      "- The optional list of \"status\" for \"examination\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the examination was done on the patient, the examination was not done on the patient, the examination was recommended by the doctor, the examination was deprecated by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "4. \"general information\": This type of entity refers to some general information that is relevant to the patient:\n",
      "- The optional list of \"entity\" for \"general information\" is [\"睡眠\", \"饮食\", \"精神状态\", \"大小便\", \"吸烟\", \"饮酒\"].\n",
      "- The optional list of \"status\" for \"general information\" is [\"病人-阳性\", \"病人-阴性\", \"未知\"], which means the status of this entity was normal, the status of this entity was abnormal, and the status is unknown, respectively.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., status: ...;\n",
      "...\n",
      "entity: ..., type: ..., status: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2235 to azure/input/gpt-35-turbo-batch/cot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, determine the hospital department the patient should visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "department: label\n",
      "The optional list for \"label\" is [\"儿科\", \"妇产科\", \"传染病科\", \"皮肤性病科\", \"外科\", \"内科\", \"五官科\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/cot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's information and consultation record in Chinese, provide the answer from the doctor's perspective in Chinese.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/cot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, determine the detailed hospital department the patient should visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "department: label\n",
      "The optional list for \"label\" is [\"泌尿外科\", \"性病科\", \"胃肠外科\", \"肝胆外科\", \"骨科\", \"小儿内科\", \"妇科\", \"小儿精神科\", \"普外科\", \"其他传染病\", \"皮肤病\", \"消化内科\", \"风湿免疫科\", \"口腔科\", \"产科\", \"肝病科\", \"肛肠外科\", \"肾内科\", \"眼科\", \"血管外科\", \"小儿外科\", \"乳腺外科\", \"心胸外科\", \"烧伤科\", \"血液科\", \"内分泌科\", \"新生儿科\", \"神经外科\", \"呼吸内科\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/cot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following physician's explanation, extract the medical entities with their corresponding types, factuality, and progression. Specifically, this explanation was generated by a physician to predict negative outcomes in kidney disease patients within the next 90 days, including rejection, death-censored graft loss, and infection. We need to extract all the following information for each entity:\n",
      "1. Entity types:\n",
      "- \"Condition\": A pathological medical condition of a patient, can describe for instance a symptom or a disease.\n",
      "- \"DiagLab\": Particular diagnostic procedures which have been carried out.\n",
      "- \"LabValues\": Mentions of lab values.\n",
      "- \"HealthState\": A positive condition of the patient.\n",
      "- \"Measure\": Mostly numeric values, often in the context of medications or lab values, but can also be a description if a value changes, e.g., raises.\n",
      "- \"Medication\": A medication.\n",
      "- \"Process\": Describes a particular process, such as blood pressure or heart rate, often related to vital parameters.\n",
      "- \"TimeInfo\": Describes temporal information, such as 2 weeks ago or January.\n",
      "- \"Other\": Additional relevant information which influences the health condition and the risk.\n",
      "\n",
      "2. Factuality: \n",
      "- \"positive\": indicates that something is present.\n",
      "- \"negative\": indicates that something is not present.\n",
      "- \"speculated\": indicates that something is not present, but might occur in the future.\n",
      "- \"unlikely\": defines a kind of speculation, but expresses a tendency towards negation.\n",
      "- \"minor\": expresses that something is present, but to a lower extent or in a lower amount.\n",
      "- \"possible_future\": expresses that something is not there, but might occur in the future.\n",
      "- \"None\": if no factuality is given.\n",
      "\n",
      "3. Progression: \n",
      "- \"increase_risk_factor\": A state/process that causes the respective endpoint (upstream in a causal chain). Increases the risk that endpoint occurs causally and probabilistically.\n",
      "- \"decrease_risk_factor\": A state/process that prevents the respective endpoint (upstream in a causal chain). Decreases the risk that endpoint occurs causally and probabilistically.\n",
      "- \"increase_symptom\": A state/process whose absence is a consequence of the respective endpoint (downstream in a causal chain). Increases risk probabilistically, but not causally.\n",
      "- \"decrease_symptom\": A state/process whose occurrence is a consequence of the respective endpoint (downstream in a causal chain). Decreases risk probabilistically, but not causally.\n",
      "- \"Conclusion\": The physician makes a concluding statement.\n",
      "- \"None\": if no progression is given.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., factuality: ..., progression: ...;\n",
      "...\n",
      "entity: ..., type: ..., factuality: ..., progression: ...;\n",
      "The optional list for \"type\" is [\"Condition\", \"DiagLab\", \"LabValues\", \"HealthState\", \"Measure\", \"Medication\", \"Process\", \"TimeInfo\", \"Other\"].\n",
      "The optional list for \"factuality\" is [\"positive\", \"negative\", \"speculated\", \"unlikely\", \"minor\", \"possible_future\", \"None\"].\n",
      "The optional list for \"progression\" is [\"increase_risk_factor\", \"decrease_risk_factor\", \"increase_symptom\", \"decrease_symptom\", \"Conclusion\", \"None\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 411 to azure/input/gpt-35-turbo-batch/cot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's chief complaint, determine whether the patient was experiencing a gout flare at the time of the Emergency Department visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Gout flare: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\", \"Unknown\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 441 to azure/input/gpt-35-turbo-batch/cot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's chief complaint, determine whether the chief complaint is related to a gout flare.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Gout flare: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\", \"Unknown\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 843 to azure/input/gpt-35-turbo-batch/cot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the text from medical consultation in Chinese, extract the medical entities mentioned by the patient and doctors, including the following types:\n",
      "- \"symptom\"(症状)：病人因患病而表现出来的异常状况，如\"发热\"、\"呼吸困难\"、\"鼻塞\"等。\n",
      "- \"drug\"(药品名)：具体的药物名称，如\"妈咪爱\"、\"蒙脱石散\"、\"蒲地蓝\"等。\n",
      "- \"drug category\"(药物类别)：根据药物功能进行划分的药物种类，如\"消炎药\"、\"感冒药\"、\"益生菌\"等。\n",
      "- \"examination\"(检查)：医学检验，如\"血常规\"、\"x光片\"、\"CRP分析\"等。\n",
      "- “operation”(操作)：相关的医疗操作，如\"输液\"、\"雾化\"、\"接种疫苗\"等。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"symptom\", \"drug\", \"drug category\", \"examination\", \"operation\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2374 to azure/input/gpt-35-turbo-batch/cot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the original diagnostic text from electronic healthcare records in Chinese, normalize them to the corresponding standard diagnostic terms. Specifically, use the names of standardized terms from the 《国际疾病分类 ICD-10 北京临床版v601》, covering diagnosis, surgery, medication, examination, laboratory testing, and symptoms. There may be multiple appropriate normalized terms for the original diagnostic text. Assuming the number of normalized terms is N, return the names of N normalized terms in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Normalized terms: label 1, label 2, ..., label N\n",
      "The optional list for \"label\" is the names of normalized terms (not code) from the 《国际疾病分类 ICD-10 北京临床版v601》, covering diagnosis, surgery, medication, examination, laboratory testing, and symptoms.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2000 to azure/input/gpt-35-turbo-batch/cot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text in Chinese, identify the clinical trial criterion that this text meets. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "clinical trial criterion: label\n",
      "The optional list for \"label\" is [\"疾病\", \"症状-患者感受\", \"体征-医生检测\", \"怀孕相关\", \"肿瘤进展\", \"疾病分期\", \"过敏耐受\", \"器官组织状态\", \"预期寿命\", \"口腔相关\", \"药物\", \"治疗或手术\", \"设备\", \"护理\", \"诊断\", \"实验室检查\", \"风险评估\", \"受体状态\", \"年龄\", \"特殊病人特征\", \"读写能力\", \"性别\", \"教育情况\", \"居住情况\", \"种族\", \"知情同意\", \"参与其它试验\", \"研究者决定\", \"能力\", \"伦理审查\", \"依存性\", \"成瘾行为\", \"睡眠\", \"锻炼\", \"饮食\", \"酒精使用\", \"性取向\", \"吸烟状况\", \"献血\", \"病例来源\", \"残疾群体\", \"健康群体\", \"数据可及性\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6146 to azure/input/gpt-35-turbo-batch/cot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, extract the clinical findings mentioned by the patient and doctors and identify their status based on the dialogue, including: \n",
      "- \"阳性\": 已有症状疾/病等相关，医生诊断（包含多个诊断结论），以及假设未来可能发生的疾病等，如：“如果不治疗的话，大概率会引起A疾病”，“A疾病”标注为阳性；\n",
      "- \"阴性\": 未患有的疾病症状相关；\n",
      "- \"其他\": 未知的标注其他，一般指用户没有回答、不知道或者回答不明确/模棱两可不好推断的情况。\n",
      "- \"不标注\": 无实际意义的不标注，一般是医生的解释说的是一般知识，和病人当前的状态条件独立不具有标注意义，及有些检查项带疾病名称的，识别的疾病（乙肝五项/乙肝抗体），药品名中出现的“疾病”不标注。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "findings: ..., status: ...;\n",
      "...\n",
      "findings: ..., status: ...;\n",
      "The optional list for \"status\" is [\"阳性\", \"阴性\", \"其他\", \"不标注\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11785 to azure/input/gpt-35-turbo-batch/cot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the next response of the doctor based on the dialogue context.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2747 to azure/input/gpt-35-turbo-batch/cot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, recognize the normalized symptoms mentioned by the patient and doctors and identify the global status of symptoms based on the dialogue, including: \n",
      "- \"positive\": 代表确定病人患有该症状\n",
      "- \"negative\": 代表确定病人没有患有该症状\n",
      "- \"uncertain\": 代表无法根据上下文确定病人是否患有该症状\n",
      "Specifically, the status of the symptom is based on the entire dialogue, not just the current sentence.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "symptom: ..., status: ...;\n",
      "...\n",
      "symptom: ..., status: ...;\n",
      "The optional list for \"status\" is [\"positive\", \"negative\", \"uncertain\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/cot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the brief report based on the dialogue between the patient and doctor. The report should include the following sections:\n",
      "1. 主诉(Chief complaint): 病人自诉（Self-report）的总结，包括主要症状或体征；\n",
      "2. 现病史(Present illness history): 对话中病人涉及到的现病史的总结，如主要症状的描述（发病情况，发病时间）；\n",
      "3. 辅助检查(Auxiliary examination): 对话中病人涉及过的医疗检查的总结，如病人已有的检查项目、检查结果、会诊记录等；\n",
      "4. 既往史(Past history): 对话中医生对病人的过去病史的总结，如既往的健康状况、过去曾经患过的疾病等；\n",
      "5. 诊断(Diagnosis): 对话中医生对病人的诊断结果的总结，如对疾病的诊断；\n",
      "6. 建议(Suggestion): 对话中医生对病人的建议的总结，如检查建议、药物治疗、注意事项。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "主诉: ...\n",
      "现病史: ...\n",
      "辅助检查: ...\n",
      "既往史: ...\n",
      "诊断: ...\n",
      "建议: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/cot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the utterance from a medical consultation in Chinese, identify the act the speaker is performing.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "dialogue act: label\n",
      "The optional list for \"label\" is [\"提问-症状\", \"提问-病因\", \"提问-基本信息\", \"提问-已有检查和治疗\", \"告知-用药建议\", \"告知-就医建议\", \"告知-注意事项\", \"诊断\", \"告知-症状\", \"告知-病因\", \"告知-基本信息\", \"告知-已有检查和治疗\", \"提问-用药建议\", \"提问-就医建议\", \"提问-注意事项\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 22059 to azure/input/gpt-35-turbo-batch/cot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the following medical information:\n",
      "- \"age\":  l'âge de la personne dont le cas est décrit, au moment du dernier élément clinique rapporté dans le cas clinique, normalisé sous la forme d'un entier (soit 0 pour un nourrisson de moins d'un an, 1 pour un enfant de moins de deux ans, y compris un an et demi, 20 pour un patient d'une vingtaine d'années, etc.).\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus). si le genre n'est pas mentionné, retournez \"None\".\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit). si le problème n'est pas mentionné, retournez \"None\".\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "age: ..., genre: ..., issue: ...\n",
      "The optional list for \"genre\" is [\"féminin\", \"masculin\", \"None\"].\n",
      "The optional list for \"issue\" is [\"guérison\", \"amélioration\", \"stable\", \"détérioration\", \"décès\", \"None\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/cot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the following medical information:\n",
      "- \"age\":  l'âge de la personne dont le cas est décrit, au moment du dernier élément clinique rapporté dans le cas clinique, normalisé sous la forme d'un entier (soit 0 pour un nourrisson de moins d'un an, 1 pour un enfant de moins de deux ans, y compris un an et demi, 20 pour un patient d'une vingtaine d'années, etc.).\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus). si le genre n'est pas mentionné, retournez \"None\".\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit). si le problème n'est pas mentionné, retournez \"None\".\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "age: ..., genre: ..., issue: ...\n",
      "The optional list for \"genre\" is [\"féminin\", \"masculin\", \"None\"].\n",
      "The optional list for \"issue\" is [\"guérison\", \"amélioration\", \"stable\", \"détérioration\", \"décès\", \"None\"].Given the clinical care report in French, extract the evidence of the following medical information from the original text:\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus).\n",
      "- \"origine\": l'origine (motif de la consultation ou de l'hospitalisation) pour le dernier événement clinique ayant motivé la consultation. Cette catégorie intègre généralement les pathologies, signes et symptômes (par exemple, \"une tuméfaction lombaire droite, fébrile avec frissons\" ou \"un contexte d'asthénie et d'altération de l'état général\"), plus rarement les circonstances d'un accident (\"une chute de 12 mètres, par défénestration, avec réception ventrale\", \"un AVP moto\" ou \"pense avoir été violée\"). Le suivi clinique se trouve dans la continuité d'événements précédents. Il ne constitue pas un motif de consultation.\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "evidence of genre: ...;\n",
      "evidence of origine: ...;\n",
      "evidence of issue: ...;\n",
      "The optional evidence of \"genre\" is the word or shot phrase that indicates the genre of the person; The optional evidence of \"origine\" and \"issue\" is the sentence or shot paragraph that indicates the origine and issue of the person, respectively. If the evidence is not mentioned, return \"None\".\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/cot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Russian, extract the following types of entities from the clincial text:\n",
      "- \"Disease\": A definite pathologic process with a characteristic set of signs and symptoms.\n",
      "- \"Symptom\": Subjective evidence of disease perceived by the patient.\n",
      "- \"Drug\": A drug product that contains one or more active and/or inactive ingredients; it is intended to treat, prevent or alleviate the symptoms of disease.\n",
      "- \"Treatment\": Procedures concerned with the remedial treatment or prevention of diseases.\n",
      "- \"Body location\": Named locations of or within the body.\n",
      "- \"Severity\": The intensity of a specific adverse event evaluated based on the magnitude of clinical signs, symptoms and findings.\n",
      "- \"Course\": The course a disease typically takes from its onset, progression in time, and eventual resolution or death of the affected individual.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Disease\", \"Symptom\", \"Drug\", \"Treatment\", \"Body location\", \"Severity\", \"Course\"].\n",
      "\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 866 to azure/input/gpt-35-turbo-batch/cot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following clinical text of a patient in Russian, extract the medical entities and identify their corresponding normalized terms.\n",
      "- \"Disease\": A definite pathologic process with a characteristic set of signs and symptoms.\n",
      "- \"Symptom\": Subjective evidence of disease perceived by the patient.\n",
      "- \"Drug\": A drug product that contains one or more active and/or inactive ingredients; it is intended to treat, prevent or alleviate the symptoms of disease.\n",
      "- \"Treatment\": Procedures concerned with the remedial treatment or prevention of diseases.\n",
      "- \"Body location\": Named locations of or within the body.\n",
      "- \"Severity\": The intensity of a specific adverse event evaluated based on the magnitude of clinical signs, symptoms and findings.\n",
      "- \"Course\": The course a disease typically takes from its onset, progression in time, and eventual resolution or death of the affected individual.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "...\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "The optional list for \"type\" is [\"Disease\", \"Symptom\", \"Drug\", \"Treatment\", \"Body location\", \"Severity\", \"Course\"].\n",
      "The normalized terms should be the corresponding text of normalized terms from the Russian language part of the UMLS ontology.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 854 to azure/input/gpt-35-turbo-batch/cot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following two clinical sentences that are labeled as \"Sentence A\" and \"Sentence B\" in French, decide the similarity of the two sentences. Specifically, analyse the potential similarity, including:\n",
      "Surface similarity: concerns the structural similarity. This similarity is based on grammatical words or words that are not related to the domain. Two sentences that have a surface similarity can be syntactically close but semantically distant.\n",
      "Semantic similarity: concerns medical concepts. The closer the concepts are to one another, the higher the similarity. These concepts can refer to medications, diseases, procedures, and others.\n",
      "Clinical compatibility: going further into the semantics, clinical compatibility is an assessment of whether sentences in a pair can refer to the same clinical case.\n",
      "Then, assign a similarity score to the sentence pair based on the following scale:\n",
      "- \"0\": For sentence pairs with only surface similarity, such as words non-specific to the medical domain or stop-words.\n",
      "- \"1\": For sentence pairs with only surface similarity, concerning at most one medical entity.\n",
      "- \"2\": For sentence pairs containing medical concepts with low semantic similarity, but no clinical compatibility. Typically, sentences in a pair can concern a disease, a procedure, or a drug.\n",
      "- \"3\": For sentence pairs with semantic similarity on several medical concepts making them partially clinically compatible.\n",
      "- \"4\": For sentence pairs with high semantic similarity and clinical compatibility. One sentence may contain more information than the other may, and vice-versa.\n",
      "- \"5\": For sentence pairs with high semantic similarity and full clinical compatibility. The sentences have globally the same meaning, while one may be more specific than the other. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "similarity score: score\n",
      "The optional list for \"score\" is [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 400 to azure/input/gpt-35-turbo-batch/cot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following sentence from a discharge summary of a cancer patient (hepatocellular carcinoma or melanoma) in German, extract the medical entities with their corresponding types and status. \n",
      "1. Entity type:\n",
      "- \"diagnosis\":  The identification of a cancer patient’s condition, specifically hepatocellular carcinoma or melanoma.\n",
      "- \"treatment\": An intervention, procedure, or therapy applied to manage, cure, or alleviate the medical condition.\n",
      "- \"medication\": A substance or drug prescribed or administered to prevent, treat, or manage a medical condition.\n",
      "\n",
      "2. Entity status:\n",
      "- \"right\": it represents the laterality of the affirmed entity. i.e., occurs on the left side.\n",
      "- \"left\": it represents the laterality of the affirmed entity. i.e., occurs on the right side.\n",
      "- \"both\": it represents the laterality of the affirmed entity. i.e., occurs on both sides.\n",
      "- \"negation\": it initiates the entity is negated, i.e., a diagnosis is ruled out or a medication is paused or stopped.\n",
      "- \"speculation\": it indicates the entity is speculative, i.e., a diagnosis diagnosis is unclear.\n",
      "- \"possible future\": it indicates the entity is a possible future event, i.e., a procedure is planned for the future.\n",
      "- \"none\": it indicates the entity has no status information, or the status information can not be determined from the context.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., status: ...;\n",
      "...\n",
      "entity: ..., type: ..., status: ...;\n",
      "The optional list for \"type\" is [\"diagnosis\", \"treatment\", \"medication\"].\n",
      "The optional list for \"status\" is [\"right\", \"left\", \"both\", \"negation\", \"speculation\", \"possible future\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/cot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following sentence from a discharge summary of a cancer patient (hepatocellular carcinoma or melanoma) in German, extract the medical entities with their types and identify their corresponding normalized terms.\n",
      "- \"diagnosis\":  A diagnosis is a disease, a symptom, or a medical observation that can be\n",
      "matched with the German Modification of the International Classification of Diseases-10 (ICD-10-GM: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/ICD/ICD-10-GM/_node.html)\n",
      "- \"treatment\": A treatment is a diagnostic procedure, an operation, or a systemic cancer treatment that can be found in the Operationen und Prozedurenschlu¨ssel (OPS: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/OPS-ICHI/OPS/_node.html).\n",
      "- \"medication\": A medication names a pharmaceutical substance or a drug that can be related to the Anatomical Therapeutic Chemical Classification System (ATC: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/ATC/_node.html). \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "...\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "The optional list for \"type\" is [\"diagnosis\", \"treatment\", \"medication\"].\n",
      "The normalized terms should be the corresponding text of normalized terms from the ICD-10-GM, OPS, or ATC classification systems.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/cot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following clinical document related to the cardiovascular domain in German, extract the following types of entities from the clinical text:\n",
      "- \"ACTIVEING\": The primary ingredient in the medication responsible for its therapeutic effect.\n",
      "- \"DRUG\": The name of the medication, including brand or generic name.\n",
      "- \"DURATION\": The length of time the medication is to be taken.\n",
      "- \"FORM\": The physical form of the medication, such as tablet, capsule, or liquid.\n",
      "- \"FREQUENCY\": How often the medication should be taken within a specific time period.\n",
      "- \"STRENGTH\": The concentration or dosage of the active ingredient in the medication.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...; \n",
      "... \n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"ACTIVEING\", \"DRUG\", \"DURATION\", \"FORM\", \"FREQUENCY\", \"STRENGTH\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/cot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical summaries of a patient in German, extract the following types of entities from the clinical text:\n",
      "- \"LOCATION_COUNTRY\": Country name or reference\n",
      "- \"NAME_DOCTOR\": Name of a medical professional\n",
      "- \"AGE\": Numeric representation of a person's age\n",
      "- \"CONTACT_FAX\": Fax number for communication\n",
      "- \"LOCATION_ZIP\": Postal or ZIP code\n",
      "- \"LOCATION_ORGANIZATION\": Name of an organization or institution\n",
      "- \"CONTACT_PHONE\": Phone number for communication\n",
      "- \"DATE\": Calendar date\n",
      "- \"LOCATION_CITY\": Name of a city\n",
      "- \"CONTACT_EMAIL\": Email address\n",
      "- \"NAME_PATIENT\": Name of a patient\n",
      "- \"LOCATION_HOSPITAL\": Name of a hospital or medical facility\n",
      "- \"PROFESSION\": Job title or occupation\n",
      "- \"NAME_TITLE\": Honorific or title before a name\n",
      "- \"NAME_USERNAME\": Username for online identification\n",
      "- \"ID\": Identification number or code\n",
      "- \"NAME_RELATIVE\": Name of a family member\n",
      "- \"NAME_EXT\": Name suffix, extension, or additional identifier\n",
      "- \"LOCATION_STREET\": Street address or name\n",
      "Return your answer in the following format. Do not output entities whose types do not exist in the clinical text. DO NOT GIVE ANY EXPLANATION:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"LOCATION_COUNTRY\", \"NAME_DOCTOR\", \"AGE\", \"CONTACT_FAX\", \"LOCATION_ZIP\", \"LOCATION_ORGANIZATION\", \"CONTACT_PHONE\", \"DATE\", \"LOCATION_CITY\", \"CONTACT_EMAIL\", \"NAME_PATIENT\", \"LOCATION_HOSPITAL\", \"PROFESSION\", \"NAME_TITLE\", \"NAME_USERNAME\", \"ID\", \"NAME_RELATIVE\", \"NAME_EXT\", \"LOCATION_STREET\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 329 to azure/input/gpt-35-turbo-batch/cot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical incident report in Japanese, determine what type of incident occurred. One report might contain more than one incident type. The incident types and their definitions are as follows:\n",
      "- \"Wrong Drug\": Wrong drug occurs when inappropriate medication or IV fluid is prescribed, dispensed, prepared or administered. Wrong drug applies when the intended drug and the actual drug are different. A generic substitution is not considered as a wrong drug.\n",
      "- \"Wrong Form\": Wrong form occurs when the wrong form of drug is ordered, dispensed or administered.\n",
      "- \"Wrong Mode\": Wrong mode occurs when the wrong mode of a medication is ordered, dispensed or administered.\n",
      "- \"Wrong Strength amount\": Wrong amount is defined as a dose of medication or volume of IV fluid over or under the intended amount, taking into account the patient's age, weight, renal and liver function.\n",
      "- \"Wrong Strength rate\": Wrong rate is defined as a rate, e.g., IV rate, being slower or faster than intended.\n",
      "- \"Wrong Strength concentration\": Wrong concentration is defined as the concentration of a medication being higher or lower than intended. Concentration is also closely related to amount and rate; most cases of 'Wrong Strength concentration' co-occur with 'Wrong Strength rate' or 'Wrong Strength amount'. A wrong concentration might be reported as a wrong amount.\n",
      "- \"Wrong Timing\": Timing-related errors are defined as administration too early or too late, relative to the time designated by the healthcare facility. There are three scenarios associated with wrong timing: No 'omission' or 'extra drug' results from wrong timing, 'omission' results from wrong timing, or 'extra drug' results from wrong timing.\n",
      "- \"Wrong Date\": Wrong date refers to the medication being administered for a different date compared to the intended date.\n",
      "- \"Wrong Duration\": Wrong duration refers to the medication being administered for a longer or shorter period than intended.\n",
      "- \"Wrong Frequency\": A wrong frequency occurs when the prescribed or administered frequency of delivery for a drug or an IV rate falls outside of the recommended range or planned number. If the frequency is larger, it is often also labeled as an extra drug. If the frequency is smaller, then 'omission' is applicable. Wrong timing is also relevant is such cases.\n",
      "- \"Wrong Dosage\": Patients may be subject to excessive or insufficient amounts of a drug.\n",
      "- \"Wrong Route\": Wrong route occurs when a medication is prescribed or administered via an incorrect route of administration, e.g., a drug that creates strong vascular irritation and should be given via the central line is administered via the peripheral line.\n",
      "- \"Others\": Other errors that are not covered by the current scope of the previous annotations, e.g., procedural errors such as forgetting to fill out a questionnaire before administrating a vaccine to a patient. For errors that are out of the scope of the above or the free text inputs does not present any error, the incident type is registered as 'Others'.\n",
      "Assuming the number of incident types is N, return the N recognized incident types in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "incident type: type 1, type 2, ..., type N\n",
      "The optional list for \"type\" is [\"Wrong Drug\", \"Wrong Form\", \"Wrong Mode\", \"Wrong Strength amount\", \"Wrong Strength rate\", \"Wrong Strength concentration\", \"Wrong Timing\", \"Wrong Date\", \"Wrong Duration\", \"Wrong Frequency\", \"Wrong Dosage\", \"Wrong Route\", \"Others\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5834 to azure/input/gpt-35-turbo-batch/cot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following medical incident report in Japanese, extract the following types of entities from the medical text.\n",
      "- \"Strength concentration\": Concentration is defined as diluted medication concentration with nominator and denominator or presented as percentage or IV fluid concentration.\n",
      "- \"Frequency\": Frequency is defined as how many times a drug is given per unit of time.\n",
      "- \"Date\": Date is defined as a time unit including a date and time unit longer than one day.\n",
      "- \"Drug\": The intended to deliver or actual delivered drug name, or entities described as drugs.\n",
      "- \"Dosage\": Dosage is defined as the number of units (e.g., tables, bottles, ampules) given to the patient as a single dose.\n",
      "- \"Strength rate\": Rate typically represents one measure against another quantity or measure.\n",
      "- \"Drug form\": The form of a drug (e.g., tablet, subcutaneous injection).\n",
      "- \"Duration\": Duration is defined as the period during which a drug is administered to the patient.\n",
      "- \"Strength amount\": The amount is defined as medication dose or IV fluid volume.\n",
      "- \"Drug mode\": The mode is a drug mode of action that is associated with pharmacodynamic action.\n",
      "- \"Route\": Route is defined as the route of drug administration to the patient, which may include the infusion sites, routes and pumps.\n",
      "- \"Timing\": Timing is defined as a scheduled administration time that is predefined as time interval.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Strength concentration\", \"Frequency\", \"Date\", \"Drug\", \"Dosage\", \"Strength rate\", \"Drug form\", \"Duration\", \"Strength amount\", \"Drug mode\", \"Route\", \"Timing\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/cot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following medical incident report in Japanese, extract the medical entities with their corresponding types and intention/factuality information. Specifically, need to extract all the following information for each entity:\n",
      "1. Entity types:\n",
      "- \"Strength concentration\": Concentration is defined as diluted medication concentration with nominator and denominator or presented as percentage or IV fluid concentration.\n",
      "- \"Frequency\": Frequency is defined as how many times a drug is given per unit of time.\n",
      "- \"Date\": Date is defined as a time unit including a date and time unit longer than one day.\n",
      "- \"Drug\": The intended to deliver or actual delivered drug name, or entities described as drugs.\n",
      "- \"Dosage\": Dosage is defined as the number of units (e.g., tables, bottles, ampules) given to the patient as a single dose.\n",
      "- \"Strength rate\": Rate typically represents one measure against another quantity or measure.\n",
      "- \"Drug form\": The form of a drug (e.g., tablet, subcutaneous injection).\n",
      "- \"Duration\": Duration is defined as the period during which a drug is administered to the patient.\n",
      "- \"Strength amount\": The amount is defined as medication dose or IV fluid volume.\n",
      "- \"Drug mode\": The mode is a drug mode of action that is associated with pharmacodynamic action.\n",
      "- \"Route\": Route is defined as the route of drug administration to the patient, which may include the infusion sites, routes and pumps.\n",
      "- \"Timing\": Timing is defined as a scheduled administration time that is predefined as time interval.\n",
      "\n",
      "2. Intention / factuality information:\n",
      "- \"IA\": Intended & Actual. The entity was intended to be given and was actually given. This indicates no error has occured as to this entity.\n",
      "- \"IN\": Intended & Not-actual. The entity was intended to be given but actually was not given. This indicates the intended medication was not delivered.\n",
      "- \"NA\": Not-intended & Actual. The entity was not intended to be given but actually was. This indicates the not intended medication was mistakenly delivered.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., intention: ...;\n",
      "...\n",
      "entity: ..., type: ..., intention: ...;\n",
      "The optional list for \"type\" is [\"Strength concentration\", \"Frequency\", \"Date\", \"Drug\", \"Dosage\", \"Strength rate\", \"Drug form\", \"Duration\", \"Strength amount\", \"Drug mode\", \"Route\", \"Timing\"].\n",
      "The optional list for \"intention\" is [\"IA\", \"IN\", \"NA\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/cot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical report of a patient in Japanese, extract the following types of entities from the clinical text:\n",
      "- \"age\": 年齢を示す表現, 例: 63歳, 56歳, 1歳6か月, 高校生. \n",
      "- \"sex\": 性別を示す表現, 例: 男性, 女性, 男児, 女児.\n",
      "- \"smoking\": 喫煙に関する表現, 例: 喫煙, タバコ, 喫煙歴, 禁煙.\n",
      "- \"drinking\": 飲酒に関する表現, 例: 飲酒, アルコール, 飲酒歴, 禁酒.\n",
      "- \"state\": 患者の状態全般を示す表現. いわゆる, 病名, 症状 (患者の訴え), 所見(観察結果) などを含む, 例: 吐き気, 萎縮症, 糖尿病, 口渇.\n",
      "- \"body\": 人体部位. 特定の部位を示す表現, 例: 頭,胃,肝,手足, 眼瞼結膜.\n",
      "- \"tissue\": 人体組織.人体各所で繰り返し出現するもの, 例: 筋,筋肉,粘膜, 細胞, 繊維.\n",
      "- \"item\": 患者の状態を表すために参照される項目, 例: 血糖,血糖値, HbA1c, 食欲.\n",
      "- \"clinical test\": 臨床検査に関する表現. item との違いは計測法を含むか否か, 例: 神経学的検査, 徒手筋力検査.\n",
      "- \"PN\": 患者の状態が, ある (Positive), ない (Negative), わからない (None) ことを示す表現, 例: で、認め, 示す, 認めるなし, 認めず, ではなく, なく不明であった、詳細不明.\n",
      "- \"judge\": 医療者により, 患者の状態がある (Positive), あることが疑われ る (Suspicious), 将来あるもしれない (Future), ない (Negative), 不明 (None)であることが判断されたことを示す表現, 例: 診断された, 考えられた,  疑われた, 可能性も考え否定的, 明らかではなかった確定診断に至らなかった.\n",
      "- \"quantity evaluation\": 数値への評価。 高い (High), 正常 (Normal) 低い (Low), 例: 上昇, 異常高値, 増加, 正常, 基準値, 保たれて低下, 減少, 減弱.\n",
      "- \"quantity progress\": 数値の変化。 上昇 (Increase) 変化なし (NoChange)低下 (Decrease). \n",
      "- \"quality evaluation\": 数値以外の状態の程度を質的に示す表現. 主に疾患の重症度を示 す 軽度 (Mild) 中等度 (Moderate) 重度・高度 (Severe), 例: 軽度, 軽い, わずか, やや中等度, 中度, 中等症強い, 著名, 著しい, 重度.\n",
      "- \"quality progress\": 数値以外の状態の時間的な変化を質的に示す表現. 出現 (Start) 悪化 (Worsen), 持続 (NoChange), 改善 (Improve), 軽快 (Recover), 例: 出現した, なった, きたした悪化, 増悪, 進行, 顕在化持続, 保たれて, 変わらず改善, 軽快, 回復落ち着き, 復帰, 軽快, 回復.\n",
      "- \"value\": 検査値など、 身体や検体を測定し得られる数値, 例: 7.5, 20, 1, 5, 165.0.\n",
      "- \"unit\": 数値との組で表される単位, 例: mg/日, 行, cm, kg/m2.\n",
      "- \"time\": 時間軸上における特定位置の時点や区間を示す表現, 例: 約10年前, その後直後.\n",
      "- \"time span\": 時間軸上の位置を問わず時間幅を示す表現, 例: 1日, 長時間, 2カ月間.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"age\", \"sex\", \"smoking\", \"drinking\", \"state\", \"body\", \"tissue\", \"item\", \"clinical test\", \"PN\", \"judge\", \"quantity evaluation\", \"quantity progress\", \"quality evaluation\", \"quality progress\", \"value\", \"unit\", \"time\", \"time span\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 220 to azure/input/gpt-35-turbo-batch/cot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following question from a patient, generate the doctor's response based on the dialogue context. Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "doctor: ...\"\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 733 to azure/input/gpt-35-turbo-batch/cot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following question from a patient, generate the doctor's response based on the dialogue context. Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "doctor: ...\"\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11217 to azure/input/gpt-35-turbo-batch/cot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2097 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 428 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 193 to azure/input/gpt-35-turbo-batch/direct-5-shot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 303 to azure/input/gpt-35-turbo-batch/direct-5-shot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 300 to azure/input/gpt-35-turbo-batch/direct-5-shot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 966 to azure/input/gpt-35-turbo-batch/direct-5-shot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 384 to azure/input/gpt-35-turbo-batch/direct-5-shot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1911 to azure/input/gpt-35-turbo-batch/direct-5-shot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 238 to azure/input/gpt-35-turbo-batch/direct-5-shot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1771 to azure/input/gpt-35-turbo-batch/direct-5-shot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6184 to azure/input/gpt-35-turbo-batch/direct-5-shot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 1199 to azure/input/gpt-35-turbo-batch/direct-5-shot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2235 to azure/input/gpt-35-turbo-batch/direct-5-shot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5193 to azure/input/gpt-35-turbo-batch/direct-5-shot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 411 to azure/input/gpt-35-turbo-batch/direct-5-shot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 441 to azure/input/gpt-35-turbo-batch/direct-5-shot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 843 to azure/input/gpt-35-turbo-batch/direct-5-shot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2374 to azure/input/gpt-35-turbo-batch/direct-5-shot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2000 to azure/input/gpt-35-turbo-batch/direct-5-shot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 6146 to azure/input/gpt-35-turbo-batch/direct-5-shot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11785 to azure/input/gpt-35-turbo-batch/direct-5-shot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 2747 to azure/input/gpt-35-turbo-batch/direct-5-shot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct-5-shot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 833 to azure/input/gpt-35-turbo-batch/direct-5-shot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 22059 to azure/input/gpt-35-turbo-batch/direct-5-shot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct-5-shot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 696 to azure/input/gpt-35-turbo-batch/direct-5-shot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 866 to azure/input/gpt-35-turbo-batch/direct-5-shot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 854 to azure/input/gpt-35-turbo-batch/direct-5-shot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 400 to azure/input/gpt-35-turbo-batch/direct-5-shot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct-5-shot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 880 to azure/input/gpt-35-turbo-batch/direct-5-shot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 329 to azure/input/gpt-35-turbo-batch/direct-5-shot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5834 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 5748 to azure/input/gpt-35-turbo-batch/direct-5-shot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 220 to azure/input/gpt-35-turbo-batch/direct-5-shot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 733 to azure/input/gpt-35-turbo-batch/direct-5-shot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Save 11217 to azure/input/gpt-35-turbo-batch/direct-5-shot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2097 to azure/input/gpt-4o-batch/direct/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 428 to azure/input/gpt-4o-batch/direct/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 193 to azure/input/gpt-4o-batch/direct/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 303 to azure/input/gpt-4o-batch/direct/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3170 to azure/input/gpt-4o-batch/direct/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3183 to azure/input/gpt-4o-batch/direct/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 384 to azure/input/gpt-4o-batch/direct/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1911 to azure/input/gpt-4o-batch/direct/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 238 to azure/input/gpt-4o-batch/direct/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1771 to azure/input/gpt-4o-batch/direct/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6184 to azure/input/gpt-4o-batch/direct/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1199 to azure/input/gpt-4o-batch/direct/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2235 to azure/input/gpt-4o-batch/direct/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 411 to azure/input/gpt-4o-batch/direct/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 441 to azure/input/gpt-4o-batch/direct/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 843 to azure/input/gpt-4o-batch/direct/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2374 to azure/input/gpt-4o-batch/direct/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2000 to azure/input/gpt-4o-batch/direct/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6146 to azure/input/gpt-4o-batch/direct/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11785 to azure/input/gpt-4o-batch/direct/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2747 to azure/input/gpt-4o-batch/direct/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 22059 to azure/input/gpt-4o-batch/direct/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 866 to azure/input/gpt-4o-batch/direct/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 854 to azure/input/gpt-4o-batch/direct/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 400 to azure/input/gpt-4o-batch/direct/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 380 to azure/input/gpt-4o-batch/direct/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 329 to azure/input/gpt-4o-batch/direct/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5834 to azure/input/gpt-4o-batch/direct/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 220 to azure/input/gpt-4o-batch/direct/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 733 to azure/input/gpt-4o-batch/direct/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11217 to azure/input/gpt-4o-batch/direct/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, determine whether the text mentions adverse drug effects.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "adverse drug effect: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2097 to azure/input/gpt-4o-batch/cot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, identify all the drugs and their corresponding adverse effect mentioned in the text.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "drug: ..., adverse effect: ...;\n",
      "...\n",
      "drug: ..., adverse effect: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 428 to azure/input/gpt-4o-batch/cot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text, identify all the drugs and their corresponding dosage information mentioned in the text.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "drug: ..., dosage: ...;\n",
      "...\n",
      "drug: ..., dosage: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 193 to azure/input/gpt-4o-batch/cot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a brain Magnetic Resonance Imaging (MRI) radiology report, determine whether the patient has acute ischemic stroke (AIS).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "AIS: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 303 to azure/input/gpt-4o-batch/cot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the clinical outcome for this patient is survival or death. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Survival: status\n",
      "The optional list for \"status\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3170 to azure/input/gpt-4o-batch/cot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the patient will require more than seven days of hospitalization.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Hospitalization > 7 days: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3183 to azure/input/gpt-4o-batch/cot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text related to cancer in Spanish, extract all entities about tumor morphology mentioned in the text. \n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: tumor morphology;\n",
      "...\n",
      "entity: ..., type: tumor morphology;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/cot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical document in Spanish, identify the entities of tumor morphology and determine the corresponding morphology codes. Specifically, the entities of tumor morphology can be linked to an morphology codes from CIE-O (Clasificación Internacional de Enfermedades para Oncología, i.e., the Spanish equivalent of ICD-O, version 3.1).\n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "- \"Morphology code\": The morphology code is a code from CIE-O that represents the morphology of the tumor. This code is used to classify the tumor morphology in a standardized way. A code consists of a four-digit morphology code indicating the tumor's histological type, followed by a slash and a single digit indicating the tumor's behavior.\n",
      "Assuming the number of normalized morphology codes is N, return the N normalized codes in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Morphology code: code 1, code 2, ..., code N\n",
      "The optional list for \"code\" is the normalized code from CIE-O.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/cot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text related to cancer in Spanish, extract all entities about tumor morphology and identify its corresponding morphology codes. Specifically, every entity of tumor morphology is linked to an morphology codes from CIE-O (Clasificación Internacional de Enfermedades para Oncología, i.e., the Spanish equivalent of ICD-O, version 3.1).\n",
      "- \"Tumor morphology\": Una neoplasia es un crecimiento o formación de tejido nuevo, anormal, especialmente de carácter tumoral, benigno o maligno. La clasificación de las neoplasias según su morfología o características histológicas hace referencia a la forma y estructura de las células tumorales que se estudian para clasificar las neoplasias según su tejido de origen. El tejido de origen y el tipo de células que componen una morfología determinan a menudo la tasa de crecimiento esperada, la gravedad de la enfermedad y el tipo de tratamiento recomendado\n",
      "- \"Morphology code\": The morphology code is a code from CIE-O that represents the morphology of the tumor. This code is used to classify the tumor morphology in a standardized way. A code consists of a four-digit morphology code indicating the tumor's histological type, followed by a slash and a single digit indicating the tumor's behavior.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., code: ...;\n",
      "...\n",
      "entity: ..., code: ...;\n",
      "The optional list for \"code\" is the normalized code from CIE-O.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/cot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine which anatomical area of the body the report refers to. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "anatomical area: label\n",
      "The optional list for \"label\" is ['Columna', 'Neuro', 'Musculoskeletal', 'Body'].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/cot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate blocks of the ICD-10 corresponding to the conditions mentioned in the report. Specifically, the block is the second level of the ICD-10 classification and represents a group of related diseases. Each block is identified by a code containing a character and two digits, which indicates its chapter and detailed block.\n",
      "This report may contain multiple conditions and is related to multiple blocks. Assuming the number of appropriate blocks is N, return the codes of N appropriate blocks in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 block: code 1, code 2, ..., code N\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/cot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate chapters of ICD-10 corresponding to the conditions mentioned in the report. Specifically, the chapter is the highest level of the ICD-10 classification and each chapter represents a group of related diseases. Each chapter is identified by a Roman numeral from I to XXII, including the following chapters:\n",
      "- \"I\": Certain infectious and parasitic diseases (A00–B99)\n",
      "- \"II\": Neoplasms (C00–D49)\n",
      "- \"III\": Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism (D50–D89)\n",
      "- \"IV\": Endocrine, nutritional, and metabolic diseases (E00–E89)\n",
      "- \"V\": Mental, Behavioral and Neurodevelopmental disorders (F01–F99)\n",
      "- \"VI\": Diseases of the nervous system (G00–G99)\n",
      "- \"VII\": Diseases of the eye and adnexa (H00–H59)\n",
      "- \"VIII\": Diseases of the ear and mastoid process (H60–H95)\n",
      "- \"IX\": Diseases of the circulatory system (I00–I99)\n",
      "- \"X\": Diseases of the respiratory system (J00–J99)\n",
      "- \"XI\": Diseases of the digestive system (K00–K95)\n",
      "- \"XII\": Diseases of the skin and subcutaneous tissue (L00–L99)\n",
      "- \"XIII\": Diseases of the musculoskeletal system and connective tissue (M00–M99)\n",
      "- \"XIV\": Diseases of the genitourinary system (N00–N99)\n",
      "- \"XV\": Pregnancy, childbirth, and the puerperium (O00–O9A)\n",
      "- \"XVI\": Certain conditions originating in the perinatal period (P00–P96)\n",
      "- \"XVII\": Congenital malformations, deformations, and chromosomal abnormalities (Q00–Q99)\n",
      "- \"XVIII\": Symptoms, signs, and abnormal clinical and laboratory findings, not elsewhere classified (R00–R99)\n",
      "- \"XIX\": Injury, poisoning, and certain other consequences of external causes (S00–T88)\n",
      "- \"XX\": External causes of morbidity (V00–Y99)\n",
      "- \"XXI\": Factors influencing health status and contact with health services (Z00–Z99)\n",
      "- \"XXII\": Codes for special purposes (U00–U85)\n",
      "This report may contain multiple conditions and is related to multiple chapters. Assuming the number of appropriate chapters is N, return the codes of N appropriate chapters in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 chapter: code 1, code 2, ..., code N\n",
      "The optional list for \"code\" is [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\", \"X\", \"XI\", \"XII\", \"XIII\", \"XIV\", \"XV\", \"XVI\", \"XVII\", \"XVIII\", \"XIX\", \"XX\", \"XXI\", \"XXII\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/cot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a radiology report in Spanish, determine the appropriate sub-blocks of the ICD-10 corresponding to the conditions mentioned in the report. Specifically, the sub-block is the third level of the ICD-10 classification and represents a group of related diseases. Each sub-block is identified by a code containing a character and two digits, which indicates its chapter, block, and detailed sub-block.\n",
      "This report may contain multiple conditions and is related to multiple sub-blocks. Assuming the number of appropriate sub-blocks is N, return the codes of N appropriate sub-blocks in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "ICD-10 sub-block: code 1, code_2, ..., code N\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/cot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text from electronic healthcare records in Chinese, extract all the clinical findings and their attributes. 具体而言，给定一段现病史或者医学影像所见报告，要求从中抽取临床发现事件的四个属性: 解剖部位、主体词、描述词，以及发生状态:\n",
      "1. 主体词(subject)：指患者的电子病历中的疾病名称或者由疾病引发的症状，也包括患者的一般情况如饮食，二便，睡眠等。主体词尽可能完整并是专有名词，比如“麻木， 疼痛，发烧，囊肿”等；专有名词，如“头晕”，晕只能发生在头部，“胸闷”，闷只能发生在胸部，所以不进行拆分，保留完整的专有名词。涉及泛化的症状不做标注，如“无其他不适”，句子中的“不适”不需要标注，只针对具体的进行标注。注意：有较小比例的主体词会映射到ICD标准术语，所使用的ICD的版本为“国际疾病分类 ICD-10北京临床版v601.xIsx”\n",
      "2. 描述词(description)：对主体词的发生时序特征、轻重程度、形态颜色等多个维度的刻画，也包括疾病的起病缓急、突发\n",
      "3. 解剖部位(location)：指主体词发生在患者的身体部位，也包括组织，细胞，系统等，也包括部位的方向和数量\n",
      "4. 发生状态(status)：“肯定”，“否定”或“不确定”，表示该主体词在患者的电子病历中的存在状态\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "subject: ..., description: [..., ...], location: [..., ...], status: ...;\n",
      "...\n",
      "subject: ..., description: [..., ...], location: [..., ...], status: ...;\n",
      "The optional list for \"status\" is [\"肯定\", \"否定\", \"不确定\"]; If there is not a description or location, they should be \"[]\"; if there are multiple descriptions or locations, they should be separated by commas in the list, like [..., ...].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 384 to azure/input/gpt-4o-batch/cot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a clinical electronic health record in Chinese, diagnose the disease this patient has.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "diagnosis: disease\n",
      "The optional list for \"disease\" is [\"胃息肉\", \"泌尿道感染\", \"慢性阻塞性肺病\", \"痛风\", \"胃溃疡\", \"高血压\", \"哮喘\", \"胃炎\", \"心律失常\", \"糖尿病\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1911 to azure/input/gpt-4o-batch/cot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a sentence from clinical notes, determine whether the provided concept is Affirmed or Negated. Specifically, if the concept is mentioned in the sentence and it is negated, then the label is \"No\". If the concept is mentioned in the sentence and it is affirmed, then the label is \"Yes\". \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "affirmed: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 238 to azure/input/gpt-4o-batch/cot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the discharge summary of a patient, identify the clinical action items for physicians from hospital discharge notes. Specifically, the clinical action items include the following types:\n",
      "- \"Patient Instructions\": Post-discharge instructions that are directed to the patient, so the PCP (primary care provider) can ensure the patient understands and performs them, such as: 'No driving until post-op visit and you are no longer taking pain medications.'\n",
      "- \"Appointment\": Appointments to be made by the PCPs, or monitored to ensure the patient attends them, such as: 'The patient requires a neurology consult at XYZ for evaluation.'\n",
      "- \"Medications\": Medications that the PCP either needs to ensure that the patient is taking correctly (e.g., time-limited medications) or new medications that may need dose adjustment, such as: 'The patient was instructed to hold ASA and refrain from NSAIDs for 2 weeks.'\n",
      "- \"Lab\": Laboratory tests that either have results pending or need to be ordered by the PCP, such as: 'We ask that the patients’ family physician repeat these tests in 2 weeks to ensure  resolution.'\n",
      "- \"Procedure\": Procedures that the PCP needs to either order, ensure another caregiver orders, or ensure the patient undergoes, such as: 'Please follow-up for EGD with GI.'\n",
      "- \"Imaging\": Imaging studies that either have results pending or need to be ordered by the PCP, such as: 'Superior segment of the left lower lobe: rounded density which could have been related to infection, but follow-up for resolution recommended to exclude possible malignancy.'\n",
      "- \"Other\": Other actionable information that is important to relay to the PCP but does not fall under existing aspects (e.g., the need to closely observe the patient’s diet, or fax results to another provider), such as: 'Since the patient has been struggling to gain weight this past year, we will monitor his nutritional status and  trend weights closely.'\n",
      "Assuming the number of action items is N, return the N recognized action items in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "action items: item 1, item 2, ..., item N\n",
      "The optional list for \"item\" is [\"Patient Instructions\", \"Appointment\", \"Medications\", \"Lab\", \"Procedure\", \"Imaging\", \"Other\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1771 to azure/input/gpt-4o-batch/cot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the anser from a doctor's perspective in Chinese.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6184 to azure/input/gpt-4o-batch/cot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, where the recommended medications from the doctor are masked as \"[MASK]\", predict those recommended medications. Note that the number of medications is equal to the number of \"[MASK]\", assumed to be N. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "medication: label 1, label 2, ..., label N\n",
      "The optional list for \"label\" is: [\"酮康唑\", \"板蓝根\", \"右美沙芬\", \"莫沙必利\", \"风寒感冒颗粒\", \"双黄连口服液\", \"蒲地蓝消炎口服液\", \"水飞蓟素\", \"米诺环素\", \"氯雷他定\", \"布地奈德\", \"苏黄止咳胶囊\", \"胶体果胶铋\", \"哈西奈德\", \"谷胱甘肽\", \"二硫化硒\", \"泰诺\", \"硫磺皂\", \"对乙酰氨基酚\", \"奥司他韦\", \"甘草酸苷\", \"红霉素\", \"西替利嗪\", \"克拉霉素\", \"氢化可的松\", \"复方甲氧那明胶囊\", \"三九胃泰\", \"替诺福韦\", \"健胃消食片\", \"炉甘石洗剂\", \"蒙脱石\", \"曲美布汀\", \"阿奇霉素\", \"扶正化瘀胶囊\", \"依巴斯汀\", \"感冒灵\", \"他克莫司\", \"氨溴索\", \"康复新液\", \"多烯磷脂酰胆碱\", \"恩替卡韦\", \"桉柠蒎肠溶软胶囊\", \"曲安奈德\", \"甘草片\", \"左氧氟沙星\", \"奥美拉唑\", \"铝镁化合物\", \"复方消化酶\", \"头孢类\", \"甲氧氯普胺\", \"地塞米松\", \"美沙拉秦\", \"双环醇\", \"肠炎宁\", \"抗病毒颗粒\", \"阿莫西林\", \"川贝枇杷露\", \"谷氨酰胺\", \"山莨菪碱\", \"阿达帕林\", \"孟鲁司特\", \"糠酸莫米松\", \"快克\", \"布洛芬\", \"益生菌\", \"通窍鼻炎颗粒\", \"阿昔洛韦\", \"生理氯化钠溶液\", \"连花清瘟胶囊\", \"黄连素\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1199 to azure/input/gpt-4o-batch/cot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, extract the following types of medical entities:\n",
      "1. \"symptom\": This type of entity refers to the symptoms mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"symptom\" is [\"行动不便\", \"战栗抽搐\", \"心慌\", \"背痛\", \"头晕\", \"呃逆\", \"腹部不适\", \"高血压\", \"高血糖\", \"呼吸困难\", \"胸闷\", \"高血脂\", \"恶心\", \"呕吐\", \"胸痛\", \"乏力\", \"出汗\", \"发热\", \"休克\", \"晕厥\", \"感冒\",\"咳嗽\", \"流涕\", \"头痛\", \"胃部不适\", \"僵硬\", \"发绀\", \"糖尿病\", \"贫血\", \"水肿\", \"心绞痛\", \"甲亢\", \"早搏\", \"心律不齐\", \"房间隔缺损\", \"房颤\", \"心衰\", \"心肌梗死\", \"先天性心脏病\", \"心肌缺血\", \"室间隔缺损\", \"心肌炎\", \"冠心病\", \"心肌病\", \"心脏肥大\"].\n",
      "- The optional list of \"status\" for \"symptom\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the symptom appeared in the patient, the symptom was not presented in the patient, the symptom was diagnosed by the doctor, the symptom was excluded by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "2. \"surgery\": This type of entity refers to the surgery operations mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"surgery\" is [\"介入\", \"射频消融\", \"搭桥\", \"支架\"].\n",
      "- The optional list of \"status\" for \"surgery\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the surgery was done on the patient, the surgery was not done on the patient, the surgery was recommended by the doctor, the surgery was deprecated by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "3. \"examination\": This type of entity refers to the medical tests mentioned by the patient and the doctor.\n",
      "- The optional list of \"entity\" for \"examination\" is [\"心电图\", \"彩超\", \"心肌酶\", \"体检\", \"造影\", \"超声\", \"ct\", \"血常规\", \"甲状腺功能\", \"胸片\", \"b超\", \"肾功能\", \"平板\", \"cta\", \"测血压\", \"核磁共振\"].\n",
      "- The optional list of \"status\" for \"examination\" is [\"病人-阳性\", \"病人-阴性\", \"医生-阳性\", \"医生-阴性\", \"未知\"], which means the examination was done on the patient, the examination was not done on the patient, the examination was recommended by the doctor, the examination was deprecated by the doctor, and the status is unknown, respectively.\n",
      "\n",
      "4. \"general information\": This type of entity refers to some general information that is relevant to the patient:\n",
      "- The optional list of \"entity\" for \"general information\" is [\"睡眠\", \"饮食\", \"精神状态\", \"大小便\", \"吸烟\", \"饮酒\"].\n",
      "- The optional list of \"status\" for \"general information\" is [\"病人-阳性\", \"病人-阴性\", \"未知\"], which means the status of this entity was normal, the status of this entity was abnormal, and the status is unknown, respectively.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., status: ...;\n",
      "...\n",
      "entity: ..., type: ..., status: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2235 to azure/input/gpt-4o-batch/cot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, determine the hospital department the patient should visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "department: label\n",
      "The optional list for \"label\" is [\"儿科\", \"妇产科\", \"传染病科\", \"皮肤性病科\", \"外科\", \"内科\", \"五官科\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/cot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's information and consultation record in Chinese, provide the answer from the doctor's perspective in Chinese.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/cot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation record in Chinese, determine the detailed hospital department the patient should visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "department: label\n",
      "The optional list for \"label\" is [\"泌尿外科\", \"性病科\", \"胃肠外科\", \"肝胆外科\", \"骨科\", \"小儿内科\", \"妇科\", \"小儿精神科\", \"普外科\", \"其他传染病\", \"皮肤病\", \"消化内科\", \"风湿免疫科\", \"口腔科\", \"产科\", \"肝病科\", \"肛肠外科\", \"肾内科\", \"眼科\", \"血管外科\", \"小儿外科\", \"乳腺外科\", \"心胸外科\", \"烧伤科\", \"血液科\", \"内分泌科\", \"新生儿科\", \"神经外科\", \"呼吸内科\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/cot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following physician's explanation, extract the medical entities with their corresponding types, factuality, and progression. Specifically, this explanation was generated by a physician to predict negative outcomes in kidney disease patients within the next 90 days, including rejection, death-censored graft loss, and infection. We need to extract all the following information for each entity:\n",
      "1. Entity types:\n",
      "- \"Condition\": A pathological medical condition of a patient, can describe for instance a symptom or a disease.\n",
      "- \"DiagLab\": Particular diagnostic procedures which have been carried out.\n",
      "- \"LabValues\": Mentions of lab values.\n",
      "- \"HealthState\": A positive condition of the patient.\n",
      "- \"Measure\": Mostly numeric values, often in the context of medications or lab values, but can also be a description if a value changes, e.g., raises.\n",
      "- \"Medication\": A medication.\n",
      "- \"Process\": Describes a particular process, such as blood pressure or heart rate, often related to vital parameters.\n",
      "- \"TimeInfo\": Describes temporal information, such as 2 weeks ago or January.\n",
      "- \"Other\": Additional relevant information which influences the health condition and the risk.\n",
      "\n",
      "2. Factuality: \n",
      "- \"positive\": indicates that something is present.\n",
      "- \"negative\": indicates that something is not present.\n",
      "- \"speculated\": indicates that something is not present, but might occur in the future.\n",
      "- \"unlikely\": defines a kind of speculation, but expresses a tendency towards negation.\n",
      "- \"minor\": expresses that something is present, but to a lower extent or in a lower amount.\n",
      "- \"possible_future\": expresses that something is not there, but might occur in the future.\n",
      "- \"None\": if no factuality is given.\n",
      "\n",
      "3. Progression: \n",
      "- \"increase_risk_factor\": A state/process that causes the respective endpoint (upstream in a causal chain). Increases the risk that endpoint occurs causally and probabilistically.\n",
      "- \"decrease_risk_factor\": A state/process that prevents the respective endpoint (upstream in a causal chain). Decreases the risk that endpoint occurs causally and probabilistically.\n",
      "- \"increase_symptom\": A state/process whose absence is a consequence of the respective endpoint (downstream in a causal chain). Increases risk probabilistically, but not causally.\n",
      "- \"decrease_symptom\": A state/process whose occurrence is a consequence of the respective endpoint (downstream in a causal chain). Decreases risk probabilistically, but not causally.\n",
      "- \"Conclusion\": The physician makes a concluding statement.\n",
      "- \"None\": if no progression is given.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., factuality: ..., progression: ...;\n",
      "...\n",
      "entity: ..., type: ..., factuality: ..., progression: ...;\n",
      "The optional list for \"type\" is [\"Condition\", \"DiagLab\", \"LabValues\", \"HealthState\", \"Measure\", \"Medication\", \"Process\", \"TimeInfo\", \"Other\"].\n",
      "The optional list for \"factuality\" is [\"positive\", \"negative\", \"speculated\", \"unlikely\", \"minor\", \"possible_future\", \"None\"].\n",
      "The optional list for \"progression\" is [\"increase_risk_factor\", \"decrease_risk_factor\", \"increase_symptom\", \"decrease_symptom\", \"Conclusion\", \"None\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 411 to azure/input/gpt-4o-batch/cot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's chief complaint, determine whether the patient was experiencing a gout flare at the time of the Emergency Department visit.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Gout flare: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\", \"Unknown\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 441 to azure/input/gpt-4o-batch/cot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the patient's chief complaint, determine whether the chief complaint is related to a gout flare.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Gout flare: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\", \"Unknown\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 843 to azure/input/gpt-4o-batch/cot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the text from medical consultation in Chinese, extract the medical entities mentioned by the patient and doctors, including the following types:\n",
      "- \"symptom\"(症状)：病人因患病而表现出来的异常状况，如\"发热\"、\"呼吸困难\"、\"鼻塞\"等。\n",
      "- \"drug\"(药品名)：具体的药物名称，如\"妈咪爱\"、\"蒙脱石散\"、\"蒲地蓝\"等。\n",
      "- \"drug category\"(药物类别)：根据药物功能进行划分的药物种类，如\"消炎药\"、\"感冒药\"、\"益生菌\"等。\n",
      "- \"examination\"(检查)：医学检验，如\"血常规\"、\"x光片\"、\"CRP分析\"等。\n",
      "- “operation”(操作)：相关的医疗操作，如\"输液\"、\"雾化\"、\"接种疫苗\"等。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"symptom\", \"drug\", \"drug category\", \"examination\", \"operation\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2374 to azure/input/gpt-4o-batch/cot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the original diagnostic text from electronic healthcare records in Chinese, normalize them to the corresponding standard diagnostic terms. Specifically, use the names of standardized terms from the 《国际疾病分类 ICD-10 北京临床版v601》, covering diagnosis, surgery, medication, examination, laboratory testing, and symptoms. There may be multiple appropriate normalized terms for the original diagnostic text. Assuming the number of normalized terms is N, return the names of N normalized terms in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Normalized terms: label 1, label 2, ..., label N\n",
      "The optional list for \"label\" is the names of normalized terms (not code) from the 《国际疾病分类 ICD-10 北京临床版v601》, covering diagnosis, surgery, medication, examination, laboratory testing, and symptoms.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2000 to azure/input/gpt-4o-batch/cot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text in Chinese, identify the clinical trial criterion that this text meets. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "clinical trial criterion: label\n",
      "The optional list for \"label\" is [\"疾病\", \"症状-患者感受\", \"体征-医生检测\", \"怀孕相关\", \"肿瘤进展\", \"疾病分期\", \"过敏耐受\", \"器官组织状态\", \"预期寿命\", \"口腔相关\", \"药物\", \"治疗或手术\", \"设备\", \"护理\", \"诊断\", \"实验室检查\", \"风险评估\", \"受体状态\", \"年龄\", \"特殊病人特征\", \"读写能力\", \"性别\", \"教育情况\", \"居住情况\", \"种族\", \"知情同意\", \"参与其它试验\", \"研究者决定\", \"能力\", \"伦理审查\", \"依存性\", \"成瘾行为\", \"睡眠\", \"锻炼\", \"饮食\", \"酒精使用\", \"性取向\", \"吸烟状况\", \"献血\", \"病例来源\", \"残疾群体\", \"健康群体\", \"数据可及性\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6146 to azure/input/gpt-4o-batch/cot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, extract the clinical findings mentioned by the patient and doctors and identify their status based on the dialogue, including: \n",
      "- \"阳性\": 已有症状疾/病等相关，医生诊断（包含多个诊断结论），以及假设未来可能发生的疾病等，如：“如果不治疗的话，大概率会引起A疾病”，“A疾病”标注为阳性；\n",
      "- \"阴性\": 未患有的疾病症状相关；\n",
      "- \"其他\": 未知的标注其他，一般指用户没有回答、不知道或者回答不明确/模棱两可不好推断的情况。\n",
      "- \"不标注\": 无实际意义的不标注，一般是医生的解释说的是一般知识，和病人当前的状态条件独立不具有标注意义，及有些检查项带疾病名称的，识别的疾病（乙肝五项/乙肝抗体），药品名中出现的“疾病”不标注。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "findings: ..., status: ...;\n",
      "...\n",
      "findings: ..., status: ...;\n",
      "The optional list for \"status\" is [\"阳性\", \"阴性\", \"其他\", \"不标注\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11785 to azure/input/gpt-4o-batch/cot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the next response of the doctor based on the dialogue context.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "医生: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2747 to azure/input/gpt-4o-batch/cot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, recognize the normalized symptoms mentioned by the patient and doctors and identify the global status of symptoms based on the dialogue, including: \n",
      "- \"positive\": 代表确定病人患有该症状\n",
      "- \"negative\": 代表确定病人没有患有该症状\n",
      "- \"uncertain\": 代表无法根据上下文确定病人是否患有该症状\n",
      "Specifically, the status of the symptom is based on the entire dialogue, not just the current sentence.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "symptom: ..., status: ...;\n",
      "...\n",
      "symptom: ..., status: ...;\n",
      "The optional list for \"status\" is [\"positive\", \"negative\", \"uncertain\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/cot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical consultation in Chinese, generate the brief report based on the dialogue between the patient and doctor. The report should include the following sections:\n",
      "1. 主诉(Chief complaint): 病人自诉（Self-report）的总结，包括主要症状或体征；\n",
      "2. 现病史(Present illness history): 对话中病人涉及到的现病史的总结，如主要症状的描述（发病情况，发病时间）；\n",
      "3. 辅助检查(Auxiliary examination): 对话中病人涉及过的医疗检查的总结，如病人已有的检查项目、检查结果、会诊记录等；\n",
      "4. 既往史(Past history): 对话中医生对病人的过去病史的总结，如既往的健康状况、过去曾经患过的疾病等；\n",
      "5. 诊断(Diagnosis): 对话中医生对病人的诊断结果的总结，如对疾病的诊断；\n",
      "6. 建议(Suggestion): 对话中医生对病人的建议的总结，如检查建议、药物治疗、注意事项。\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "主诉: ...\n",
      "现病史: ...\n",
      "辅助检查: ...\n",
      "既往史: ...\n",
      "诊断: ...\n",
      "建议: ...\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/cot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the utterance from a medical consultation in Chinese, identify the act the speaker is performing.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "dialogue act: label\n",
      "The optional list for \"label\" is [\"提问-症状\", \"提问-病因\", \"提问-基本信息\", \"提问-已有检查和治疗\", \"告知-用药建议\", \"告知-就医建议\", \"告知-注意事项\", \"诊断\", \"告知-症状\", \"告知-病因\", \"告知-基本信息\", \"告知-已有检查和治疗\", \"提问-用药建议\", \"提问-就医建议\", \"提问-注意事项\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 22059 to azure/input/gpt-4o-batch/cot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the following medical information:\n",
      "- \"age\":  l'âge de la personne dont le cas est décrit, au moment du dernier élément clinique rapporté dans le cas clinique, normalisé sous la forme d'un entier (soit 0 pour un nourrisson de moins d'un an, 1 pour un enfant de moins de deux ans, y compris un an et demi, 20 pour un patient d'une vingtaine d'années, etc.).\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus). si le genre n'est pas mentionné, retournez \"None\".\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit). si le problème n'est pas mentionné, retournez \"None\".\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "age: ..., genre: ..., issue: ...\n",
      "The optional list for \"genre\" is [\"féminin\", \"masculin\", \"None\"].\n",
      "The optional list for \"issue\" is [\"guérison\", \"amélioration\", \"stable\", \"détérioration\", \"décès\", \"None\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/cot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the following medical information:\n",
      "- \"age\":  l'âge de la personne dont le cas est décrit, au moment du dernier élément clinique rapporté dans le cas clinique, normalisé sous la forme d'un entier (soit 0 pour un nourrisson de moins d'un an, 1 pour un enfant de moins de deux ans, y compris un an et demi, 20 pour un patient d'une vingtaine d'années, etc.).\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus). si le genre n'est pas mentionné, retournez \"None\".\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit). si le problème n'est pas mentionné, retournez \"None\".\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "age: ..., genre: ..., issue: ...\n",
      "The optional list for \"genre\" is [\"féminin\", \"masculin\", \"None\"].\n",
      "The optional list for \"issue\" is [\"guérison\", \"amélioration\", \"stable\", \"détérioration\", \"décès\", \"None\"].Given the clinical care report in French, extract the evidence of the following medical information from the original text:\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus).\n",
      "- \"origine\": l'origine (motif de la consultation ou de l'hospitalisation) pour le dernier événement clinique ayant motivé la consultation. Cette catégorie intègre généralement les pathologies, signes et symptômes (par exemple, \"une tuméfaction lombaire droite, fébrile avec frissons\" ou \"un contexte d'asthénie et d'altération de l'état général\"), plus rarement les circonstances d'un accident (\"une chute de 12 mètres, par défénestration, avec réception ventrale\", \"un AVP moto\" ou \"pense avoir été violée\"). Le suivi clinique se trouve dans la continuité d'événements précédents. Il ne constitue pas un motif de consultation.\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "evidence of genre: ...;\n",
      "evidence of origine: ...;\n",
      "evidence of issue: ...;\n",
      "The optional evidence of \"genre\" is the word or shot phrase that indicates the genre of the person; The optional evidence of \"origine\" and \"issue\" is the sentence or shot paragraph that indicates the origine and issue of the person, respectively. If the evidence is not mentioned, return \"None\".\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/cot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Russian, extract the following types of entities from the clincial text:\n",
      "- \"Disease\": A definite pathologic process with a characteristic set of signs and symptoms.\n",
      "- \"Symptom\": Subjective evidence of disease perceived by the patient.\n",
      "- \"Drug\": A drug product that contains one or more active and/or inactive ingredients; it is intended to treat, prevent or alleviate the symptoms of disease.\n",
      "- \"Treatment\": Procedures concerned with the remedial treatment or prevention of diseases.\n",
      "- \"Body location\": Named locations of or within the body.\n",
      "- \"Severity\": The intensity of a specific adverse event evaluated based on the magnitude of clinical signs, symptoms and findings.\n",
      "- \"Course\": The course a disease typically takes from its onset, progression in time, and eventual resolution or death of the affected individual.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Disease\", \"Symptom\", \"Drug\", \"Treatment\", \"Body location\", \"Severity\", \"Course\"].\n",
      "\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 866 to azure/input/gpt-4o-batch/cot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following clinical text of a patient in Russian, extract the medical entities and identify their corresponding normalized terms.\n",
      "- \"Disease\": A definite pathologic process with a characteristic set of signs and symptoms.\n",
      "- \"Symptom\": Subjective evidence of disease perceived by the patient.\n",
      "- \"Drug\": A drug product that contains one or more active and/or inactive ingredients; it is intended to treat, prevent or alleviate the symptoms of disease.\n",
      "- \"Treatment\": Procedures concerned with the remedial treatment or prevention of diseases.\n",
      "- \"Body location\": Named locations of or within the body.\n",
      "- \"Severity\": The intensity of a specific adverse event evaluated based on the magnitude of clinical signs, symptoms and findings.\n",
      "- \"Course\": The course a disease typically takes from its onset, progression in time, and eventual resolution or death of the affected individual.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "...\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "The optional list for \"type\" is [\"Disease\", \"Symptom\", \"Drug\", \"Treatment\", \"Body location\", \"Severity\", \"Course\"].\n",
      "The normalized terms should be the corresponding text of normalized terms from the Russian language part of the UMLS ontology.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 854 to azure/input/gpt-4o-batch/cot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following two clinical sentences that are labeled as \"Sentence A\" and \"Sentence B\" in French, decide the similarity of the two sentences. Specifically, analyse the potential similarity, including:\n",
      "Surface similarity: concerns the structural similarity. This similarity is based on grammatical words or words that are not related to the domain. Two sentences that have a surface similarity can be syntactically close but semantically distant.\n",
      "Semantic similarity: concerns medical concepts. The closer the concepts are to one another, the higher the similarity. These concepts can refer to medications, diseases, procedures, and others.\n",
      "Clinical compatibility: going further into the semantics, clinical compatibility is an assessment of whether sentences in a pair can refer to the same clinical case.\n",
      "Then, assign a similarity score to the sentence pair based on the following scale:\n",
      "- \"0\": For sentence pairs with only surface similarity, such as words non-specific to the medical domain or stop-words.\n",
      "- \"1\": For sentence pairs with only surface similarity, concerning at most one medical entity.\n",
      "- \"2\": For sentence pairs containing medical concepts with low semantic similarity, but no clinical compatibility. Typically, sentences in a pair can concern a disease, a procedure, or a drug.\n",
      "- \"3\": For sentence pairs with semantic similarity on several medical concepts making them partially clinically compatible.\n",
      "- \"4\": For sentence pairs with high semantic similarity and clinical compatibility. One sentence may contain more information than the other may, and vice-versa.\n",
      "- \"5\": For sentence pairs with high semantic similarity and full clinical compatibility. The sentences have globally the same meaning, while one may be more specific than the other. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "similarity score: score\n",
      "The optional list for \"score\" is [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 400 to azure/input/gpt-4o-batch/cot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following sentence from a discharge summary of a cancer patient (hepatocellular carcinoma or melanoma) in German, extract the medical entities with their corresponding types and status. \n",
      "1. Entity type:\n",
      "- \"diagnosis\":  The identification of a cancer patient’s condition, specifically hepatocellular carcinoma or melanoma.\n",
      "- \"treatment\": An intervention, procedure, or therapy applied to manage, cure, or alleviate the medical condition.\n",
      "- \"medication\": A substance or drug prescribed or administered to prevent, treat, or manage a medical condition.\n",
      "\n",
      "2. Entity status:\n",
      "- \"right\": it represents the laterality of the affirmed entity. i.e., occurs on the left side.\n",
      "- \"left\": it represents the laterality of the affirmed entity. i.e., occurs on the right side.\n",
      "- \"both\": it represents the laterality of the affirmed entity. i.e., occurs on both sides.\n",
      "- \"negation\": it initiates the entity is negated, i.e., a diagnosis is ruled out or a medication is paused or stopped.\n",
      "- \"speculation\": it indicates the entity is speculative, i.e., a diagnosis diagnosis is unclear.\n",
      "- \"possible future\": it indicates the entity is a possible future event, i.e., a procedure is planned for the future.\n",
      "- \"none\": it indicates the entity has no status information, or the status information can not be determined from the context.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., status: ...;\n",
      "...\n",
      "entity: ..., type: ..., status: ...;\n",
      "The optional list for \"type\" is [\"diagnosis\", \"treatment\", \"medication\"].\n",
      "The optional list for \"status\" is [\"right\", \"left\", \"both\", \"negation\", \"speculation\", \"possible future\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/cot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following sentence from a discharge summary of a cancer patient (hepatocellular carcinoma or melanoma) in German, extract the medical entities with their types and identify their corresponding normalized terms.\n",
      "- \"diagnosis\":  A diagnosis is a disease, a symptom, or a medical observation that can be\n",
      "matched with the German Modification of the International Classification of Diseases-10 (ICD-10-GM: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/ICD/ICD-10-GM/_node.html)\n",
      "- \"treatment\": A treatment is a diagnostic procedure, an operation, or a systemic cancer treatment that can be found in the Operationen und Prozedurenschlu¨ssel (OPS: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/OPS-ICHI/OPS/_node.html).\n",
      "- \"medication\": A medication names a pharmaceutical substance or a drug that can be related to the Anatomical Therapeutic Chemical Classification System (ATC: https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/ATC/_node.html). \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "...\n",
      "entity: ..., type: ..., normalized terms: ...;\n",
      "The optional list for \"type\" is [\"diagnosis\", \"treatment\", \"medication\"].\n",
      "The normalized terms should be the corresponding text of normalized terms from the ICD-10-GM, OPS, or ATC classification systems.\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/cot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following clinical document related to the cardiovascular domain in German, extract the following types of entities from the clinical text:\n",
      "- \"ACTIVEING\": The primary ingredient in the medication responsible for its therapeutic effect.\n",
      "- \"DRUG\": The name of the medication, including brand or generic name.\n",
      "- \"DURATION\": The length of time the medication is to be taken.\n",
      "- \"FORM\": The physical form of the medication, such as tablet, capsule, or liquid.\n",
      "- \"FREQUENCY\": How often the medication should be taken within a specific time period.\n",
      "- \"STRENGTH\": The concentration or dosage of the active ingredient in the medication.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...; \n",
      "... \n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"ACTIVEING\", \"DRUG\", \"DURATION\", \"FORM\", \"FREQUENCY\", \"STRENGTH\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 380 to azure/input/gpt-4o-batch/cot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical summaries of a patient in German, extract the following types of entities from the clinical text:\n",
      "- \"LOCATION_COUNTRY\": Country name or reference\n",
      "- \"NAME_DOCTOR\": Name of a medical professional\n",
      "- \"AGE\": Numeric representation of a person's age\n",
      "- \"CONTACT_FAX\": Fax number for communication\n",
      "- \"LOCATION_ZIP\": Postal or ZIP code\n",
      "- \"LOCATION_ORGANIZATION\": Name of an organization or institution\n",
      "- \"CONTACT_PHONE\": Phone number for communication\n",
      "- \"DATE\": Calendar date\n",
      "- \"LOCATION_CITY\": Name of a city\n",
      "- \"CONTACT_EMAIL\": Email address\n",
      "- \"NAME_PATIENT\": Name of a patient\n",
      "- \"LOCATION_HOSPITAL\": Name of a hospital or medical facility\n",
      "- \"PROFESSION\": Job title or occupation\n",
      "- \"NAME_TITLE\": Honorific or title before a name\n",
      "- \"NAME_USERNAME\": Username for online identification\n",
      "- \"ID\": Identification number or code\n",
      "- \"NAME_RELATIVE\": Name of a family member\n",
      "- \"NAME_EXT\": Name suffix, extension, or additional identifier\n",
      "- \"LOCATION_STREET\": Street address or name\n",
      "Return your answer in the following format. Do not output entities whose types do not exist in the clinical text. DO NOT GIVE ANY EXPLANATION:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"LOCATION_COUNTRY\", \"NAME_DOCTOR\", \"AGE\", \"CONTACT_FAX\", \"LOCATION_ZIP\", \"LOCATION_ORGANIZATION\", \"CONTACT_PHONE\", \"DATE\", \"LOCATION_CITY\", \"CONTACT_EMAIL\", \"NAME_PATIENT\", \"LOCATION_HOSPITAL\", \"PROFESSION\", \"NAME_TITLE\", \"NAME_USERNAME\", \"ID\", \"NAME_RELATIVE\", \"NAME_EXT\", \"LOCATION_STREET\"]\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 329 to azure/input/gpt-4o-batch/cot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the medical incident report in Japanese, determine what type of incident occurred. One report might contain more than one incident type. The incident types and their definitions are as follows:\n",
      "- \"Wrong Drug\": Wrong drug occurs when inappropriate medication or IV fluid is prescribed, dispensed, prepared or administered. Wrong drug applies when the intended drug and the actual drug are different. A generic substitution is not considered as a wrong drug.\n",
      "- \"Wrong Form\": Wrong form occurs when the wrong form of drug is ordered, dispensed or administered.\n",
      "- \"Wrong Mode\": Wrong mode occurs when the wrong mode of a medication is ordered, dispensed or administered.\n",
      "- \"Wrong Strength amount\": Wrong amount is defined as a dose of medication or volume of IV fluid over or under the intended amount, taking into account the patient's age, weight, renal and liver function.\n",
      "- \"Wrong Strength rate\": Wrong rate is defined as a rate, e.g., IV rate, being slower or faster than intended.\n",
      "- \"Wrong Strength concentration\": Wrong concentration is defined as the concentration of a medication being higher or lower than intended. Concentration is also closely related to amount and rate; most cases of 'Wrong Strength concentration' co-occur with 'Wrong Strength rate' or 'Wrong Strength amount'. A wrong concentration might be reported as a wrong amount.\n",
      "- \"Wrong Timing\": Timing-related errors are defined as administration too early or too late, relative to the time designated by the healthcare facility. There are three scenarios associated with wrong timing: No 'omission' or 'extra drug' results from wrong timing, 'omission' results from wrong timing, or 'extra drug' results from wrong timing.\n",
      "- \"Wrong Date\": Wrong date refers to the medication being administered for a different date compared to the intended date.\n",
      "- \"Wrong Duration\": Wrong duration refers to the medication being administered for a longer or shorter period than intended.\n",
      "- \"Wrong Frequency\": A wrong frequency occurs when the prescribed or administered frequency of delivery for a drug or an IV rate falls outside of the recommended range or planned number. If the frequency is larger, it is often also labeled as an extra drug. If the frequency is smaller, then 'omission' is applicable. Wrong timing is also relevant is such cases.\n",
      "- \"Wrong Dosage\": Patients may be subject to excessive or insufficient amounts of a drug.\n",
      "- \"Wrong Route\": Wrong route occurs when a medication is prescribed or administered via an incorrect route of administration, e.g., a drug that creates strong vascular irritation and should be given via the central line is administered via the peripheral line.\n",
      "- \"Others\": Other errors that are not covered by the current scope of the previous annotations, e.g., procedural errors such as forgetting to fill out a questionnaire before administrating a vaccine to a patient. For errors that are out of the scope of the above or the free text inputs does not present any error, the incident type is registered as 'Others'.\n",
      "Assuming the number of incident types is N, return the N recognized incident types in the output.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "incident type: type 1, type 2, ..., type N\n",
      "The optional list for \"type\" is [\"Wrong Drug\", \"Wrong Form\", \"Wrong Mode\", \"Wrong Strength amount\", \"Wrong Strength rate\", \"Wrong Strength concentration\", \"Wrong Timing\", \"Wrong Date\", \"Wrong Duration\", \"Wrong Frequency\", \"Wrong Dosage\", \"Wrong Route\", \"Others\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5834 to azure/input/gpt-4o-batch/cot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following medical incident report in Japanese, extract the following types of entities from the medical text.\n",
      "- \"Strength concentration\": Concentration is defined as diluted medication concentration with nominator and denominator or presented as percentage or IV fluid concentration.\n",
      "- \"Frequency\": Frequency is defined as how many times a drug is given per unit of time.\n",
      "- \"Date\": Date is defined as a time unit including a date and time unit longer than one day.\n",
      "- \"Drug\": The intended to deliver or actual delivered drug name, or entities described as drugs.\n",
      "- \"Dosage\": Dosage is defined as the number of units (e.g., tables, bottles, ampules) given to the patient as a single dose.\n",
      "- \"Strength rate\": Rate typically represents one measure against another quantity or measure.\n",
      "- \"Drug form\": The form of a drug (e.g., tablet, subcutaneous injection).\n",
      "- \"Duration\": Duration is defined as the period during which a drug is administered to the patient.\n",
      "- \"Strength amount\": The amount is defined as medication dose or IV fluid volume.\n",
      "- \"Drug mode\": The mode is a drug mode of action that is associated with pharmacodynamic action.\n",
      "- \"Route\": Route is defined as the route of drug administration to the patient, which may include the infusion sites, routes and pumps.\n",
      "- \"Timing\": Timing is defined as a scheduled administration time that is predefined as time interval.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Strength concentration\", \"Frequency\", \"Date\", \"Drug\", \"Dosage\", \"Strength rate\", \"Drug form\", \"Duration\", \"Strength amount\", \"Drug mode\", \"Route\", \"Timing\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/cot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following medical incident report in Japanese, extract the medical entities with their corresponding types and intention/factuality information. Specifically, need to extract all the following information for each entity:\n",
      "1. Entity types:\n",
      "- \"Strength concentration\": Concentration is defined as diluted medication concentration with nominator and denominator or presented as percentage or IV fluid concentration.\n",
      "- \"Frequency\": Frequency is defined as how many times a drug is given per unit of time.\n",
      "- \"Date\": Date is defined as a time unit including a date and time unit longer than one day.\n",
      "- \"Drug\": The intended to deliver or actual delivered drug name, or entities described as drugs.\n",
      "- \"Dosage\": Dosage is defined as the number of units (e.g., tables, bottles, ampules) given to the patient as a single dose.\n",
      "- \"Strength rate\": Rate typically represents one measure against another quantity or measure.\n",
      "- \"Drug form\": The form of a drug (e.g., tablet, subcutaneous injection).\n",
      "- \"Duration\": Duration is defined as the period during which a drug is administered to the patient.\n",
      "- \"Strength amount\": The amount is defined as medication dose or IV fluid volume.\n",
      "- \"Drug mode\": The mode is a drug mode of action that is associated with pharmacodynamic action.\n",
      "- \"Route\": Route is defined as the route of drug administration to the patient, which may include the infusion sites, routes and pumps.\n",
      "- \"Timing\": Timing is defined as a scheduled administration time that is predefined as time interval.\n",
      "\n",
      "2. Intention / factuality information:\n",
      "- \"IA\": Intended & Actual. The entity was intended to be given and was actually given. This indicates no error has occured as to this entity.\n",
      "- \"IN\": Intended & Not-actual. The entity was intended to be given but actually was not given. This indicates the intended medication was not delivered.\n",
      "- \"NA\": Not-intended & Actual. The entity was not intended to be given but actually was. This indicates the not intended medication was mistakenly delivered.\n",
      "\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ..., intention: ...;\n",
      "...\n",
      "entity: ..., type: ..., intention: ...;\n",
      "The optional list for \"type\" is [\"Strength concentration\", \"Frequency\", \"Date\", \"Drug\", \"Dosage\", \"Strength rate\", \"Drug form\", \"Duration\", \"Strength amount\", \"Drug mode\", \"Route\", \"Timing\"].\n",
      "The optional list for \"intention\" is [\"IA\", \"IN\", \"NA\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/cot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical report of a patient in Japanese, extract the following types of entities from the clinical text:\n",
      "- \"age\": 年齢を示す表現, 例: 63歳, 56歳, 1歳6か月, 高校生. \n",
      "- \"sex\": 性別を示す表現, 例: 男性, 女性, 男児, 女児.\n",
      "- \"smoking\": 喫煙に関する表現, 例: 喫煙, タバコ, 喫煙歴, 禁煙.\n",
      "- \"drinking\": 飲酒に関する表現, 例: 飲酒, アルコール, 飲酒歴, 禁酒.\n",
      "- \"state\": 患者の状態全般を示す表現. いわゆる, 病名, 症状 (患者の訴え), 所見(観察結果) などを含む, 例: 吐き気, 萎縮症, 糖尿病, 口渇.\n",
      "- \"body\": 人体部位. 特定の部位を示す表現, 例: 頭,胃,肝,手足, 眼瞼結膜.\n",
      "- \"tissue\": 人体組織.人体各所で繰り返し出現するもの, 例: 筋,筋肉,粘膜, 細胞, 繊維.\n",
      "- \"item\": 患者の状態を表すために参照される項目, 例: 血糖,血糖値, HbA1c, 食欲.\n",
      "- \"clinical test\": 臨床検査に関する表現. item との違いは計測法を含むか否か, 例: 神経学的検査, 徒手筋力検査.\n",
      "- \"PN\": 患者の状態が, ある (Positive), ない (Negative), わからない (None) ことを示す表現, 例: で、認め, 示す, 認めるなし, 認めず, ではなく, なく不明であった、詳細不明.\n",
      "- \"judge\": 医療者により, 患者の状態がある (Positive), あることが疑われ る (Suspicious), 将来あるもしれない (Future), ない (Negative), 不明 (None)であることが判断されたことを示す表現, 例: 診断された, 考えられた,  疑われた, 可能性も考え否定的, 明らかではなかった確定診断に至らなかった.\n",
      "- \"quantity evaluation\": 数値への評価。 高い (High), 正常 (Normal) 低い (Low), 例: 上昇, 異常高値, 増加, 正常, 基準値, 保たれて低下, 減少, 減弱.\n",
      "- \"quantity progress\": 数値の変化。 上昇 (Increase) 変化なし (NoChange)低下 (Decrease). \n",
      "- \"quality evaluation\": 数値以外の状態の程度を質的に示す表現. 主に疾患の重症度を示 す 軽度 (Mild) 中等度 (Moderate) 重度・高度 (Severe), 例: 軽度, 軽い, わずか, やや中等度, 中度, 中等症強い, 著名, 著しい, 重度.\n",
      "- \"quality progress\": 数値以外の状態の時間的な変化を質的に示す表現. 出現 (Start) 悪化 (Worsen), 持続 (NoChange), 改善 (Improve), 軽快 (Recover), 例: 出現した, なった, きたした悪化, 増悪, 進行, 顕在化持続, 保たれて, 変わらず改善, 軽快, 回復落ち着き, 復帰, 軽快, 回復.\n",
      "- \"value\": 検査値など、 身体や検体を測定し得られる数値, 例: 7.5, 20, 1, 5, 165.0.\n",
      "- \"unit\": 数値との組で表される単位, 例: mg/日, 行, cm, kg/m2.\n",
      "- \"time\": 時間軸上における特定位置の時点や区間を示す表現, 例: 約10年前, その後直後.\n",
      "- \"time span\": 時間軸上の位置を問わず時間幅を示す表現, 例: 1日, 長時間, 2カ月間.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"age\", \"sex\", \"smoking\", \"drinking\", \"state\", \"body\", \"tissue\", \"item\", \"clinical test\", \"PN\", \"judge\", \"quantity evaluation\", \"quantity progress\", \"quality evaluation\", \"quality progress\", \"value\", \"unit\", \"time\", \"time span\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 220 to azure/input/gpt-4o-batch/cot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following question from a patient, generate the doctor's response based on the dialogue context. Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "doctor: ...\"\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 733 to azure/input/gpt-4o-batch/cot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following question from a patient, generate the doctor's response based on the dialogue context. Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "doctor: ...\"\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11217 to azure/input/gpt-4o-batch/cot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Test split: 2097 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2097 to azure/input/gpt-4o-batch/direct-5-shot/1-1.ADE-ADE identification.batch.jsonl\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Test split: 428 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 428 to azure/input/gpt-4o-batch/direct-5-shot/1-2.ADE-ADE relation.batch.jsonl\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Test split: 193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 193 to azure/input/gpt-4o-batch/direct-5-shot/1-3.ADE-Drug dosage.batch.jsonl\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Test split: 303 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 303 to azure/input/gpt-4o-batch/direct-5-shot/5.BrainMRI-AIS.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3170 to azure/input/gpt-4o-batch/direct-5-shot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 3183 to azure/input/gpt-4o-batch/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.CODING.batch.jsonl\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Test split: 300 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 300 to azure/input/gpt-4o-batch/direct-5-shot/7.Cantemist.Norm.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.area.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_block.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_chapter.batch.jsonl\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Test split: 966 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 966 to azure/input/gpt-4o-batch/direct-5-shot/8.CARES.icd10_sub_block.batch.jsonl\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Test split: 384 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 384 to azure/input/gpt-4o-batch/direct-5-shot/9.CHIP-CDEE.batch.jsonl\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Test split: 1911 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1911 to azure/input/gpt-4o-batch/direct-5-shot/12.C-EMRS.batch.jsonl\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Test split: 238 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 238 to azure/input/gpt-4o-batch/direct-5-shot/19.ClinicalNotes-UPMC.batch.jsonl\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Test split: 1771 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1771 to azure/input/gpt-4o-batch/direct-5-shot/22.CLIP.batch.jsonl\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Test split: 6184 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6184 to azure/input/gpt-4o-batch/direct-5-shot/23.cMedQA.batch.jsonl\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Test split: 1199 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 1199 to azure/input/gpt-4o-batch/direct-5-shot/26.DialMed.batch.jsonl\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Test split: 2235 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2235 to azure/input/gpt-4o-batch/direct-5-shot/28.MIE.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.primary_department.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.qa.batch.jsonl\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Test split: 5193 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5193 to azure/input/gpt-4o-batch/direct-5-shot/29.EHRQA.sub_department.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 411 to azure/input/gpt-4o-batch/direct-5-shot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Test split: 441 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 441 to azure/input/gpt-4o-batch/direct-5-shot/33.GOUT-CC.consensus.batch.jsonl\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Test split: 843 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 843 to azure/input/gpt-4o-batch/direct-5-shot/33.GOUT-CC.predict.batch.jsonl\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Test split: 2374 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2374 to azure/input/gpt-4o-batch/direct-5-shot/43.IMCS-V2-NER.batch.jsonl\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Test split: 2000 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2000 to azure/input/gpt-4o-batch/direct-5-shot/81.CHIP-CDN.batch.jsonl\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Test split: 6146 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 6146 to azure/input/gpt-4o-batch/direct-5-shot/82.CHIP-CTC.batch.jsonl\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Test split: 11785 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11785 to azure/input/gpt-4o-batch/direct-5-shot/83.CHIP-MDCFNPC.batch.jsonl\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Test split: 2747 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 2747 to azure/input/gpt-4o-batch/direct-5-shot/84.MedDG.batch.jsonl\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct-5-shot/85.IMCS-V2-SR.batch.jsonl\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Test split: 833 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 833 to azure/input/gpt-4o-batch/direct-5-shot/86.IMCS-V2-MRG.batch.jsonl\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Test split: 22059 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 22059 to azure/input/gpt-4o-batch/direct-5-shot/87.IMCS-V2-DAC.batch.jsonl\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct-5-shot/91-1.CAS.label.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 696 to azure/input/gpt-4o-batch/direct-5-shot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Test split: 866 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 866 to azure/input/gpt-4o-batch/direct-5-shot/96.RuCCoN.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Test split: 854 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 854 to azure/input/gpt-4o-batch/direct-5-shot/96.RuCCoN.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Test split: 400 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 400 to azure/input/gpt-4o-batch/direct-5-shot/97.CLISTER.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct-5-shot/98.BRONCO150.NER_status.batch.jsonl\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Test split: 880 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 880 to azure/input/gpt-4o-batch/direct-5-shot/98.BRONCO150.NER_Nor.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 380 to azure/input/gpt-4o-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Test split: 329 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 329 to azure/input/gpt-4o-batch/direct-5-shot/100.GraSSCo_PHI.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Test split: 5834 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5834 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.IncidentType.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.NER.batch.jsonl\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Test split: 5748 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 5748 to azure/input/gpt-4o-batch/direct-5-shot/101.IFMIR.NER_factuality.batch.jsonl\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Test split: 220 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 220 to azure/input/gpt-4o-batch/direct-5-shot/102.iCorpus.batch.jsonl\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Test split: 733 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 733 to azure/input/gpt-4o-batch/direct-5-shot/103.icliniq-10k.batch.jsonl\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Test split: 11217 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Save 11217 to azure/input/gpt-4o-batch/direct-5-shot/104.HealthCareMagic-100k.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple task into one batch data jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-35-turbo-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input/merged/gpt-35-turbo-batch/direct/gpt-35-turbo-batch.direct.chunk_0.jsonl with 49708 lines and size 137.82 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct/gpt-35-turbo-batch.direct.chunk_1.jsonl with 49675 lines and size 73.35 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct/gpt-35-turbo-batch.direct.chunk_2.jsonl with 30209 lines and size 74.64 MB\n"
     ]
    }
   ],
   "source": [
    "prompt_mode = \"direct\"\n",
    "model = \"gpt-35-turbo-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=50000, max_size_mb=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mode = \"cot\"\n",
    "model = \"gpt-35-turbo-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=50000, max_size_mb=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_0.jsonl with 6191 lines and size 161.19 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_1.jsonl with 6015 lines and size 176.35 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_2.jsonl with 26240 lines and size 149.22 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_3.jsonl with 33606 lines and size 156.75 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_4.jsonl with 28040 lines and size 149.37 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_5.jsonl with 18283 lines and size 116.24 MB\n",
      "Created: azure/input/merged/gpt-35-turbo-batch/direct-5-shot/gpt-35-turbo-batch.direct-5-shot.chunk_6.jsonl with 11217 lines and size 75.50 MB\n"
     ]
    }
   ],
   "source": [
    "prompt_mode = \"direct-5-shot\"\n",
    "model = \"gpt-35-turbo-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=50000, max_size_mb=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpt-4o-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input/merged/gpt-4o-batch/direct/gpt-4o-batch.direct.chunk_0.jsonl with 49708 lines and size 137.25 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct/gpt-4o-batch.direct.chunk_1.jsonl with 49675 lines and size 72.78 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct/gpt-4o-batch.direct.chunk_2.jsonl with 30209 lines and size 74.29 MB\n"
     ]
    }
   ],
   "source": [
    "prompt_mode = \"direct\"\n",
    "model = \"gpt-4o-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=50000, max_size_mb=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input/merged/gpt-4o-batch/cot/gpt-4o-batch.cot.chunk_0.jsonl with 49708 lines and size 140.75 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/cot/gpt-4o-batch.cot.chunk_1.jsonl with 49675 lines and size 76.34 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/cot/gpt-4o-batch.cot.chunk_2.jsonl with 30209 lines and size 76.40 MB\n"
     ]
    }
   ],
   "source": [
    "prompt_mode = \"cot\"\n",
    "model = \"gpt-4o-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=50000, max_size_mb=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_0.jsonl with 6191 lines and size 161.12 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_1.jsonl with 6981 lines and size 185.43 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_2.jsonl with 25274 lines and size 139.78 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_3.jsonl with 33606 lines and size 156.37 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_4.jsonl with 33874 lines and size 184.12 MB\n",
      "Created: azure/input/merged/gpt-4o-batch/direct-5-shot/gpt-4o-batch.direct-5-shot.chunk_5.jsonl with 23666 lines and size 156.34 MB\n"
     ]
    }
   ],
   "source": [
    "prompt_mode = \"direct-5-shot\"\n",
    "model = \"gpt-4o-batch\"\n",
    "merge_azure_batch_data(model, prompt_mode, max_lines=80000, max_size_mb=190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_azure_result = \"azure/output\"\n",
    "path_dir_save = \"result_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-35-turbo/104.HealthCareMagic-100k-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-35-turbo/1-1.ADE-ADE identification-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-35-turbo/1-2.ADE-ADE relation-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-35-turbo/1-3.ADE-Drug dosage-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-35-turbo/5.BrainMRI-AIS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3151\n",
      " - Missing: 28572\n",
      " - Missing: 28800\n",
      " - Missing: 28940\n",
      " - Missing: 29056\n",
      " - Missing: 29306\n",
      " - Missing: 29355\n",
      " - Missing: 29734\n",
      " - Missing: 29811\n",
      " - Missing: 30060\n",
      " - Missing: 30072\n",
      " - Missing: 30206\n",
      " - Missing: 30267\n",
      " - Missing: 30324\n",
      " - Missing: 30353\n",
      " - Missing: 30996\n",
      " - Missing: 31167\n",
      " - Missing: 31190\n",
      " - Missing: 31258\n",
      " - Missing: 31648\n",
      " - Matched: 3151\n",
      " - Lost 19 samples.\n",
      " - Saved: result_test/6.Brateca.mortality/gpt-35-turbo/6.Brateca.mortality-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3165\n",
      " - Missing: 28771\n",
      " - Missing: 28801\n",
      " - Missing: 29581\n",
      " - Missing: 29604\n",
      " - Missing: 29879\n",
      " - Missing: 29899\n",
      " - Missing: 29949\n",
      " - Missing: 30014\n",
      " - Missing: 30081\n",
      " - Missing: 30095\n",
      " - Missing: 30293\n",
      " - Missing: 30369\n",
      " - Missing: 30666\n",
      " - Missing: 30815\n",
      " - Missing: 30825\n",
      " - Missing: 31134\n",
      " - Missing: 31615\n",
      " - Missing: 31806\n",
      " - Matched: 3165\n",
      " - Lost 18 samples.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-35-turbo/7.Cantemist.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-35-turbo/7.Cantemist.CODING-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-35-turbo/7.Cantemist.Norm-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-35-turbo/8.CARES.area-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-35-turbo/8.CARES.icd10_block-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-35-turbo/8.CARES.icd10_chapter-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-35-turbo/8.CARES.icd10_sub_block-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-35-turbo/9.CHIP-CDEE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-35-turbo/12.C-EMRS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-35-turbo/19.ClinicalNotes-UPMC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-35-turbo/22.CLIP-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-35-turbo/23.cMedQA-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-35-turbo/26.DialMed-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-35-turbo/28.MIE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-35-turbo/29.EHRQA.primary_department-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-35-turbo/29.EHRQA.qa-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-35-turbo/29.EHRQA.sub_department-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-35-turbo/33.GOUT-CC.consensus-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-35-turbo/33.GOUT-CC.predict-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-35-turbo/43.IMCS-V2-NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-35-turbo/81.CHIP-CDN-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-35-turbo/1-1.ADE-ADE identification-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-35-turbo/1-2.ADE-ADE relation-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-35-turbo/1-3.ADE-Drug dosage-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-35-turbo/5.BrainMRI-AIS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3151\n",
      " - Missing: 28572\n",
      " - Missing: 28800\n",
      " - Missing: 28940\n",
      " - Missing: 29056\n",
      " - Missing: 29306\n",
      " - Missing: 29355\n",
      " - Missing: 29734\n",
      " - Missing: 29811\n",
      " - Missing: 30060\n",
      " - Missing: 30072\n",
      " - Missing: 30206\n",
      " - Missing: 30267\n",
      " - Missing: 30324\n",
      " - Missing: 30353\n",
      " - Missing: 30996\n",
      " - Missing: 31167\n",
      " - Missing: 31190\n",
      " - Missing: 31258\n",
      " - Missing: 31648\n",
      " - Matched: 3151\n",
      " - Lost 19 samples.\n",
      " - Saved: result_test/6.Brateca.mortality/gpt-35-turbo/6.Brateca.mortality-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3166\n",
      " - Missing: 28771\n",
      " - Missing: 28801\n",
      " - Missing: 29581\n",
      " - Missing: 29604\n",
      " - Missing: 29879\n",
      " - Missing: 29949\n",
      " - Missing: 30014\n",
      " - Missing: 30081\n",
      " - Missing: 30095\n",
      " - Missing: 30293\n",
      " - Missing: 30369\n",
      " - Missing: 30666\n",
      " - Missing: 30815\n",
      " - Missing: 30825\n",
      " - Missing: 31134\n",
      " - Missing: 31615\n",
      " - Missing: 31806\n",
      " - Matched: 3166\n",
      " - Lost 17 samples.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-35-turbo/7.Cantemist.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-35-turbo/7.Cantemist.CODING-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-35-turbo/7.Cantemist.Norm-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-35-turbo/8.CARES.area-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-35-turbo/8.CARES.icd10_block-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-35-turbo/8.CARES.icd10_chapter-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-35-turbo/8.CARES.icd10_sub_block-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-35-turbo/9.CHIP-CDEE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-35-turbo/12.C-EMRS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-35-turbo/19.ClinicalNotes-UPMC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-35-turbo/22.CLIP-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-35-turbo/23.cMedQA-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-35-turbo/26.DialMed-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-35-turbo/28.MIE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-35-turbo/29.EHRQA.primary_department-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-35-turbo/29.EHRQA.qa-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-35-turbo/29.EHRQA.sub_department-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-35-turbo/33.GOUT-CC.consensus-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-35-turbo/33.GOUT-CC.predict-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-35-turbo/43.IMCS-V2-NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-35-turbo/81.CHIP-CDN-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-4o/1-1.ADE-ADE identification-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-4o/1-2.ADE-ADE relation-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3170\n",
      " - Matched: 3170\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.mortality/gpt-4o/6.Brateca.mortality-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-4o/1-3.ADE-Drug dosage-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-4o/5.BrainMRI-AIS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 375\n",
      " - Missing: 23\n",
      " - Missing: 160\n",
      " - Missing: 242\n",
      " - Missing: 262\n",
      " - Missing: 334\n",
      " - Matched: 375\n",
      " - Lost 5 samples.\n",
      " - Saved: result_test/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-35-turbo/101.IFMIR.IncidentType-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-35-turbo/101.IFMIR.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-35-turbo/100.GraSSCo_PHI-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-35-turbo/101.IFMIR.NER_factuality-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-35-turbo/102.iCorpus-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-35-turbo/103.icliniq-10k-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-35-turbo/104.HealthCareMagic-100k-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-35-turbo/82.CHIP-CTC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-35-turbo/83.CHIP-MDCFNPC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-35-turbo/84.MedDG-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-35-turbo/85.IMCS-V2-SR-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-35-turbo/86.IMCS-V2-MRG-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-35-turbo/87.IMCS-V2-DAC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-35-turbo/91-1.CAS.label-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-35-turbo/96.RuCCoN.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-35-turbo/96.RuCCoN.NER_Nor-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-35-turbo/97.CLISTER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-35-turbo/98.BRONCO150.NER_status-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-35-turbo/98.BRONCO150.NER_Nor-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 375\n",
      " - Missing: 23\n",
      " - Missing: 160\n",
      " - Missing: 242\n",
      " - Missing: 262\n",
      " - Missing: 334\n",
      " - Matched: 375\n",
      " - Lost 5 samples.\n",
      " - Saved: result_test/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-35-turbo/101.IFMIR.IncidentType-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-35-turbo/101.IFMIR.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-35-turbo/100.GraSSCo_PHI-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-35-turbo/101.IFMIR.NER_factuality-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-35-turbo/102.iCorpus-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-35-turbo/103.icliniq-10k-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-35-turbo/104.HealthCareMagic-100k-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-4o/1-1.ADE-ADE identification-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-4o/1-2.ADE-ADE relation-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-4o/1-3.ADE-Drug dosage-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-4o/5.BrainMRI-AIS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3170\n",
      " - Matched: 3170\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.mortality/gpt-4o/6.Brateca.mortality-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-4o/7.Cantemist.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-4o/7.Cantemist.CODING-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-4o/7.Cantemist.Norm-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-4o/8.CARES.area-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-4o/8.CARES.icd10_block-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-4o/8.CARES.icd10_chapter-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-4o/8.CARES.icd10_sub_block-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-4o/9.CHIP-CDEE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-4o/12.C-EMRS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-4o/19.ClinicalNotes-UPMC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-4o/22.CLIP-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-4o/23.cMedQA-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-4o/26.DialMed-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-4o/28.MIE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-4o/29.EHRQA.primary_department-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-4o/29.EHRQA.qa-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-4o/29.EHRQA.sub_department-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-4o/31.Ex4CDS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-4o/33.GOUT-CC.consensus-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-4o/33.GOUT-CC.predict-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-4o/43.IMCS-V2-NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-4o/81.CHIP-CDN-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-4o/1-1.ADE-ADE identification-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-4o/1-2.ADE-ADE relation-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-4o/1-3.ADE-Drug dosage-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-4o/5.BrainMRI-AIS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3170\n",
      " - Matched: 3170\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.mortality/gpt-4o/6.Brateca.mortality-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-4o/7.Cantemist.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-4o/7.Cantemist.CODING-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-4o/7.Cantemist.Norm-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-4o/8.CARES.area-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-4o/8.CARES.icd10_block-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-4o/8.CARES.icd10_chapter-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-4o/8.CARES.icd10_sub_block-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-4o/9.CHIP-CDEE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-4o/12.C-EMRS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-4o/19.ClinicalNotes-UPMC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-4o/22.CLIP-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-4o/23.cMedQA-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-4o/26.DialMed-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-4o/28.MIE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-4o/29.EHRQA.primary_department-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-4o/29.EHRQA.qa-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-4o/29.EHRQA.sub_department-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-4o/31.Ex4CDS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-4o/33.GOUT-CC.consensus-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-4o/33.GOUT-CC.predict-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-4o/43.IMCS-V2-NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-4o/81.CHIP-CDN-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-35-turbo/82.CHIP-CTC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-35-turbo/83.CHIP-MDCFNPC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-35-turbo/84.MedDG-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-35-turbo/85.IMCS-V2-SR-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-35-turbo/86.IMCS-V2-MRG-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-35-turbo/87.IMCS-V2-DAC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-35-turbo/91-1.CAS.label-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-35-turbo/96.RuCCoN.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-35-turbo/96.RuCCoN.NER_Nor-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-35-turbo/97.CLISTER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-35-turbo/98.BRONCO150.NER_status-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-35-turbo/98.BRONCO150.NER_Nor-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-4o/7.Cantemist.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-4o/7.Cantemist.CODING-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-4o/7.Cantemist.Norm-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-4o/8.CARES.area-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-4o/8.CARES.icd10_block-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-4o/8.CARES.icd10_chapter-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_chapter\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_chapter/gpt-35-turbo/8.CARES.icd10_chapter-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-35-turbo/12.C-EMRS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-35-turbo/9.CHIP-CDEE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-35-turbo/19.ClinicalNotes-UPMC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-35-turbo/22.CLIP-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-35-turbo/23.cMedQA-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-35-turbo/26.DialMed-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-35-turbo/8.CARES.icd10_sub_block-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-35-turbo/28.MIE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-35-turbo/29.EHRQA.primary_department-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-35-turbo/29.EHRQA.qa-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5191\n",
      " - Missing: 49197\n",
      " - Missing: 51603\n",
      " - Matched: 5191\n",
      " - Lost 2 samples.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-35-turbo/29.EHRQA.sub_department-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-35-turbo/33.GOUT-CC.consensus-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-35-turbo/33.GOUT-CC.predict-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-35-turbo/43.IMCS-V2-NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-35-turbo/81.CHIP-CDN-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-35-turbo/82.CHIP-CTC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-35-turbo/83.CHIP-MDCFNPC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-35-turbo/84.MedDG-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-35-turbo/85.IMCS-V2-SR-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-35-turbo/86.IMCS-V2-MRG-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-35-turbo/87.IMCS-V2-DAC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-35-turbo/91-1.CAS.label-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-35-turbo/96.RuCCoN.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-35-turbo/96.RuCCoN.NER_Nor-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-35-turbo/97.CLISTER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-35-turbo/98.BRONCO150.NER_status-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-35-turbo/98.BRONCO150.NER_Nor-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-35-turbo/100.GraSSCo_PHI-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-35-turbo/101.IFMIR.IncidentType-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-35-turbo/101.IFMIR.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-35-turbo/101.IFMIR.NER_factuality-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-35-turbo/102.iCorpus-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-35-turbo/103.icliniq-10k-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-1.ADE-ADE identification\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2097\n",
      " - Num of batch: 2097\n",
      " - Num of result: 2097\n",
      " - Matched: 2097\n",
      " - All matched.\n",
      " - Saved: result_test/1-1.ADE-ADE identification/gpt-35-turbo/1-1.ADE-ADE identification-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-2.ADE-ADE relation\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 428\n",
      " - Num of batch: 428\n",
      " - Num of result: 428\n",
      " - Matched: 428\n",
      " - All matched.\n",
      " - Saved: result_test/1-2.ADE-ADE relation/gpt-35-turbo/1-2.ADE-ADE relation-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 1-3.ADE-Drug dosage\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 193\n",
      " - Num of batch: 193\n",
      " - Num of result: 193\n",
      " - Matched: 193\n",
      " - All matched.\n",
      " - Saved: result_test/1-3.ADE-Drug dosage/gpt-35-turbo/1-3.ADE-Drug dosage-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 5.BrainMRI-AIS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 303\n",
      " - Num of batch: 303\n",
      " - Num of result: 303\n",
      " - Matched: 303\n",
      " - All matched.\n",
      " - Saved: result_test/5.BrainMRI-AIS/gpt-35-turbo/5.BrainMRI-AIS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_test/99.CARDIO:DE/gpt-4o/99.CARDIO:DE-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-4o/101.IFMIR.IncidentType-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-4o/101.IFMIR.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-4o/100.GraSSCo_PHI-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-4o/101.IFMIR.NER_factuality-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-4o/102.iCorpus-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-4o/103.icliniq-10k-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-4o/104.HealthCareMagic-100k-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-4o/82.CHIP-CTC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-4o/83.CHIP-MDCFNPC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-4o/84.MedDG-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-4o/85.IMCS-V2-SR-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-4o/86.IMCS-V2-MRG-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-4o/87.IMCS-V2-DAC-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-4o/91-1.CAS.label-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-4o/96.RuCCoN.NER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-4o/96.RuCCoN.NER_Nor-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-4o/97.CLISTER-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-4o/98.BRONCO150.NER_status-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-4o/98.BRONCO150.NER_Nor-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 785\n",
      " - Missing: 28643\n",
      " - Missing: 28644\n",
      " - Missing: 28645\n",
      " - Missing: 28646\n",
      " - Missing: 28647\n",
      " - Missing: 28648\n",
      " - Missing: 28651\n",
      " - Missing: 28652\n",
      " - Missing: 28654\n",
      " - Missing: 28656\n",
      " - Missing: 28657\n",
      " - Missing: 28658\n",
      " - Missing: 28659\n",
      " - Missing: 28660\n",
      " - Missing: 28661\n",
      " - Missing: 28662\n",
      " - Missing: 28664\n",
      " - Missing: 28665\n",
      " - Missing: 28666\n",
      " - Missing: 28668\n",
      " - Missing: 28669\n",
      " - Missing: 28670\n",
      " - Missing: 28671\n",
      " - Missing: 28672\n",
      " - Missing: 28674\n",
      " - Missing: 28675\n",
      " - Missing: 28679\n",
      " - Missing: 28680\n",
      " - Missing: 28682\n",
      " - Missing: 28683\n",
      " - Missing: 28684\n",
      " - Missing: 28685\n",
      " - Missing: 28686\n",
      " - Missing: 28687\n",
      " - Missing: 28688\n",
      " - Missing: 28689\n",
      " - Missing: 28690\n",
      " - Missing: 28691\n",
      " - Missing: 28692\n",
      " - Missing: 28695\n",
      " - Missing: 28696\n",
      " - Missing: 28697\n",
      " - Missing: 28698\n",
      " - Missing: 28700\n",
      " - Missing: 28701\n",
      " - Missing: 28702\n",
      " - Missing: 28703\n",
      " - Missing: 28704\n",
      " - Missing: 28706\n",
      " - Missing: 28707\n",
      " - Missing: 28708\n",
      " - Missing: 28709\n",
      " - Missing: 28710\n",
      " - Missing: 28711\n",
      " - Missing: 28712\n",
      " - Missing: 28713\n",
      " - Missing: 28714\n",
      " - Missing: 28715\n",
      " - Missing: 28716\n",
      " - Missing: 28718\n",
      " - Missing: 28720\n",
      " - Missing: 28723\n",
      " - Missing: 28724\n",
      " - Missing: 28725\n",
      " - Missing: 28726\n",
      " - Missing: 28727\n",
      " - Missing: 28728\n",
      " - Missing: 28730\n",
      " - Missing: 28732\n",
      " - Missing: 28733\n",
      " - Missing: 28735\n",
      " - Missing: 28736\n",
      " - Missing: 28737\n",
      " - Missing: 28738\n",
      " - Missing: 28740\n",
      " - Missing: 28743\n",
      " - Missing: 28744\n",
      " - Missing: 28745\n",
      " - Missing: 28746\n",
      " - Missing: 28747\n",
      " - Missing: 28748\n",
      " - Missing: 28750\n",
      " - Missing: 28751\n",
      " - Missing: 28752\n",
      " - Missing: 28753\n",
      " - Missing: 28754\n",
      " - Missing: 28756\n",
      " - Missing: 28757\n",
      " - Missing: 28758\n",
      " - Missing: 28759\n",
      " - Missing: 28760\n",
      " - Missing: 28761\n",
      " - Missing: 28762\n",
      " - Missing: 28764\n",
      " - Missing: 28765\n",
      " - Missing: 28766\n",
      " - Missing: 28767\n",
      " - Missing: 28768\n",
      " - Missing: 28769\n",
      " - Missing: 28770\n",
      " - Missing: 28771\n",
      " - Missing: 28772\n",
      " - Missing: 28773\n",
      " - Missing: 28775\n",
      " - Missing: 28776\n",
      " - Missing: 28778\n",
      " - Missing: 28779\n",
      " - Missing: 28780\n",
      " - Missing: 28782\n",
      " - Missing: 28783\n",
      " - Missing: 28785\n",
      " - Missing: 28786\n",
      " - Missing: 28788\n",
      " - Missing: 28789\n",
      " - Missing: 28790\n",
      " - Missing: 28791\n",
      " - Missing: 28792\n",
      " - Missing: 28793\n",
      " - Missing: 28794\n",
      " - Missing: 28795\n",
      " - Missing: 28796\n",
      " - Missing: 28797\n",
      " - Missing: 28798\n",
      " - Missing: 28799\n",
      " - Missing: 28800\n",
      " - Missing: 28801\n",
      " - Missing: 28802\n",
      " - Missing: 28803\n",
      " - Missing: 28805\n",
      " - Missing: 28806\n",
      " - Missing: 28807\n",
      " - Missing: 28808\n",
      " - Missing: 28810\n",
      " - Missing: 28811\n",
      " - Missing: 28814\n",
      " - Missing: 28815\n",
      " - Missing: 28816\n",
      " - Missing: 28817\n",
      " - Missing: 28818\n",
      " - Missing: 28824\n",
      " - Missing: 28825\n",
      " - Missing: 28826\n",
      " - Missing: 28827\n",
      " - Missing: 28828\n",
      " - Missing: 28830\n",
      " - Missing: 28831\n",
      " - Missing: 28832\n",
      " - Missing: 28833\n",
      " - Missing: 28834\n",
      " - Missing: 28835\n",
      " - Missing: 28836\n",
      " - Missing: 28837\n",
      " - Missing: 28840\n",
      " - Missing: 28841\n",
      " - Missing: 28842\n",
      " - Missing: 28843\n",
      " - Missing: 28844\n",
      " - Missing: 28845\n",
      " - Missing: 28846\n",
      " - Missing: 28847\n",
      " - Missing: 28849\n",
      " - Missing: 28851\n",
      " - Missing: 28853\n",
      " - Missing: 28854\n",
      " - Missing: 28855\n",
      " - Missing: 28856\n",
      " - Missing: 28857\n",
      " - Missing: 28858\n",
      " - Missing: 28860\n",
      " - Missing: 28861\n",
      " - Missing: 28862\n",
      " - Missing: 28863\n",
      " - Missing: 28864\n",
      " - Missing: 28866\n",
      " - Missing: 28867\n",
      " - Missing: 28868\n",
      " - Missing: 28870\n",
      " - Missing: 28872\n",
      " - Missing: 28873\n",
      " - Missing: 28874\n",
      " - Missing: 28875\n",
      " - Missing: 28876\n",
      " - Missing: 28877\n",
      " - Missing: 28878\n",
      " - Missing: 28879\n",
      " - Missing: 28880\n",
      " - Missing: 28881\n",
      " - Missing: 28882\n",
      " - Missing: 28883\n",
      " - Missing: 28884\n",
      " - Missing: 28885\n",
      " - Missing: 28886\n",
      " - Missing: 28888\n",
      " - Missing: 28889\n",
      " - Missing: 28890\n",
      " - Missing: 28891\n",
      " - Missing: 28892\n",
      " - Missing: 28893\n",
      " - Missing: 28894\n",
      " - Missing: 28895\n",
      " - Missing: 28896\n",
      " - Missing: 28897\n",
      " - Missing: 28898\n",
      " - Missing: 28899\n",
      " - Missing: 28900\n",
      " - Missing: 28901\n",
      " - Missing: 28902\n",
      " - Missing: 28903\n",
      " - Missing: 28904\n",
      " - Missing: 28905\n",
      " - Missing: 28907\n",
      " - Missing: 28908\n",
      " - Missing: 28911\n",
      " - Missing: 28912\n",
      " - Missing: 28913\n",
      " - Missing: 28914\n",
      " - Missing: 28915\n",
      " - Missing: 28917\n",
      " - Missing: 28918\n",
      " - Missing: 28919\n",
      " - Missing: 28920\n",
      " - Missing: 28922\n",
      " - Missing: 28923\n",
      " - Missing: 28924\n",
      " - Missing: 28925\n",
      " - Missing: 28926\n",
      " - Missing: 28927\n",
      " - Missing: 28929\n",
      " - Missing: 28930\n",
      " - Missing: 28931\n",
      " - Missing: 28932\n",
      " - Missing: 28933\n",
      " - Missing: 28936\n",
      " - Missing: 28937\n",
      " - Missing: 28938\n",
      " - Missing: 28939\n",
      " - Missing: 28941\n",
      " - Missing: 28942\n",
      " - Missing: 28943\n",
      " - Missing: 28945\n",
      " - Missing: 28946\n",
      " - Missing: 28947\n",
      " - Missing: 28948\n",
      " - Missing: 28949\n",
      " - Missing: 28950\n",
      " - Missing: 28951\n",
      " - Missing: 28952\n",
      " - Missing: 28953\n",
      " - Missing: 28954\n",
      " - Missing: 28955\n",
      " - Missing: 28956\n",
      " - Missing: 28957\n",
      " - Missing: 28958\n",
      " - Missing: 28961\n",
      " - Missing: 28964\n",
      " - Missing: 28965\n",
      " - Missing: 28966\n",
      " - Missing: 28967\n",
      " - Missing: 28969\n",
      " - Missing: 28970\n",
      " - Missing: 28972\n",
      " - Missing: 28973\n",
      " - Missing: 28974\n",
      " - Missing: 28976\n",
      " - Missing: 28977\n",
      " - Missing: 28978\n",
      " - Missing: 28979\n",
      " - Missing: 28980\n",
      " - Missing: 28981\n",
      " - Missing: 28983\n",
      " - Missing: 28984\n",
      " - Missing: 28985\n",
      " - Missing: 28986\n",
      " - Missing: 28987\n",
      " - Missing: 28988\n",
      " - Missing: 28989\n",
      " - Missing: 28990\n",
      " - Missing: 28992\n",
      " - Missing: 28994\n",
      " - Missing: 28995\n",
      " - Missing: 28997\n",
      " - Missing: 28998\n",
      " - Missing: 29001\n",
      " - Missing: 29002\n",
      " - Missing: 29003\n",
      " - Missing: 29004\n",
      " - Missing: 29005\n",
      " - Missing: 29007\n",
      " - Missing: 29008\n",
      " - Missing: 29009\n",
      " - Missing: 29010\n",
      " - Missing: 29011\n",
      " - Missing: 29012\n",
      " - Missing: 29014\n",
      " - Missing: 29015\n",
      " - Missing: 29016\n",
      " - Missing: 29017\n",
      " - Missing: 29018\n",
      " - Missing: 29019\n",
      " - Missing: 29020\n",
      " - Missing: 29021\n",
      " - Missing: 29022\n",
      " - Missing: 29023\n",
      " - Missing: 29024\n",
      " - Missing: 29025\n",
      " - Missing: 29026\n",
      " - Missing: 29027\n",
      " - Missing: 29028\n",
      " - Missing: 29029\n",
      " - Missing: 29032\n",
      " - Missing: 29035\n",
      " - Missing: 29036\n",
      " - Missing: 29037\n",
      " - Missing: 29039\n",
      " - Missing: 29040\n",
      " - Missing: 29041\n",
      " - Missing: 29043\n",
      " - Missing: 29044\n",
      " - Missing: 29045\n",
      " - Missing: 29046\n",
      " - Missing: 29047\n",
      " - Missing: 29048\n",
      " - Missing: 29050\n",
      " - Missing: 29051\n",
      " - Missing: 29052\n",
      " - Missing: 29054\n",
      " - Missing: 29055\n",
      " - Missing: 29056\n",
      " - Missing: 29059\n",
      " - Missing: 29060\n",
      " - Missing: 29061\n",
      " - Missing: 29062\n",
      " - Missing: 29063\n",
      " - Missing: 29064\n",
      " - Missing: 29065\n",
      " - Missing: 29066\n",
      " - Missing: 29067\n",
      " - Missing: 29068\n",
      " - Missing: 29072\n",
      " - Missing: 29073\n",
      " - Missing: 29074\n",
      " - Missing: 29075\n",
      " - Missing: 29076\n",
      " - Missing: 29077\n",
      " - Missing: 29078\n",
      " - Missing: 29080\n",
      " - Missing: 29081\n",
      " - Missing: 29082\n",
      " - Missing: 29083\n",
      " - Missing: 29084\n",
      " - Missing: 29085\n",
      " - Missing: 29086\n",
      " - Missing: 29087\n",
      " - Missing: 29088\n",
      " - Missing: 29089\n",
      " - Missing: 29090\n",
      " - Missing: 29091\n",
      " - Missing: 29092\n",
      " - Missing: 29093\n",
      " - Missing: 29094\n",
      " - Missing: 29095\n",
      " - Missing: 29096\n",
      " - Missing: 29100\n",
      " - Missing: 29101\n",
      " - Missing: 29102\n",
      " - Missing: 29103\n",
      " - Missing: 29105\n",
      " - Missing: 29107\n",
      " - Missing: 29108\n",
      " - Missing: 29109\n",
      " - Missing: 29110\n",
      " - Missing: 29111\n",
      " - Missing: 29112\n",
      " - Missing: 29114\n",
      " - Missing: 29115\n",
      " - Missing: 29116\n",
      " - Missing: 29118\n",
      " - Missing: 29120\n",
      " - Missing: 29122\n",
      " - Missing: 29124\n",
      " - Missing: 29125\n",
      " - Missing: 29126\n",
      " - Missing: 29127\n",
      " - Missing: 29128\n",
      " - Missing: 29129\n",
      " - Missing: 29130\n",
      " - Missing: 29131\n",
      " - Missing: 29132\n",
      " - Missing: 29133\n",
      " - Missing: 29134\n",
      " - Missing: 29135\n",
      " - Missing: 29136\n",
      " - Missing: 29137\n",
      " - Missing: 29139\n",
      " - Missing: 29140\n",
      " - Missing: 29141\n",
      " - Missing: 29142\n",
      " - Missing: 29145\n",
      " - Missing: 29146\n",
      " - Missing: 29151\n",
      " - Missing: 29152\n",
      " - Missing: 29153\n",
      " - Missing: 29154\n",
      " - Missing: 29155\n",
      " - Missing: 29156\n",
      " - Missing: 29158\n",
      " - Missing: 29160\n",
      " - Missing: 29161\n",
      " - Missing: 29162\n",
      " - Missing: 29163\n",
      " - Missing: 29164\n",
      " - Missing: 29166\n",
      " - Missing: 29167\n",
      " - Missing: 29168\n",
      " - Missing: 29170\n",
      " - Missing: 29171\n",
      " - Missing: 29173\n",
      " - Missing: 29176\n",
      " - Missing: 29178\n",
      " - Missing: 29180\n",
      " - Missing: 29181\n",
      " - Missing: 29182\n",
      " - Missing: 29183\n",
      " - Missing: 29184\n",
      " - Missing: 29185\n",
      " - Missing: 29186\n",
      " - Missing: 29191\n",
      " - Missing: 29193\n",
      " - Missing: 29194\n",
      " - Missing: 29195\n",
      " - Missing: 29198\n",
      " - Missing: 29199\n",
      " - Missing: 29200\n",
      " - Missing: 29201\n",
      " - Missing: 29202\n",
      " - Missing: 29204\n",
      " - Missing: 29205\n",
      " - Missing: 29208\n",
      " - Missing: 29209\n",
      " - Missing: 29210\n",
      " - Missing: 29211\n",
      " - Missing: 29213\n",
      " - Missing: 29214\n",
      " - Missing: 29216\n",
      " - Missing: 29218\n",
      " - Missing: 29220\n",
      " - Missing: 29221\n",
      " - Missing: 29222\n",
      " - Missing: 29223\n",
      " - Missing: 29224\n",
      " - Missing: 29225\n",
      " - Missing: 29226\n",
      " - Missing: 29227\n",
      " - Missing: 29228\n",
      " - Missing: 29229\n",
      " - Missing: 29233\n",
      " - Missing: 29234\n",
      " - Missing: 29235\n",
      " - Missing: 29236\n",
      " - Missing: 29239\n",
      " - Missing: 29241\n",
      " - Missing: 29243\n",
      " - Missing: 29246\n",
      " - Missing: 29248\n",
      " - Missing: 29249\n",
      " - Missing: 29250\n",
      " - Missing: 29252\n",
      " - Missing: 29253\n",
      " - Missing: 29254\n",
      " - Missing: 29255\n",
      " - Missing: 29256\n",
      " - Missing: 29258\n",
      " - Missing: 29259\n",
      " - Missing: 29260\n",
      " - Missing: 29261\n",
      " - Missing: 29262\n",
      " - Missing: 29265\n",
      " - Missing: 29266\n",
      " - Missing: 29267\n",
      " - Missing: 29268\n",
      " - Missing: 29269\n",
      " - Missing: 29270\n",
      " - Missing: 29271\n",
      " - Missing: 29272\n",
      " - Missing: 29273\n",
      " - Missing: 29274\n",
      " - Missing: 29275\n",
      " - Missing: 29276\n",
      " - Missing: 29277\n",
      " - Missing: 29278\n",
      " - Missing: 29282\n",
      " - Missing: 29283\n",
      " - Missing: 29284\n",
      " - Missing: 29285\n",
      " - Missing: 29286\n",
      " - Missing: 29287\n",
      " - Missing: 29289\n",
      " - Missing: 29290\n",
      " - Missing: 29292\n",
      " - Missing: 29294\n",
      " - Missing: 29296\n",
      " - Missing: 29297\n",
      " - Missing: 29298\n",
      " - Missing: 29299\n",
      " - Missing: 29301\n",
      " - Missing: 29302\n",
      " - Missing: 29303\n",
      " - Missing: 29305\n",
      " - Missing: 29306\n",
      " - Missing: 29308\n",
      " - Missing: 29310\n",
      " - Missing: 29311\n",
      " - Missing: 29314\n",
      " - Missing: 29316\n",
      " - Missing: 29318\n",
      " - Missing: 29319\n",
      " - Missing: 29320\n",
      " - Missing: 29321\n",
      " - Missing: 29322\n",
      " - Missing: 29323\n",
      " - Missing: 29324\n",
      " - Missing: 29325\n",
      " - Missing: 29326\n",
      " - Missing: 29327\n",
      " - Missing: 29328\n",
      " - Missing: 29329\n",
      " - Missing: 29334\n",
      " - Missing: 29335\n",
      " - Missing: 29336\n",
      " - Missing: 29338\n",
      " - Missing: 29339\n",
      " - Missing: 29341\n",
      " - Missing: 29342\n",
      " - Missing: 29343\n",
      " - Missing: 29344\n",
      " - Missing: 29345\n",
      " - Missing: 29347\n",
      " - Missing: 29348\n",
      " - Missing: 29349\n",
      " - Missing: 29350\n",
      " - Missing: 29351\n",
      " - Missing: 29352\n",
      " - Missing: 29353\n",
      " - Missing: 29354\n",
      " - Missing: 29357\n",
      " - Missing: 29358\n",
      " - Missing: 29359\n",
      " - Missing: 29362\n",
      " - Missing: 29363\n",
      " - Missing: 29365\n",
      " - Missing: 29366\n",
      " - Missing: 29367\n",
      " - Missing: 29369\n",
      " - Missing: 29372\n",
      " - Missing: 29374\n",
      " - Missing: 29377\n",
      " - Missing: 29378\n",
      " - Missing: 29379\n",
      " - Missing: 29380\n",
      " - Missing: 29381\n",
      " - Missing: 29382\n",
      " - Missing: 29383\n",
      " - Missing: 29384\n",
      " - Missing: 29385\n",
      " - Missing: 29387\n",
      " - Missing: 29388\n",
      " - Missing: 29389\n",
      " - Missing: 29390\n",
      " - Missing: 29391\n",
      " - Missing: 29392\n",
      " - Missing: 29393\n",
      " - Missing: 29394\n",
      " - Missing: 29395\n",
      " - Missing: 29396\n",
      " - Missing: 29397\n",
      " - Missing: 29398\n",
      " - Missing: 29399\n",
      " - Missing: 29400\n",
      " - Missing: 29401\n",
      " - Missing: 29402\n",
      " - Missing: 29403\n",
      " - Missing: 29405\n",
      " - Missing: 29406\n",
      " - Missing: 29407\n",
      " - Missing: 29409\n",
      " - Missing: 29411\n",
      " - Missing: 29412\n",
      " - Missing: 29415\n",
      " - Missing: 29417\n",
      " - Missing: 29419\n",
      " - Missing: 29422\n",
      " - Missing: 29423\n",
      " - Missing: 29425\n",
      " - Missing: 29426\n",
      " - Missing: 29427\n",
      " - Missing: 29430\n",
      " - Missing: 29431\n",
      " - Missing: 29432\n",
      " - Missing: 29436\n",
      " - Missing: 29438\n",
      " - Missing: 29440\n",
      " - Missing: 29443\n",
      " - Missing: 29444\n",
      " - Missing: 29446\n",
      " - Missing: 29447\n",
      " - Missing: 29449\n",
      " - Missing: 29451\n",
      " - Missing: 29453\n",
      " - Missing: 29454\n",
      " - Missing: 29455\n",
      " - Missing: 29457\n",
      " - Missing: 29459\n",
      " - Missing: 29460\n",
      " - Missing: 29461\n",
      " - Missing: 29464\n",
      " - Missing: 29465\n",
      " - Missing: 29466\n",
      " - Missing: 29467\n",
      " - Missing: 29468\n",
      " - Missing: 29471\n",
      " - Missing: 29474\n",
      " - Missing: 29475\n",
      " - Missing: 29476\n",
      " - Missing: 29477\n",
      " - Missing: 29478\n",
      " - Missing: 29479\n",
      " - Missing: 29481\n",
      " - Missing: 29482\n",
      " - Missing: 29483\n",
      " - Missing: 29484\n",
      " - Missing: 29485\n",
      " - Missing: 29486\n",
      " - Missing: 29488\n",
      " - Missing: 29489\n",
      " - Missing: 29492\n",
      " - Missing: 29493\n",
      " - Missing: 29495\n",
      " - Missing: 29497\n",
      " - Missing: 29498\n",
      " - Missing: 29499\n",
      " - Missing: 29500\n",
      " - Missing: 29501\n",
      " - Missing: 29503\n",
      " - Missing: 29504\n",
      " - Missing: 29505\n",
      " - Missing: 29506\n",
      " - Missing: 29507\n",
      " - Missing: 29509\n",
      " - Missing: 29510\n",
      " - Missing: 29511\n",
      " - Missing: 29513\n",
      " - Missing: 29514\n",
      " - Missing: 29515\n",
      " - Missing: 29517\n",
      " - Missing: 29518\n",
      " - Missing: 29521\n",
      " - Missing: 29523\n",
      " - Missing: 29525\n",
      " - Missing: 29526\n",
      " - Missing: 29527\n",
      " - Missing: 29528\n",
      " - Missing: 29531\n",
      " - Missing: 29532\n",
      " - Missing: 29534\n",
      " - Missing: 29537\n",
      " - Missing: 29538\n",
      " - Missing: 29539\n",
      " - Missing: 29540\n",
      " - Missing: 29541\n",
      " - Missing: 29542\n",
      " - Missing: 29543\n",
      " - Missing: 29544\n",
      " - Missing: 29545\n",
      " - Missing: 29546\n",
      " - Missing: 29548\n",
      " - Missing: 29549\n",
      " - Missing: 29551\n",
      " - Missing: 29552\n",
      " - Missing: 29553\n",
      " - Missing: 29555\n",
      " - Missing: 29556\n",
      " - Missing: 29557\n",
      " - Missing: 29560\n",
      " - Missing: 29561\n",
      " - Missing: 29562\n",
      " - Missing: 29563\n",
      " - Missing: 29564\n",
      " - Missing: 29565\n",
      " - Missing: 29566\n",
      " - Missing: 29568\n",
      " - Missing: 29569\n",
      " - Missing: 29570\n",
      " - Missing: 29571\n",
      " - Missing: 29574\n",
      " - Missing: 29575\n",
      " - Missing: 29576\n",
      " - Missing: 29578\n",
      " - Missing: 29579\n",
      " - Missing: 29580\n",
      " - Missing: 29581\n",
      " - Missing: 29582\n",
      " - Missing: 29583\n",
      " - Missing: 29584\n",
      " - Missing: 29585\n",
      " - Missing: 29586\n",
      " - Missing: 29587\n",
      " - Missing: 29588\n",
      " - Missing: 29590\n",
      " - Missing: 29592\n",
      " - Missing: 29594\n",
      " - Missing: 29595\n",
      " - Missing: 29596\n",
      " - Missing: 29597\n",
      " - Missing: 29598\n",
      " - Missing: 29601\n",
      " - Missing: 29602\n",
      " - Missing: 29603\n",
      " - Missing: 29604\n",
      " - Missing: 29607\n",
      " - Missing: 29608\n",
      " - Missing: 29609\n",
      " - Missing: 29610\n",
      " - Missing: 29611\n",
      " - Missing: 29612\n",
      " - Missing: 29613\n",
      " - Missing: 29614\n",
      " - Missing: 29615\n",
      " - Missing: 29616\n",
      " - Missing: 29618\n",
      " - Missing: 29619\n",
      " - Missing: 29621\n",
      " - Missing: 29622\n",
      " - Missing: 29623\n",
      " - Missing: 29624\n",
      " - Missing: 29627\n",
      " - Missing: 29628\n",
      " - Missing: 29629\n",
      " - Missing: 29630\n",
      " - Missing: 29631\n",
      " - Missing: 29633\n",
      " - Missing: 29634\n",
      " - Missing: 29636\n",
      " - Missing: 29639\n",
      " - Missing: 29640\n",
      " - Missing: 29641\n",
      " - Missing: 29645\n",
      " - Missing: 29646\n",
      " - Missing: 29647\n",
      " - Missing: 29649\n",
      " - Missing: 29650\n",
      " - Missing: 29651\n",
      " - Missing: 29652\n",
      " - Missing: 29654\n",
      " - Missing: 29655\n",
      " - Missing: 29656\n",
      " - Missing: 29657\n",
      " - Missing: 29658\n",
      " - Missing: 29660\n",
      " - Missing: 29661\n",
      " - Missing: 29663\n",
      " - Missing: 29666\n",
      " - Missing: 29667\n",
      " - Missing: 29668\n",
      " - Missing: 29669\n",
      " - Missing: 29670\n",
      " - Missing: 29671\n",
      " - Missing: 29672\n",
      " - Missing: 29673\n",
      " - Missing: 29674\n",
      " - Missing: 29675\n",
      " - Missing: 29676\n",
      " - Missing: 29677\n",
      " - Missing: 29678\n",
      " - Missing: 29680\n",
      " - Missing: 29683\n",
      " - Missing: 29684\n",
      " - Missing: 29687\n",
      " - Missing: 29688\n",
      " - Missing: 29689\n",
      " - Missing: 29690\n",
      " - Missing: 29692\n",
      " - Missing: 29693\n",
      " - Missing: 29694\n",
      " - Missing: 29695\n",
      " - Missing: 29696\n",
      " - Missing: 29697\n",
      " - Missing: 29698\n",
      " - Missing: 29700\n",
      " - Missing: 29702\n",
      " - Missing: 29703\n",
      " - Missing: 29705\n",
      " - Missing: 29706\n",
      " - Missing: 29707\n",
      " - Missing: 29708\n",
      " - Missing: 29709\n",
      " - Missing: 29710\n",
      " - Missing: 29712\n",
      " - Missing: 29713\n",
      " - Missing: 29714\n",
      " - Missing: 29715\n",
      " - Missing: 29717\n",
      " - Missing: 29718\n",
      " - Missing: 29719\n",
      " - Missing: 29722\n",
      " - Missing: 29723\n",
      " - Missing: 29724\n",
      " - Missing: 29725\n",
      " - Missing: 29726\n",
      " - Missing: 29729\n",
      " - Missing: 29730\n",
      " - Missing: 29731\n",
      " - Missing: 29732\n",
      " - Missing: 29733\n",
      " - Missing: 29734\n",
      " - Missing: 29735\n",
      " - Missing: 29736\n",
      " - Missing: 29737\n",
      " - Missing: 29738\n",
      " - Missing: 29739\n",
      " - Missing: 29740\n",
      " - Missing: 29742\n",
      " - Missing: 29743\n",
      " - Missing: 29744\n",
      " - Missing: 29745\n",
      " - Missing: 29746\n",
      " - Missing: 29749\n",
      " - Missing: 29751\n",
      " - Missing: 29752\n",
      " - Missing: 29754\n",
      " - Missing: 29755\n",
      " - Missing: 29756\n",
      " - Missing: 29757\n",
      " - Missing: 29758\n",
      " - Missing: 29760\n",
      " - Missing: 29761\n",
      " - Missing: 29762\n",
      " - Missing: 29763\n",
      " - Missing: 29764\n",
      " - Missing: 29765\n",
      " - Missing: 29766\n",
      " - Missing: 29767\n",
      " - Missing: 29768\n",
      " - Missing: 29769\n",
      " - Missing: 29772\n",
      " - Missing: 29775\n",
      " - Missing: 29776\n",
      " - Missing: 29777\n",
      " - Missing: 29779\n",
      " - Missing: 29780\n",
      " - Missing: 29782\n",
      " - Missing: 29783\n",
      " - Missing: 29785\n",
      " - Missing: 29786\n",
      " - Missing: 29789\n",
      " - Missing: 29790\n",
      " - Missing: 29792\n",
      " - Missing: 29793\n",
      " - Missing: 29795\n",
      " - Missing: 29796\n",
      " - Missing: 29797\n",
      " - Missing: 29799\n",
      " - Missing: 29800\n",
      " - Missing: 29801\n",
      " - Missing: 29803\n",
      " - Missing: 29805\n",
      " - Missing: 29806\n",
      " - Missing: 29807\n",
      " - Missing: 29808\n",
      " - Missing: 29811\n",
      " - Missing: 29813\n",
      " - Missing: 29814\n",
      " - Missing: 29816\n",
      " - Missing: 29819\n",
      " - Missing: 29820\n",
      " - Missing: 29822\n",
      " - Missing: 29823\n",
      " - Missing: 29825\n",
      " - Missing: 29826\n",
      " - Missing: 29827\n",
      " - Missing: 29828\n",
      " - Missing: 29829\n",
      " - Missing: 29830\n",
      " - Missing: 29831\n",
      " - Missing: 29832\n",
      " - Missing: 29833\n",
      " - Missing: 29834\n",
      " - Missing: 29835\n",
      " - Missing: 29836\n",
      " - Missing: 29837\n",
      " - Missing: 29839\n",
      " - Missing: 29842\n",
      " - Missing: 29843\n",
      " - Missing: 29844\n",
      " - Missing: 29845\n",
      " - Missing: 29846\n",
      " - Missing: 29847\n",
      " - Missing: 29848\n",
      " - Missing: 29849\n",
      " - Missing: 29850\n",
      " - Missing: 29851\n",
      " - Missing: 29852\n",
      " - Missing: 29853\n",
      " - Missing: 29854\n",
      " - Missing: 29855\n",
      " - Missing: 29857\n",
      " - Missing: 29860\n",
      " - Missing: 29861\n",
      " - Missing: 29862\n",
      " - Missing: 29863\n",
      " - Missing: 29864\n",
      " - Missing: 29866\n",
      " - Missing: 29868\n",
      " - Missing: 29869\n",
      " - Missing: 29870\n",
      " - Missing: 29871\n",
      " - Missing: 29872\n",
      " - Missing: 29873\n",
      " - Missing: 29874\n",
      " - Missing: 29875\n",
      " - Missing: 29876\n",
      " - Missing: 29877\n",
      " - Missing: 29878\n",
      " - Missing: 29879\n",
      " - Missing: 29881\n",
      " - Missing: 29884\n",
      " - Missing: 29887\n",
      " - Missing: 29888\n",
      " - Missing: 29890\n",
      " - Missing: 29891\n",
      " - Missing: 29894\n",
      " - Missing: 29895\n",
      " - Missing: 29896\n",
      " - Missing: 29897\n",
      " - Missing: 29898\n",
      " - Missing: 29899\n",
      " - Missing: 29900\n",
      " - Missing: 29901\n",
      " - Missing: 29902\n",
      " - Missing: 29905\n",
      " - Missing: 29906\n",
      " - Missing: 29908\n",
      " - Missing: 29909\n",
      " - Missing: 29910\n",
      " - Missing: 29911\n",
      " - Missing: 29913\n",
      " - Missing: 29914\n",
      " - Missing: 29915\n",
      " - Missing: 29916\n",
      " - Missing: 29917\n",
      " - Missing: 29918\n",
      " - Missing: 29919\n",
      " - Missing: 29920\n",
      " - Missing: 29921\n",
      " - Missing: 29923\n",
      " - Missing: 29925\n",
      " - Missing: 29926\n",
      " - Missing: 29927\n",
      " - Missing: 29929\n",
      " - Missing: 29930\n",
      " - Missing: 29931\n",
      " - Missing: 29932\n",
      " - Missing: 29933\n",
      " - Missing: 29936\n",
      " - Missing: 29939\n",
      " - Missing: 29940\n",
      " - Missing: 29942\n",
      " - Missing: 29944\n",
      " - Missing: 29946\n",
      " - Missing: 29947\n",
      " - Missing: 29949\n",
      " - Missing: 29950\n",
      " - Missing: 29951\n",
      " - Missing: 29953\n",
      " - Missing: 29955\n",
      " - Missing: 29957\n",
      " - Missing: 29958\n",
      " - Missing: 29960\n",
      " - Missing: 29961\n",
      " - Missing: 29962\n",
      " - Missing: 29964\n",
      " - Missing: 29966\n",
      " - Missing: 29967\n",
      " - Missing: 29968\n",
      " - Missing: 29969\n",
      " - Missing: 29970\n",
      " - Missing: 29971\n",
      " - Missing: 29972\n",
      " - Missing: 29973\n",
      " - Missing: 29974\n",
      " - Missing: 29975\n",
      " - Missing: 29976\n",
      " - Missing: 29977\n",
      " - Missing: 29978\n",
      " - Missing: 29980\n",
      " - Missing: 29981\n",
      " - Missing: 29982\n",
      " - Missing: 29987\n",
      " - Missing: 29988\n",
      " - Missing: 29989\n",
      " - Missing: 29990\n",
      " - Missing: 29991\n",
      " - Missing: 29992\n",
      " - Missing: 29993\n",
      " - Missing: 29994\n",
      " - Missing: 29995\n",
      " - Missing: 29996\n",
      " - Missing: 29997\n",
      " - Missing: 29998\n",
      " - Missing: 30000\n",
      " - Missing: 30002\n",
      " - Missing: 30003\n",
      " - Missing: 30004\n",
      " - Missing: 30005\n",
      " - Missing: 30006\n",
      " - Missing: 30007\n",
      " - Missing: 30009\n",
      " - Missing: 30010\n",
      " - Missing: 30011\n",
      " - Missing: 30012\n",
      " - Missing: 30014\n",
      " - Missing: 30015\n",
      " - Missing: 30016\n",
      " - Missing: 30021\n",
      " - Missing: 30022\n",
      " - Missing: 30023\n",
      " - Missing: 30024\n",
      " - Missing: 30025\n",
      " - Missing: 30026\n",
      " - Missing: 30027\n",
      " - Missing: 30028\n",
      " - Missing: 30029\n",
      " - Missing: 30030\n",
      " - Missing: 30031\n",
      " - Missing: 30032\n",
      " - Missing: 30033\n",
      " - Missing: 30034\n",
      " - Missing: 30036\n",
      " - Missing: 30037\n",
      " - Missing: 30038\n",
      " - Missing: 30039\n",
      " - Missing: 30040\n",
      " - Missing: 30041\n",
      " - Missing: 30042\n",
      " - Missing: 30043\n",
      " - Missing: 30044\n",
      " - Missing: 30045\n",
      " - Missing: 30048\n",
      " - Missing: 30049\n",
      " - Missing: 30050\n",
      " - Missing: 30051\n",
      " - Missing: 30055\n",
      " - Missing: 30056\n",
      " - Missing: 30059\n",
      " - Missing: 30061\n",
      " - Missing: 30062\n",
      " - Missing: 30063\n",
      " - Missing: 30064\n",
      " - Missing: 30065\n",
      " - Missing: 30067\n",
      " - Missing: 30068\n",
      " - Missing: 30070\n",
      " - Missing: 30071\n",
      " - Missing: 30072\n",
      " - Missing: 30074\n",
      " - Missing: 30075\n",
      " - Missing: 30076\n",
      " - Missing: 30077\n",
      " - Missing: 30078\n",
      " - Missing: 30079\n",
      " - Missing: 30080\n",
      " - Missing: 30081\n",
      " - Missing: 30083\n",
      " - Missing: 30084\n",
      " - Missing: 30085\n",
      " - Missing: 30086\n",
      " - Missing: 30087\n",
      " - Missing: 30089\n",
      " - Missing: 30090\n",
      " - Missing: 30091\n",
      " - Missing: 30092\n",
      " - Missing: 30093\n",
      " - Missing: 30094\n",
      " - Missing: 30095\n",
      " - Missing: 30096\n",
      " - Missing: 30098\n",
      " - Missing: 30099\n",
      " - Missing: 30100\n",
      " - Missing: 30101\n",
      " - Missing: 30102\n",
      " - Missing: 30104\n",
      " - Missing: 30105\n",
      " - Missing: 30106\n",
      " - Missing: 30109\n",
      " - Missing: 30110\n",
      " - Missing: 30111\n",
      " - Missing: 30113\n",
      " - Missing: 30114\n",
      " - Missing: 30116\n",
      " - Missing: 30117\n",
      " - Missing: 30118\n",
      " - Missing: 30119\n",
      " - Missing: 30121\n",
      " - Missing: 30124\n",
      " - Missing: 30127\n",
      " - Missing: 30130\n",
      " - Missing: 30131\n",
      " - Missing: 30132\n",
      " - Missing: 30133\n",
      " - Missing: 30135\n",
      " - Missing: 30137\n",
      " - Missing: 30138\n",
      " - Missing: 30140\n",
      " - Missing: 30141\n",
      " - Missing: 30142\n",
      " - Missing: 30143\n",
      " - Missing: 30144\n",
      " - Missing: 30145\n",
      " - Missing: 30146\n",
      " - Missing: 30147\n",
      " - Missing: 30149\n",
      " - Missing: 30151\n",
      " - Missing: 30153\n",
      " - Missing: 30155\n",
      " - Missing: 30157\n",
      " - Missing: 30158\n",
      " - Missing: 30163\n",
      " - Missing: 30164\n",
      " - Missing: 30165\n",
      " - Missing: 30167\n",
      " - Missing: 30168\n",
      " - Missing: 30169\n",
      " - Missing: 30170\n",
      " - Missing: 30171\n",
      " - Missing: 30172\n",
      " - Missing: 30173\n",
      " - Missing: 30174\n",
      " - Missing: 30175\n",
      " - Missing: 30176\n",
      " - Missing: 30180\n",
      " - Missing: 30182\n",
      " - Missing: 30183\n",
      " - Missing: 30184\n",
      " - Missing: 30188\n",
      " - Missing: 30190\n",
      " - Missing: 30193\n",
      " - Missing: 30195\n",
      " - Missing: 30196\n",
      " - Missing: 30197\n",
      " - Missing: 30199\n",
      " - Missing: 30200\n",
      " - Missing: 30202\n",
      " - Missing: 30204\n",
      " - Missing: 30206\n",
      " - Missing: 30207\n",
      " - Missing: 30209\n",
      " - Missing: 30210\n",
      " - Missing: 30211\n",
      " - Missing: 30212\n",
      " - Missing: 30213\n",
      " - Missing: 30215\n",
      " - Missing: 30216\n",
      " - Missing: 30217\n",
      " - Missing: 30218\n",
      " - Missing: 30219\n",
      " - Missing: 30220\n",
      " - Missing: 30221\n",
      " - Missing: 30222\n",
      " - Missing: 30223\n",
      " - Missing: 30224\n",
      " - Missing: 30225\n",
      " - Missing: 30226\n",
      " - Missing: 30227\n",
      " - Missing: 30228\n",
      " - Missing: 30229\n",
      " - Missing: 30230\n",
      " - Missing: 30231\n",
      " - Missing: 30233\n",
      " - Missing: 30234\n",
      " - Missing: 30236\n",
      " - Missing: 30237\n",
      " - Missing: 30238\n",
      " - Missing: 30239\n",
      " - Missing: 30240\n",
      " - Missing: 30241\n",
      " - Missing: 30242\n",
      " - Missing: 30244\n",
      " - Missing: 30245\n",
      " - Missing: 30246\n",
      " - Missing: 30247\n",
      " - Missing: 30248\n",
      " - Missing: 30249\n",
      " - Missing: 30250\n",
      " - Missing: 30251\n",
      " - Missing: 30253\n",
      " - Missing: 30254\n",
      " - Missing: 30256\n",
      " - Missing: 30257\n",
      " - Missing: 30258\n",
      " - Missing: 30259\n",
      " - Missing: 30260\n",
      " - Missing: 30261\n",
      " - Missing: 30262\n",
      " - Missing: 30263\n",
      " - Missing: 30264\n",
      " - Missing: 30266\n",
      " - Missing: 30267\n",
      " - Missing: 30269\n",
      " - Missing: 30270\n",
      " - Missing: 30272\n",
      " - Missing: 30273\n",
      " - Missing: 30274\n",
      " - Missing: 30275\n",
      " - Missing: 30276\n",
      " - Missing: 30278\n",
      " - Missing: 30279\n",
      " - Missing: 30282\n",
      " - Missing: 30283\n",
      " - Missing: 30284\n",
      " - Missing: 30285\n",
      " - Missing: 30286\n",
      " - Missing: 30288\n",
      " - Missing: 30291\n",
      " - Missing: 30292\n",
      " - Missing: 30293\n",
      " - Missing: 30295\n",
      " - Missing: 30296\n",
      " - Missing: 30297\n",
      " - Missing: 30298\n",
      " - Missing: 30300\n",
      " - Missing: 30301\n",
      " - Missing: 30302\n",
      " - Missing: 30304\n",
      " - Missing: 30306\n",
      " - Missing: 30307\n",
      " - Missing: 30308\n",
      " - Missing: 30311\n",
      " - Missing: 30312\n",
      " - Missing: 30313\n",
      " - Missing: 30314\n",
      " - Missing: 30315\n",
      " - Missing: 30317\n",
      " - Missing: 30318\n",
      " - Missing: 30319\n",
      " - Missing: 30322\n",
      " - Missing: 30323\n",
      " - Missing: 30326\n",
      " - Missing: 30328\n",
      " - Missing: 30329\n",
      " - Missing: 30330\n",
      " - Missing: 30331\n",
      " - Missing: 30332\n",
      " - Missing: 30333\n",
      " - Missing: 30334\n",
      " - Missing: 30335\n",
      " - Missing: 30336\n",
      " - Missing: 30337\n",
      " - Missing: 30338\n",
      " - Missing: 30339\n",
      " - Missing: 30340\n",
      " - Missing: 30341\n",
      " - Missing: 30342\n",
      " - Missing: 30345\n",
      " - Missing: 30346\n",
      " - Missing: 30347\n",
      " - Missing: 30349\n",
      " - Missing: 30350\n",
      " - Missing: 30351\n",
      " - Missing: 30353\n",
      " - Missing: 30354\n",
      " - Missing: 30356\n",
      " - Missing: 30357\n",
      " - Missing: 30358\n",
      " - Missing: 30360\n",
      " - Missing: 30364\n",
      " - Missing: 30365\n",
      " - Missing: 30366\n",
      " - Missing: 30367\n",
      " - Missing: 30368\n",
      " - Missing: 30369\n",
      " - Missing: 30373\n",
      " - Missing: 30374\n",
      " - Missing: 30375\n",
      " - Missing: 30378\n",
      " - Missing: 30381\n",
      " - Missing: 30382\n",
      " - Missing: 30383\n",
      " - Missing: 30384\n",
      " - Missing: 30385\n",
      " - Missing: 30386\n",
      " - Missing: 30388\n",
      " - Missing: 30389\n",
      " - Missing: 30390\n",
      " - Missing: 30391\n",
      " - Missing: 30392\n",
      " - Missing: 30393\n",
      " - Missing: 30396\n",
      " - Missing: 30397\n",
      " - Missing: 30400\n",
      " - Missing: 30402\n",
      " - Missing: 30403\n",
      " - Missing: 30405\n",
      " - Missing: 30406\n",
      " - Missing: 30407\n",
      " - Missing: 30409\n",
      " - Missing: 30410\n",
      " - Missing: 30411\n",
      " - Missing: 30412\n",
      " - Missing: 30413\n",
      " - Missing: 30414\n",
      " - Missing: 30415\n",
      " - Missing: 30416\n",
      " - Missing: 30417\n",
      " - Missing: 30418\n",
      " - Missing: 30420\n",
      " - Missing: 30421\n",
      " - Missing: 30422\n",
      " - Missing: 30425\n",
      " - Missing: 30426\n",
      " - Missing: 30427\n",
      " - Missing: 30428\n",
      " - Missing: 30429\n",
      " - Missing: 30430\n",
      " - Missing: 30432\n",
      " - Missing: 30433\n",
      " - Missing: 30434\n",
      " - Missing: 30436\n",
      " - Missing: 30437\n",
      " - Missing: 30438\n",
      " - Missing: 30439\n",
      " - Missing: 30440\n",
      " - Missing: 30441\n",
      " - Missing: 30443\n",
      " - Missing: 30444\n",
      " - Missing: 30445\n",
      " - Missing: 30446\n",
      " - Missing: 30447\n",
      " - Missing: 30449\n",
      " - Missing: 30451\n",
      " - Missing: 30452\n",
      " - Missing: 30455\n",
      " - Missing: 30457\n",
      " - Missing: 30458\n",
      " - Missing: 30459\n",
      " - Missing: 30461\n",
      " - Missing: 30462\n",
      " - Missing: 30463\n",
      " - Missing: 30465\n",
      " - Missing: 30466\n",
      " - Missing: 30467\n",
      " - Missing: 30468\n",
      " - Missing: 30469\n",
      " - Missing: 30470\n",
      " - Missing: 30471\n",
      " - Missing: 30472\n",
      " - Missing: 30473\n",
      " - Missing: 30474\n",
      " - Missing: 30475\n",
      " - Missing: 30476\n",
      " - Missing: 30478\n",
      " - Missing: 30479\n",
      " - Missing: 30481\n",
      " - Missing: 30483\n",
      " - Missing: 30484\n",
      " - Missing: 30485\n",
      " - Missing: 30487\n",
      " - Missing: 30488\n",
      " - Missing: 30490\n",
      " - Missing: 30491\n",
      " - Missing: 30492\n",
      " - Missing: 30493\n",
      " - Missing: 30494\n",
      " - Missing: 30495\n",
      " - Missing: 30496\n",
      " - Missing: 30497\n",
      " - Missing: 30498\n",
      " - Missing: 30499\n",
      " - Missing: 30500\n",
      " - Missing: 30501\n",
      " - Missing: 30502\n",
      " - Missing: 30503\n",
      " - Missing: 30506\n",
      " - Missing: 30507\n",
      " - Missing: 30511\n",
      " - Missing: 30512\n",
      " - Missing: 30513\n",
      " - Missing: 30514\n",
      " - Missing: 30516\n",
      " - Missing: 30517\n",
      " - Missing: 30518\n",
      " - Missing: 30519\n",
      " - Missing: 30520\n",
      " - Missing: 30521\n",
      " - Missing: 30522\n",
      " - Missing: 30523\n",
      " - Missing: 30524\n",
      " - Missing: 30526\n",
      " - Missing: 30527\n",
      " - Missing: 30528\n",
      " - Missing: 30529\n",
      " - Missing: 30530\n",
      " - Missing: 30531\n",
      " - Missing: 30532\n",
      " - Missing: 30533\n",
      " - Missing: 30535\n",
      " - Missing: 30537\n",
      " - Missing: 30538\n",
      " - Missing: 30539\n",
      " - Missing: 30541\n",
      " - Missing: 30542\n",
      " - Missing: 30543\n",
      " - Missing: 30544\n",
      " - Missing: 30545\n",
      " - Missing: 30546\n",
      " - Missing: 30547\n",
      " - Missing: 30548\n",
      " - Missing: 30549\n",
      " - Missing: 30550\n",
      " - Missing: 30551\n",
      " - Missing: 30552\n",
      " - Missing: 30553\n",
      " - Missing: 30554\n",
      " - Missing: 30555\n",
      " - Missing: 30556\n",
      " - Missing: 30557\n",
      " - Missing: 30558\n",
      " - Missing: 30560\n",
      " - Missing: 30561\n",
      " - Missing: 30562\n",
      " - Missing: 30564\n",
      " - Missing: 30565\n",
      " - Missing: 30567\n",
      " - Missing: 30568\n",
      " - Missing: 30570\n",
      " - Missing: 30571\n",
      " - Missing: 30572\n",
      " - Missing: 30574\n",
      " - Missing: 30577\n",
      " - Missing: 30578\n",
      " - Missing: 30579\n",
      " - Missing: 30580\n",
      " - Missing: 30581\n",
      " - Missing: 30582\n",
      " - Missing: 30584\n",
      " - Missing: 30585\n",
      " - Missing: 30586\n",
      " - Missing: 30587\n",
      " - Missing: 30588\n",
      " - Missing: 30589\n",
      " - Missing: 30590\n",
      " - Missing: 30591\n",
      " - Missing: 30592\n",
      " - Missing: 30595\n",
      " - Missing: 30596\n",
      " - Missing: 30597\n",
      " - Missing: 30599\n",
      " - Missing: 30601\n",
      " - Missing: 30603\n",
      " - Missing: 30604\n",
      " - Missing: 30605\n",
      " - Missing: 30606\n",
      " - Missing: 30607\n",
      " - Missing: 30608\n",
      " - Missing: 30609\n",
      " - Missing: 30610\n",
      " - Missing: 30611\n",
      " - Missing: 30612\n",
      " - Missing: 30613\n",
      " - Missing: 30614\n",
      " - Missing: 30617\n",
      " - Missing: 30620\n",
      " - Missing: 30622\n",
      " - Missing: 30623\n",
      " - Missing: 30624\n",
      " - Missing: 30625\n",
      " - Missing: 30626\n",
      " - Missing: 30628\n",
      " - Missing: 30629\n",
      " - Missing: 30631\n",
      " - Missing: 30632\n",
      " - Missing: 30633\n",
      " - Missing: 30634\n",
      " - Missing: 30635\n",
      " - Missing: 30636\n",
      " - Missing: 30637\n",
      " - Missing: 30639\n",
      " - Missing: 30640\n",
      " - Missing: 30641\n",
      " - Missing: 30642\n",
      " - Missing: 30643\n",
      " - Missing: 30644\n",
      " - Missing: 30645\n",
      " - Missing: 30646\n",
      " - Missing: 30647\n",
      " - Missing: 30648\n",
      " - Missing: 30649\n",
      " - Missing: 30650\n",
      " - Missing: 30651\n",
      " - Missing: 30652\n",
      " - Missing: 30653\n",
      " - Missing: 30654\n",
      " - Missing: 30655\n",
      " - Missing: 30656\n",
      " - Missing: 30657\n",
      " - Missing: 30658\n",
      " - Missing: 30659\n",
      " - Missing: 30660\n",
      " - Missing: 30661\n",
      " - Missing: 30662\n",
      " - Missing: 30664\n",
      " - Missing: 30665\n",
      " - Missing: 30666\n",
      " - Missing: 30667\n",
      " - Missing: 30668\n",
      " - Missing: 30669\n",
      " - Missing: 30672\n",
      " - Missing: 30673\n",
      " - Missing: 30674\n",
      " - Missing: 30675\n",
      " - Missing: 30676\n",
      " - Missing: 30677\n",
      " - Missing: 30678\n",
      " - Missing: 30679\n",
      " - Missing: 30681\n",
      " - Missing: 30682\n",
      " - Missing: 30683\n",
      " - Missing: 30684\n",
      " - Missing: 30685\n",
      " - Missing: 30686\n",
      " - Missing: 30687\n",
      " - Missing: 30688\n",
      " - Missing: 30689\n",
      " - Missing: 30691\n",
      " - Missing: 30692\n",
      " - Missing: 30693\n",
      " - Missing: 30695\n",
      " - Missing: 30696\n",
      " - Missing: 30697\n",
      " - Missing: 30699\n",
      " - Missing: 30700\n",
      " - Missing: 30701\n",
      " - Missing: 30702\n",
      " - Missing: 30703\n",
      " - Missing: 30704\n",
      " - Missing: 30705\n",
      " - Missing: 30706\n",
      " - Missing: 30707\n",
      " - Missing: 30709\n",
      " - Missing: 30710\n",
      " - Missing: 30711\n",
      " - Missing: 30712\n",
      " - Missing: 30713\n",
      " - Missing: 30714\n",
      " - Missing: 30715\n",
      " - Missing: 30717\n",
      " - Missing: 30721\n",
      " - Missing: 30722\n",
      " - Missing: 30723\n",
      " - Missing: 30724\n",
      " - Missing: 30725\n",
      " - Missing: 30726\n",
      " - Missing: 30727\n",
      " - Missing: 30728\n",
      " - Missing: 30729\n",
      " - Missing: 30730\n",
      " - Missing: 30732\n",
      " - Missing: 30733\n",
      " - Missing: 30734\n",
      " - Missing: 30735\n",
      " - Missing: 30736\n",
      " - Missing: 30737\n",
      " - Missing: 30738\n",
      " - Missing: 30739\n",
      " - Missing: 30740\n",
      " - Missing: 30742\n",
      " - Missing: 30743\n",
      " - Missing: 30744\n",
      " - Missing: 30745\n",
      " - Missing: 30746\n",
      " - Missing: 30747\n",
      " - Missing: 30748\n",
      " - Missing: 30750\n",
      " - Missing: 30751\n",
      " - Missing: 30752\n",
      " - Missing: 30753\n",
      " - Missing: 30754\n",
      " - Missing: 30755\n",
      " - Missing: 30756\n",
      " - Missing: 30757\n",
      " - Missing: 30758\n",
      " - Missing: 30759\n",
      " - Missing: 30760\n",
      " - Missing: 30761\n",
      " - Missing: 30763\n",
      " - Missing: 30764\n",
      " - Missing: 30765\n",
      " - Missing: 30766\n",
      " - Missing: 30768\n",
      " - Missing: 30770\n",
      " - Missing: 30771\n",
      " - Missing: 30772\n",
      " - Missing: 30773\n",
      " - Missing: 30774\n",
      " - Missing: 30775\n",
      " - Missing: 30776\n",
      " - Missing: 30778\n",
      " - Missing: 30779\n",
      " - Missing: 30781\n",
      " - Missing: 30783\n",
      " - Missing: 30784\n",
      " - Missing: 30785\n",
      " - Missing: 30787\n",
      " - Missing: 30788\n",
      " - Missing: 30789\n",
      " - Missing: 30791\n",
      " - Missing: 30792\n",
      " - Missing: 30793\n",
      " - Missing: 30794\n",
      " - Missing: 30795\n",
      " - Missing: 30797\n",
      " - Missing: 30798\n",
      " - Missing: 30799\n",
      " - Missing: 30800\n",
      " - Missing: 30801\n",
      " - Missing: 30802\n",
      " - Missing: 30803\n",
      " - Missing: 30804\n",
      " - Missing: 30806\n",
      " - Missing: 30807\n",
      " - Missing: 30808\n",
      " - Missing: 30809\n",
      " - Missing: 30810\n",
      " - Missing: 30811\n",
      " - Missing: 30812\n",
      " - Missing: 30814\n",
      " - Missing: 30815\n",
      " - Missing: 30816\n",
      " - Missing: 30817\n",
      " - Missing: 30818\n",
      " - Missing: 30820\n",
      " - Missing: 30821\n",
      " - Missing: 30823\n",
      " - Missing: 30824\n",
      " - Missing: 30825\n",
      " - Missing: 30827\n",
      " - Missing: 30828\n",
      " - Missing: 30830\n",
      " - Missing: 30831\n",
      " - Missing: 30832\n",
      " - Missing: 30835\n",
      " - Missing: 30836\n",
      " - Missing: 30837\n",
      " - Missing: 30838\n",
      " - Missing: 30839\n",
      " - Missing: 30840\n",
      " - Missing: 30843\n",
      " - Missing: 30844\n",
      " - Missing: 30845\n",
      " - Missing: 30846\n",
      " - Missing: 30847\n",
      " - Missing: 30848\n",
      " - Missing: 30849\n",
      " - Missing: 30850\n",
      " - Missing: 30852\n",
      " - Missing: 30853\n",
      " - Missing: 30854\n",
      " - Missing: 30855\n",
      " - Missing: 30856\n",
      " - Missing: 30857\n",
      " - Missing: 30858\n",
      " - Missing: 30859\n",
      " - Missing: 30860\n",
      " - Missing: 30861\n",
      " - Missing: 30863\n",
      " - Missing: 30865\n",
      " - Missing: 30866\n",
      " - Missing: 30867\n",
      " - Missing: 30868\n",
      " - Missing: 30869\n",
      " - Missing: 30870\n",
      " - Missing: 30871\n",
      " - Missing: 30872\n",
      " - Missing: 30873\n",
      " - Missing: 30874\n",
      " - Missing: 30877\n",
      " - Missing: 30880\n",
      " - Missing: 30881\n",
      " - Missing: 30882\n",
      " - Missing: 30883\n",
      " - Missing: 30884\n",
      " - Missing: 30885\n",
      " - Missing: 30886\n",
      " - Missing: 30887\n",
      " - Missing: 30888\n",
      " - Missing: 30889\n",
      " - Missing: 30890\n",
      " - Missing: 30891\n",
      " - Missing: 30893\n",
      " - Missing: 30894\n",
      " - Missing: 30895\n",
      " - Missing: 30897\n",
      " - Missing: 30902\n",
      " - Missing: 30904\n",
      " - Missing: 30906\n",
      " - Missing: 30908\n",
      " - Missing: 30910\n",
      " - Missing: 30911\n",
      " - Missing: 30912\n",
      " - Missing: 30913\n",
      " - Missing: 30914\n",
      " - Missing: 30916\n",
      " - Missing: 30917\n",
      " - Missing: 30920\n",
      " - Missing: 30922\n",
      " - Missing: 30923\n",
      " - Missing: 30925\n",
      " - Missing: 30926\n",
      " - Missing: 30927\n",
      " - Missing: 30928\n",
      " - Missing: 30929\n",
      " - Missing: 30931\n",
      " - Missing: 30933\n",
      " - Missing: 30934\n",
      " - Missing: 30936\n",
      " - Missing: 30937\n",
      " - Missing: 30940\n",
      " - Missing: 30941\n",
      " - Missing: 30942\n",
      " - Missing: 30943\n",
      " - Missing: 30944\n",
      " - Missing: 30945\n",
      " - Missing: 30946\n",
      " - Missing: 30947\n",
      " - Missing: 30948\n",
      " - Missing: 30949\n",
      " - Missing: 30951\n",
      " - Missing: 30953\n",
      " - Missing: 30954\n",
      " - Missing: 30955\n",
      " - Missing: 30956\n",
      " - Missing: 30957\n",
      " - Missing: 30958\n",
      " - Missing: 30959\n",
      " - Missing: 30960\n",
      " - Missing: 30961\n",
      " - Missing: 30964\n",
      " - Missing: 30965\n",
      " - Missing: 30966\n",
      " - Missing: 30967\n",
      " - Missing: 30968\n",
      " - Missing: 30969\n",
      " - Missing: 30971\n",
      " - Missing: 30972\n",
      " - Missing: 30973\n",
      " - Missing: 30974\n",
      " - Missing: 30975\n",
      " - Missing: 30976\n",
      " - Missing: 30977\n",
      " - Missing: 30978\n",
      " - Missing: 30979\n",
      " - Missing: 30980\n",
      " - Missing: 30981\n",
      " - Missing: 30982\n",
      " - Missing: 30983\n",
      " - Missing: 30984\n",
      " - Missing: 30985\n",
      " - Missing: 30987\n",
      " - Missing: 30988\n",
      " - Missing: 30989\n",
      " - Missing: 30990\n",
      " - Missing: 30992\n",
      " - Missing: 30993\n",
      " - Missing: 30994\n",
      " - Missing: 30995\n",
      " - Missing: 30997\n",
      " - Missing: 30999\n",
      " - Missing: 31001\n",
      " - Missing: 31003\n",
      " - Missing: 31004\n",
      " - Missing: 31005\n",
      " - Missing: 31006\n",
      " - Missing: 31009\n",
      " - Missing: 31011\n",
      " - Missing: 31012\n",
      " - Missing: 31013\n",
      " - Missing: 31014\n",
      " - Missing: 31015\n",
      " - Missing: 31016\n",
      " - Missing: 31017\n",
      " - Missing: 31018\n",
      " - Missing: 31019\n",
      " - Missing: 31020\n",
      " - Missing: 31022\n",
      " - Missing: 31023\n",
      " - Missing: 31025\n",
      " - Missing: 31026\n",
      " - Missing: 31027\n",
      " - Missing: 31028\n",
      " - Missing: 31029\n",
      " - Missing: 31030\n",
      " - Missing: 31031\n",
      " - Missing: 31032\n",
      " - Missing: 31033\n",
      " - Missing: 31034\n",
      " - Missing: 31035\n",
      " - Missing: 31038\n",
      " - Missing: 31039\n",
      " - Missing: 31040\n",
      " - Missing: 31041\n",
      " - Missing: 31042\n",
      " - Missing: 31043\n",
      " - Missing: 31044\n",
      " - Missing: 31045\n",
      " - Missing: 31046\n",
      " - Missing: 31051\n",
      " - Missing: 31052\n",
      " - Missing: 31053\n",
      " - Missing: 31054\n",
      " - Missing: 31055\n",
      " - Missing: 31056\n",
      " - Missing: 31057\n",
      " - Missing: 31058\n",
      " - Missing: 31059\n",
      " - Missing: 31060\n",
      " - Missing: 31061\n",
      " - Missing: 31062\n",
      " - Missing: 31063\n",
      " - Missing: 31064\n",
      " - Missing: 31065\n",
      " - Missing: 31066\n",
      " - Missing: 31067\n",
      " - Missing: 31068\n",
      " - Missing: 31069\n",
      " - Missing: 31071\n",
      " - Missing: 31072\n",
      " - Missing: 31074\n",
      " - Missing: 31075\n",
      " - Missing: 31076\n",
      " - Missing: 31077\n",
      " - Missing: 31080\n",
      " - Missing: 31081\n",
      " - Missing: 31082\n",
      " - Missing: 31084\n",
      " - Missing: 31085\n",
      " - Missing: 31087\n",
      " - Missing: 31089\n",
      " - Missing: 31090\n",
      " - Missing: 31091\n",
      " - Missing: 31093\n",
      " - Missing: 31094\n",
      " - Missing: 31095\n",
      " - Missing: 31097\n",
      " - Missing: 31098\n",
      " - Missing: 31101\n",
      " - Missing: 31105\n",
      " - Missing: 31106\n",
      " - Missing: 31107\n",
      " - Missing: 31108\n",
      " - Missing: 31110\n",
      " - Missing: 31112\n",
      " - Missing: 31113\n",
      " - Missing: 31114\n",
      " - Missing: 31115\n",
      " - Missing: 31116\n",
      " - Missing: 31120\n",
      " - Missing: 31121\n",
      " - Missing: 31122\n",
      " - Missing: 31123\n",
      " - Missing: 31124\n",
      " - Missing: 31125\n",
      " - Missing: 31126\n",
      " - Missing: 31127\n",
      " - Missing: 31128\n",
      " - Missing: 31129\n",
      " - Missing: 31130\n",
      " - Missing: 31131\n",
      " - Missing: 31132\n",
      " - Missing: 31133\n",
      " - Missing: 31134\n",
      " - Missing: 31135\n",
      " - Missing: 31136\n",
      " - Missing: 31137\n",
      " - Missing: 31138\n",
      " - Missing: 31140\n",
      " - Missing: 31141\n",
      " - Missing: 31144\n",
      " - Missing: 31145\n",
      " - Missing: 31146\n",
      " - Missing: 31147\n",
      " - Missing: 31150\n",
      " - Missing: 31151\n",
      " - Missing: 31152\n",
      " - Missing: 31153\n",
      " - Missing: 31154\n",
      " - Missing: 31155\n",
      " - Missing: 31156\n",
      " - Missing: 31157\n",
      " - Missing: 31158\n",
      " - Missing: 31159\n",
      " - Missing: 31160\n",
      " - Missing: 31161\n",
      " - Missing: 31162\n",
      " - Missing: 31163\n",
      " - Missing: 31164\n",
      " - Missing: 31165\n",
      " - Missing: 31167\n",
      " - Missing: 31169\n",
      " - Missing: 31173\n",
      " - Missing: 31174\n",
      " - Missing: 31177\n",
      " - Missing: 31178\n",
      " - Missing: 31179\n",
      " - Missing: 31183\n",
      " - Missing: 31184\n",
      " - Missing: 31186\n",
      " - Missing: 31189\n",
      " - Missing: 31190\n",
      " - Missing: 31191\n",
      " - Missing: 31192\n",
      " - Missing: 31193\n",
      " - Missing: 31194\n",
      " - Missing: 31195\n",
      " - Missing: 31196\n",
      " - Missing: 31197\n",
      " - Missing: 31198\n",
      " - Missing: 31199\n",
      " - Missing: 31200\n",
      " - Missing: 31201\n",
      " - Missing: 31202\n",
      " - Missing: 31203\n",
      " - Missing: 31205\n",
      " - Missing: 31206\n",
      " - Missing: 31207\n",
      " - Missing: 31208\n",
      " - Missing: 31210\n",
      " - Missing: 31211\n",
      " - Missing: 31212\n",
      " - Missing: 31214\n",
      " - Missing: 31215\n",
      " - Missing: 31219\n",
      " - Missing: 31221\n",
      " - Missing: 31222\n",
      " - Missing: 31223\n",
      " - Missing: 31224\n",
      " - Missing: 31225\n",
      " - Missing: 31227\n",
      " - Missing: 31228\n",
      " - Missing: 31229\n",
      " - Missing: 31230\n",
      " - Missing: 31231\n",
      " - Missing: 31232\n",
      " - Missing: 31233\n",
      " - Missing: 31234\n",
      " - Missing: 31235\n",
      " - Missing: 31237\n",
      " - Missing: 31238\n",
      " - Missing: 31239\n",
      " - Missing: 31240\n",
      " - Missing: 31241\n",
      " - Missing: 31242\n",
      " - Missing: 31243\n",
      " - Missing: 31246\n",
      " - Missing: 31247\n",
      " - Missing: 31248\n",
      " - Missing: 31249\n",
      " - Missing: 31250\n",
      " - Missing: 31251\n",
      " - Missing: 31252\n",
      " - Missing: 31253\n",
      " - Missing: 31255\n",
      " - Missing: 31257\n",
      " - Missing: 31258\n",
      " - Missing: 31259\n",
      " - Missing: 31260\n",
      " - Missing: 31261\n",
      " - Missing: 31263\n",
      " - Missing: 31264\n",
      " - Missing: 31266\n",
      " - Missing: 31267\n",
      " - Missing: 31268\n",
      " - Missing: 31269\n",
      " - Missing: 31270\n",
      " - Missing: 31274\n",
      " - Missing: 31278\n",
      " - Missing: 31279\n",
      " - Missing: 31280\n",
      " - Missing: 31281\n",
      " - Missing: 31282\n",
      " - Missing: 31283\n",
      " - Missing: 31285\n",
      " - Missing: 31286\n",
      " - Missing: 31287\n",
      " - Missing: 31288\n",
      " - Missing: 31289\n",
      " - Missing: 31290\n",
      " - Missing: 31292\n",
      " - Missing: 31294\n",
      " - Missing: 31296\n",
      " - Missing: 31297\n",
      " - Missing: 31298\n",
      " - Missing: 31299\n",
      " - Missing: 31300\n",
      " - Missing: 31303\n",
      " - Missing: 31305\n",
      " - Missing: 31306\n",
      " - Missing: 31308\n",
      " - Missing: 31309\n",
      " - Missing: 31310\n",
      " - Missing: 31311\n",
      " - Missing: 31312\n",
      " - Missing: 31314\n",
      " - Missing: 31315\n",
      " - Missing: 31316\n",
      " - Missing: 31320\n",
      " - Missing: 31322\n",
      " - Missing: 31323\n",
      " - Missing: 31324\n",
      " - Missing: 31325\n",
      " - Missing: 31327\n",
      " - Missing: 31328\n",
      " - Missing: 31329\n",
      " - Missing: 31330\n",
      " - Missing: 31331\n",
      " - Missing: 31332\n",
      " - Missing: 31333\n",
      " - Missing: 31334\n",
      " - Missing: 31335\n",
      " - Missing: 31336\n",
      " - Missing: 31337\n",
      " - Missing: 31338\n",
      " - Missing: 31339\n",
      " - Missing: 31340\n",
      " - Missing: 31341\n",
      " - Missing: 31345\n",
      " - Missing: 31346\n",
      " - Missing: 31347\n",
      " - Missing: 31348\n",
      " - Missing: 31350\n",
      " - Missing: 31354\n",
      " - Missing: 31355\n",
      " - Missing: 31356\n",
      " - Missing: 31357\n",
      " - Missing: 31358\n",
      " - Missing: 31359\n",
      " - Missing: 31360\n",
      " - Missing: 31361\n",
      " - Missing: 31362\n",
      " - Missing: 31363\n",
      " - Missing: 31364\n",
      " - Missing: 31365\n",
      " - Missing: 31366\n",
      " - Missing: 31367\n",
      " - Missing: 31369\n",
      " - Missing: 31370\n",
      " - Missing: 31371\n",
      " - Missing: 31372\n",
      " - Missing: 31374\n",
      " - Missing: 31375\n",
      " - Missing: 31376\n",
      " - Missing: 31377\n",
      " - Missing: 31378\n",
      " - Missing: 31379\n",
      " - Missing: 31381\n",
      " - Missing: 31382\n",
      " - Missing: 31384\n",
      " - Missing: 31386\n",
      " - Missing: 31387\n",
      " - Missing: 31388\n",
      " - Missing: 31389\n",
      " - Missing: 31390\n",
      " - Missing: 31391\n",
      " - Missing: 31392\n",
      " - Missing: 31393\n",
      " - Missing: 31394\n",
      " - Missing: 31396\n",
      " - Missing: 31397\n",
      " - Missing: 31398\n",
      " - Missing: 31399\n",
      " - Missing: 31400\n",
      " - Missing: 31401\n",
      " - Missing: 31402\n",
      " - Missing: 31404\n",
      " - Missing: 31405\n",
      " - Missing: 31406\n",
      " - Missing: 31407\n",
      " - Missing: 31408\n",
      " - Missing: 31410\n",
      " - Missing: 31411\n",
      " - Missing: 31413\n",
      " - Missing: 31414\n",
      " - Missing: 31415\n",
      " - Missing: 31416\n",
      " - Missing: 31418\n",
      " - Missing: 31419\n",
      " - Missing: 31420\n",
      " - Missing: 31421\n",
      " - Missing: 31423\n",
      " - Missing: 31424\n",
      " - Missing: 31425\n",
      " - Missing: 31427\n",
      " - Missing: 31428\n",
      " - Missing: 31430\n",
      " - Missing: 31431\n",
      " - Missing: 31432\n",
      " - Missing: 31433\n",
      " - Missing: 31436\n",
      " - Missing: 31437\n",
      " - Missing: 31438\n",
      " - Missing: 31439\n",
      " - Missing: 31440\n",
      " - Missing: 31441\n",
      " - Missing: 31442\n",
      " - Missing: 31444\n",
      " - Missing: 31446\n",
      " - Missing: 31447\n",
      " - Missing: 31450\n",
      " - Missing: 31454\n",
      " - Missing: 31455\n",
      " - Missing: 31457\n",
      " - Missing: 31458\n",
      " - Missing: 31461\n",
      " - Missing: 31463\n",
      " - Missing: 31464\n",
      " - Missing: 31465\n",
      " - Missing: 31467\n",
      " - Missing: 31468\n",
      " - Missing: 31469\n",
      " - Missing: 31470\n",
      " - Missing: 31471\n",
      " - Missing: 31472\n",
      " - Missing: 31475\n",
      " - Missing: 31476\n",
      " - Missing: 31477\n",
      " - Missing: 31478\n",
      " - Missing: 31479\n",
      " - Missing: 31482\n",
      " - Missing: 31484\n",
      " - Missing: 31487\n",
      " - Missing: 31488\n",
      " - Missing: 31489\n",
      " - Missing: 31490\n",
      " - Missing: 31492\n",
      " - Missing: 31493\n",
      " - Missing: 31494\n",
      " - Missing: 31496\n",
      " - Missing: 31498\n",
      " - Missing: 31499\n",
      " - Missing: 31501\n",
      " - Missing: 31503\n",
      " - Missing: 31504\n",
      " - Missing: 31505\n",
      " - Missing: 31506\n",
      " - Missing: 31508\n",
      " - Missing: 31509\n",
      " - Missing: 31510\n",
      " - Missing: 31511\n",
      " - Missing: 31512\n",
      " - Missing: 31513\n",
      " - Missing: 31515\n",
      " - Missing: 31516\n",
      " - Missing: 31517\n",
      " - Missing: 31518\n",
      " - Missing: 31519\n",
      " - Missing: 31521\n",
      " - Missing: 31522\n",
      " - Missing: 31523\n",
      " - Missing: 31524\n",
      " - Missing: 31525\n",
      " - Missing: 31526\n",
      " - Missing: 31527\n",
      " - Missing: 31528\n",
      " - Missing: 31529\n",
      " - Missing: 31530\n",
      " - Missing: 31531\n",
      " - Missing: 31532\n",
      " - Missing: 31533\n",
      " - Missing: 31535\n",
      " - Missing: 31536\n",
      " - Missing: 31537\n",
      " - Missing: 31542\n",
      " - Missing: 31543\n",
      " - Missing: 31544\n",
      " - Missing: 31547\n",
      " - Missing: 31548\n",
      " - Missing: 31549\n",
      " - Missing: 31550\n",
      " - Missing: 31551\n",
      " - Missing: 31552\n",
      " - Missing: 31554\n",
      " - Missing: 31555\n",
      " - Missing: 31556\n",
      " - Missing: 31557\n",
      " - Missing: 31558\n",
      " - Missing: 31560\n",
      " - Missing: 31561\n",
      " - Missing: 31562\n",
      " - Missing: 31563\n",
      " - Missing: 31564\n",
      " - Missing: 31565\n",
      " - Missing: 31567\n",
      " - Missing: 31568\n",
      " - Missing: 31569\n",
      " - Missing: 31570\n",
      " - Missing: 31571\n",
      " - Missing: 31572\n",
      " - Missing: 31573\n",
      " - Missing: 31574\n",
      " - Missing: 31575\n",
      " - Missing: 31576\n",
      " - Missing: 31577\n",
      " - Missing: 31578\n",
      " - Missing: 31579\n",
      " - Missing: 31580\n",
      " - Missing: 31581\n",
      " - Missing: 31582\n",
      " - Missing: 31583\n",
      " - Missing: 31584\n",
      " - Missing: 31586\n",
      " - Missing: 31587\n",
      " - Missing: 31590\n",
      " - Missing: 31591\n",
      " - Missing: 31592\n",
      " - Missing: 31594\n",
      " - Missing: 31595\n",
      " - Missing: 31597\n",
      " - Missing: 31598\n",
      " - Missing: 31600\n",
      " - Missing: 31602\n",
      " - Missing: 31607\n",
      " - Missing: 31608\n",
      " - Missing: 31610\n",
      " - Missing: 31611\n",
      " - Missing: 31613\n",
      " - Missing: 31614\n",
      " - Missing: 31615\n",
      " - Missing: 31616\n",
      " - Missing: 31617\n",
      " - Missing: 31618\n",
      " - Missing: 31619\n",
      " - Missing: 31620\n",
      " - Missing: 31621\n",
      " - Missing: 31622\n",
      " - Missing: 31624\n",
      " - Missing: 31626\n",
      " - Missing: 31629\n",
      " - Missing: 31630\n",
      " - Missing: 31631\n",
      " - Missing: 31634\n",
      " - Missing: 31636\n",
      " - Missing: 31637\n",
      " - Missing: 31638\n",
      " - Missing: 31641\n",
      " - Missing: 31642\n",
      " - Missing: 31643\n",
      " - Missing: 31644\n",
      " - Missing: 31645\n",
      " - Missing: 31646\n",
      " - Missing: 31647\n",
      " - Missing: 31649\n",
      " - Missing: 31650\n",
      " - Missing: 31651\n",
      " - Missing: 31652\n",
      " - Missing: 31653\n",
      " - Missing: 31654\n",
      " - Missing: 31655\n",
      " - Missing: 31656\n",
      " - Missing: 31657\n",
      " - Missing: 31658\n",
      " - Missing: 31659\n",
      " - Missing: 31660\n",
      " - Missing: 31661\n",
      " - Missing: 31662\n",
      " - Missing: 31663\n",
      " - Missing: 31665\n",
      " - Missing: 31667\n",
      " - Missing: 31668\n",
      " - Missing: 31670\n",
      " - Missing: 31671\n",
      " - Missing: 31672\n",
      " - Missing: 31673\n",
      " - Missing: 31675\n",
      " - Missing: 31676\n",
      " - Missing: 31677\n",
      " - Missing: 31678\n",
      " - Missing: 31679\n",
      " - Missing: 31681\n",
      " - Missing: 31682\n",
      " - Missing: 31686\n",
      " - Missing: 31687\n",
      " - Missing: 31689\n",
      " - Missing: 31690\n",
      " - Missing: 31691\n",
      " - Missing: 31692\n",
      " - Missing: 31693\n",
      " - Missing: 31696\n",
      " - Missing: 31698\n",
      " - Missing: 31699\n",
      " - Missing: 31700\n",
      " - Missing: 31701\n",
      " - Missing: 31702\n",
      " - Missing: 31703\n",
      " - Missing: 31704\n",
      " - Missing: 31706\n",
      " - Missing: 31707\n",
      " - Missing: 31709\n",
      " - Missing: 31710\n",
      " - Missing: 31711\n",
      " - Missing: 31712\n",
      " - Missing: 31713\n",
      " - Missing: 31716\n",
      " - Missing: 31717\n",
      " - Missing: 31718\n",
      " - Missing: 31719\n",
      " - Missing: 31720\n",
      " - Missing: 31721\n",
      " - Missing: 31723\n",
      " - Missing: 31724\n",
      " - Missing: 31725\n",
      " - Missing: 31726\n",
      " - Missing: 31727\n",
      " - Missing: 31731\n",
      " - Missing: 31732\n",
      " - Missing: 31733\n",
      " - Missing: 31734\n",
      " - Missing: 31735\n",
      " - Missing: 31737\n",
      " - Missing: 31738\n",
      " - Missing: 31739\n",
      " - Missing: 31740\n",
      " - Missing: 31741\n",
      " - Missing: 31743\n",
      " - Missing: 31744\n",
      " - Missing: 31746\n",
      " - Missing: 31747\n",
      " - Missing: 31748\n",
      " - Missing: 31751\n",
      " - Missing: 31752\n",
      " - Missing: 31753\n",
      " - Missing: 31754\n",
      " - Missing: 31755\n",
      " - Missing: 31756\n",
      " - Missing: 31758\n",
      " - Missing: 31759\n",
      " - Missing: 31760\n",
      " - Missing: 31761\n",
      " - Missing: 31762\n",
      " - Missing: 31763\n",
      " - Missing: 31764\n",
      " - Missing: 31765\n",
      " - Missing: 31766\n",
      " - Missing: 31767\n",
      " - Missing: 31768\n",
      " - Missing: 31769\n",
      " - Missing: 31770\n",
      " - Missing: 31771\n",
      " - Missing: 31772\n",
      " - Missing: 31773\n",
      " - Missing: 31775\n",
      " - Missing: 31776\n",
      " - Missing: 31778\n",
      " - Missing: 31779\n",
      " - Missing: 31781\n",
      " - Missing: 31782\n",
      " - Missing: 31783\n",
      " - Missing: 31784\n",
      " - Missing: 31785\n",
      " - Missing: 31786\n",
      " - Missing: 31787\n",
      " - Missing: 31788\n",
      " - Missing: 31789\n",
      " - Missing: 31790\n",
      " - Missing: 31791\n",
      " - Missing: 31793\n",
      " - Missing: 31794\n",
      " - Missing: 31795\n",
      " - Missing: 31796\n",
      " - Missing: 31797\n",
      " - Missing: 31798\n",
      " - Missing: 31799\n",
      " - Missing: 31801\n",
      " - Missing: 31802\n",
      " - Missing: 31805\n",
      " - Missing: 31806\n",
      " - Missing: 31808\n",
      " - Missing: 31809\n",
      " - Missing: 31810\n",
      " - Missing: 31811\n",
      " - Missing: 31812\n",
      " - Missing: 31813\n",
      " - Missing: 31814\n",
      " - Missing: 31815\n",
      " - Missing: 31816\n",
      " - Missing: 31817\n",
      " - Missing: 31818\n",
      " - Missing: 31819\n",
      " - Missing: 31820\n",
      " - Missing: 31823\n",
      " - Missing: 31824\n",
      " - Missing: 31825\n",
      " - Matched: 785\n",
      " - Lost 2398 samples.\n",
      " - Saved: result_test/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.NER\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.NER/gpt-35-turbo/7.Cantemist.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.CODING\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.CODING/gpt-35-turbo/7.Cantemist.CODING-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 7.Cantemist.Norm\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 300\n",
      " - Num of batch: 300\n",
      " - Num of result: 300\n",
      " - Matched: 300\n",
      " - All matched.\n",
      " - Saved: result_test/7.Cantemist.Norm/gpt-35-turbo/7.Cantemist.Norm-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.area\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.area/gpt-35-turbo/8.CARES.area-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_block\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_block/gpt-35-turbo/8.CARES.icd10_block-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-4o/82.CHIP-CTC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-4o/83.CHIP-MDCFNPC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-4o/84.MedDG-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-4o/85.IMCS-V2-SR-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-4o/86.IMCS-V2-MRG-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-4o/87.IMCS-V2-DAC-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-4o/91-1.CAS.label-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-4o/96.RuCCoN.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-4o/96.RuCCoN.NER_Nor-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-4o/97.CLISTER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-4o/98.BRONCO150.NER_status-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-4o/98.BRONCO150.NER_Nor-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_test/99.CARDIO:DE/gpt-4o/99.CARDIO:DE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-4o/101.IFMIR.IncidentType-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-4o/101.IFMIR.NER-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-4o/100.GraSSCo_PHI-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-4o/101.IFMIR.NER_factuality-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-4o/102.iCorpus-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-4o/103.icliniq-10k-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-4o/104.HealthCareMagic-100k-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 8.CARES.icd10_sub_block\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 966\n",
      " - Num of batch: 966\n",
      " - Num of result: 966\n",
      " - Matched: 966\n",
      " - All matched.\n",
      " - Saved: result_test/8.CARES.icd10_sub_block/gpt-4o/8.CARES.icd10_sub_block-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 12.C-EMRS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1911\n",
      " - Num of batch: 1911\n",
      " - Num of result: 1911\n",
      " - Matched: 1911\n",
      " - All matched.\n",
      " - Saved: result_test/12.C-EMRS/gpt-4o/12.C-EMRS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 238\n",
      " - Num of batch: 238\n",
      " - Num of result: 238\n",
      " - Matched: 238\n",
      " - All matched.\n",
      " - Saved: result_test/19.ClinicalNotes-UPMC/gpt-4o/19.ClinicalNotes-UPMC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1771\n",
      " - Num of batch: 1771\n",
      " - Num of result: 1771\n",
      " - Matched: 1771\n",
      " - All matched.\n",
      " - Saved: result_test/22.CLIP/gpt-4o/22.CLIP-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 23.cMedQA\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6184\n",
      " - Num of batch: 6184\n",
      " - Num of result: 6184\n",
      " - Matched: 6184\n",
      " - All matched.\n",
      " - Saved: result_test/23.cMedQA/gpt-4o/23.cMedQA-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 26.DialMed\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1199\n",
      " - Num of batch: 1199\n",
      " - Num of result: 1199\n",
      " - Matched: 1199\n",
      " - All matched.\n",
      " - Saved: result_test/26.DialMed/gpt-4o/26.DialMed-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result_test/28.MIE/gpt-4o/28.MIE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 9.CHIP-CDEE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 384\n",
      " - Num of batch: 384\n",
      " - Num of result: 384\n",
      " - Matched: 384\n",
      " - All matched.\n",
      " - Saved: result_test/9.CHIP-CDEE/gpt-4o/9.CHIP-CDEE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.primary_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.primary_department/gpt-4o/29.EHRQA.primary_department-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.qa\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.qa/gpt-4o/29.EHRQA.qa-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 29.EHRQA.sub_department\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5193\n",
      " - Num of batch: 5193\n",
      " - Num of result: 5193\n",
      " - Matched: 5193\n",
      " - All matched.\n",
      " - Saved: result_test/29.EHRQA.sub_department/gpt-4o/29.EHRQA.sub_department-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result_test/31.Ex4CDS/gpt-4o/31.Ex4CDS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.consensus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 441\n",
      " - Num of batch: 441\n",
      " - Num of result: 441\n",
      " - Matched: 441\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.consensus/gpt-4o/33.GOUT-CC.consensus-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 33.GOUT-CC.predict\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 843\n",
      " - Num of batch: 843\n",
      " - Num of result: 843\n",
      " - Matched: 843\n",
      " - All matched.\n",
      " - Saved: result_test/33.GOUT-CC.predict/gpt-4o/33.GOUT-CC.predict-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 43.IMCS-V2-NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2374\n",
      " - Num of batch: 2374\n",
      " - Num of result: 2374\n",
      " - Matched: 2374\n",
      " - All matched.\n",
      " - Saved: result_test/43.IMCS-V2-NER/gpt-4o/43.IMCS-V2-NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 81.CHIP-CDN\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2000\n",
      " - Num of batch: 2000\n",
      " - Num of result: 2000\n",
      " - Matched: 2000\n",
      " - All matched.\n",
      " - Saved: result_test/81.CHIP-CDN/gpt-4o/81.CHIP-CDN-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 82.CHIP-CTC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 6146\n",
      " - Num of batch: 6146\n",
      " - Num of result: 6146\n",
      " - Matched: 6146\n",
      " - All matched.\n",
      " - Saved: result_test/82.CHIP-CTC/gpt-4o/82.CHIP-CTC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 83.CHIP-MDCFNPC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11785\n",
      " - Num of batch: 11785\n",
      " - Num of result: 11785\n",
      " - Matched: 11785\n",
      " - All matched.\n",
      " - Saved: result_test/83.CHIP-MDCFNPC/gpt-4o/83.CHIP-MDCFNPC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 84.MedDG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2747\n",
      " - Num of batch: 2747\n",
      " - Num of result: 2747\n",
      " - Matched: 2747\n",
      " - All matched.\n",
      " - Saved: result_test/84.MedDG/gpt-4o/84.MedDG-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 85.IMCS-V2-SR\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/85.IMCS-V2-SR/gpt-4o/85.IMCS-V2-SR-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 86.IMCS-V2-MRG\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 833\n",
      " - Num of batch: 833\n",
      " - Num of result: 833\n",
      " - Matched: 833\n",
      " - All matched.\n",
      " - Saved: result_test/86.IMCS-V2-MRG/gpt-4o/86.IMCS-V2-MRG-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 87.IMCS-V2-DAC\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 22059\n",
      " - Num of batch: 22059\n",
      " - Num of result: 22059\n",
      " - Matched: 22059\n",
      " - All matched.\n",
      " - Saved: result_test/87.IMCS-V2-DAC/gpt-4o/87.IMCS-V2-DAC-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-1.CAS.label/gpt-4o/91-1.CAS.label-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result_test/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 866\n",
      " - Num of batch: 866\n",
      " - Num of result: 866\n",
      " - Matched: 866\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER/gpt-4o/96.RuCCoN.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 854\n",
      " - Num of batch: 854\n",
      " - Num of result: 854\n",
      " - Matched: 854\n",
      " - All matched.\n",
      " - Saved: result_test/96.RuCCoN.NER_Nor/gpt-4o/96.RuCCoN.NER_Nor-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 97.CLISTER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 400\n",
      " - Num of batch: 400\n",
      " - Num of result: 400\n",
      " - Matched: 400\n",
      " - All matched.\n",
      " - Saved: result_test/97.CLISTER/gpt-4o/97.CLISTER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_status\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_status/gpt-4o/98.BRONCO150.NER_status-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 98.BRONCO150.NER_Nor\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 880\n",
      " - Num of batch: 880\n",
      " - Num of result: 880\n",
      " - Matched: 880\n",
      " - All matched.\n",
      " - Saved: result_test/98.BRONCO150.NER_Nor/gpt-4o/98.BRONCO150.NER_Nor-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_test/99.CARDIO:DE/gpt-4o/99.CARDIO:DE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 100.GraSSCo_PHI\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 329\n",
      " - Num of batch: 329\n",
      " - Num of result: 329\n",
      " - Matched: 329\n",
      " - All matched.\n",
      " - Saved: result_test/100.GraSSCo_PHI/gpt-4o/100.GraSSCo_PHI-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.IncidentType\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5834\n",
      " - Num of batch: 5834\n",
      " - Num of result: 5834\n",
      " - Matched: 5834\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.IncidentType/gpt-4o/101.IFMIR.IncidentType-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER/gpt-4o/101.IFMIR.NER-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 101.IFMIR.NER_factuality\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 5748\n",
      " - Num of batch: 5748\n",
      " - Num of result: 5748\n",
      " - Matched: 5748\n",
      " - All matched.\n",
      " - Saved: result_test/101.IFMIR.NER_factuality/gpt-4o/101.IFMIR.NER_factuality-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 102.iCorpus\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 220\n",
      " - Num of batch: 220\n",
      " - Num of result: 220\n",
      " - Matched: 220\n",
      " - All matched.\n",
      " - Saved: result_test/102.iCorpus/gpt-4o/102.iCorpus-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 103.icliniq-10k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 733\n",
      " - Num of batch: 733\n",
      " - Num of result: 733\n",
      " - Matched: 733\n",
      " - All matched.\n",
      " - Saved: result_test/103.icliniq-10k/gpt-4o/103.icliniq-10k-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 104.HealthCareMagic-100k\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 11217\n",
      " - Num of batch: 11217\n",
      " - Num of result: 11217\n",
      " - Matched: 11217\n",
      " - All matched.\n",
      " - Saved: result_test/104.HealthCareMagic-100k/gpt-4o/104.HealthCareMagic-100k-direct-5-shot-greedy-42.result.json\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "process_azure_result_to_task_result(path_dir_azure_result, path_dir_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mising result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:25<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "list_path_file = [\n",
    "    os.path.join(path_dir_azure_result, path_file)\n",
    "    for path_file in os.listdir(path_dir_azure_result)\n",
    "    if path_file.endswith(\".jsonl\")\n",
    "]\n",
    "dict_model_prompt_result = {\n",
    "    \"gpt-35-turbo-batch\": {\n",
    "        \"direct\": [],\n",
    "        \"cot\": [],\n",
    "        \"direct-5-shot\": [],\n",
    "    },\n",
    "    \"gpt-4o-batch\": {\n",
    "        \"direct\": [],\n",
    "        \"cot\": [],\n",
    "        \"direct-5-shot\": [],\n",
    "    }\n",
    "}\n",
    "for path_file in tqdm(list_path_file):\n",
    "    with open(path_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        list_dict_result = [json.loads(line) for line in f.readlines()]\n",
    "    dict_result = list_dict_result[0]\n",
    "    task_name, model_name, prompt_mode, split, id = dict_result['custom_id'].split(\"|\")\n",
    "    dict_model_prompt_result[model_name][prompt_mode].append(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-35-turbo-batch': {'direct': ['azure/output/file-4f34fb37-fc17-4273-8823-c463092641ad.jsonl',\n",
       "   'azure/output/file-3072394f-90ab-4762-abce-65636c96f265.jsonl',\n",
       "   'azure/output/file-be494034-2a2c-4db9-ba9e-16c90f3f2b33.jsonl'],\n",
       "  'cot': ['azure/output/file-4658a44f-42c9-48ee-abe6-5d8b8b01e014.jsonl',\n",
       "   'azure/output/file-69ffa97d-1c68-45fa-a678-547d68edc8cb.jsonl',\n",
       "   'azure/output/file-1ce9d616-383d-45fb-af29-9e26c958d06c.jsonl'],\n",
       "  'direct-5-shot': ['azure/output/file-ca075f22-6ec6-447a-bfd8-c04e9605f681.jsonl',\n",
       "   'azure/output/file-b39c2e02-2bd7-4983-8f74-045fc50fcf50.jsonl',\n",
       "   'azure/output/file-9ed9d259-3067-40dd-96b4-4a92bb31b46a.jsonl',\n",
       "   'azure/output/file-c562680f-1cde-431a-bd27-991851f8a4ce.jsonl',\n",
       "   'azure/output/file-8fd5ab91-800e-4f8f-b74a-8c0ab51bbcf3.jsonl',\n",
       "   'azure/output/file-6eed46d6-bc0d-4700-9a30-b9f236276511.jsonl',\n",
       "   'azure/output/file-f2370c62-ee40-4851-82fc-808c0d8a10b3.jsonl']},\n",
       " 'gpt-4o-batch': {'direct': ['azure/output/file-59b186d8-74d8-4c2a-b1df-e88ea8029225.jsonl',\n",
       "   'azure/output/file-128804c9-ad0b-48dc-bb43-1ddee229af22.jsonl',\n",
       "   'azure/output/file-4eef4d6f-b8fa-4061-a623-7846c41266d8.jsonl'],\n",
       "  'cot': ['azure/output/file-2b078840-bc72-41e9-af6a-6924a52361a0.jsonl',\n",
       "   'azure/output/file-d9ba2dab-7e34-4519-92ca-d6c9ecbac837.jsonl',\n",
       "   'azure/output/file-4544adb7-0240-4907-8699-9d5ca1e9f4df.jsonl'],\n",
       "  'direct-5-shot': ['azure/output/file-80f2b63a-1c83-40b4-99a2-ec556b4bb24a.jsonl',\n",
       "   'azure/output/file-6ab84e98-6180-4ad4-acbf-cc88c5c95d19.jsonl',\n",
       "   'azure/output/file-8024b1a0-e8cf-4ada-9c90-165dbdb89132.jsonl',\n",
       "   'azure/output/file-509dc287-3504-4563-8bbd-8481353a429a.jsonl',\n",
       "   'azure/output/file-31b7e67c-834a-498e-8dd9-adbdc070f1d1.jsonl',\n",
       "   'azure/output/file-76fc04f5-e495-4d3c-9735-4ba174ebf50c.jsonl']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_model_prompt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 104.HealthCareMagic-100k\n",
      "Task: 1-1.ADE-ADE identification\n",
      "Task: 1-2.ADE-ADE relation\n",
      "Task: 1-3.ADE-Drug dosage\n",
      "Task: 5.BrainMRI-AIS\n",
      "Task: 6.Brateca.mortality\n",
      " - gpt-35-turbo miss: direct-5-shot\n",
      "Task: 6.Brateca.hospitalization\n",
      "Task: 7.Cantemist.NER\n",
      "Task: 7.Cantemist.CODING\n",
      "Task: 7.Cantemist.Norm\n",
      "Task: 8.CARES.area\n",
      "Task: 8.CARES.icd10_block\n",
      "Task: 8.CARES.icd10_chapter\n",
      "Task: 8.CARES.icd10_sub_block\n",
      "Task: 9.CHIP-CDEE\n",
      "Task: 12.C-EMRS\n",
      "Task: 19.ClinicalNotes-UPMC\n",
      "Task: 22.CLIP\n",
      "Task: 23.cMedQA\n",
      "Task: 26.DialMed\n",
      "Task: 28.MIE\n",
      "Task: 29.EHRQA.primary_department\n",
      "Task: 29.EHRQA.qa\n",
      "Task: 29.EHRQA.sub_department\n",
      "Task: 31.Ex4CDS\n",
      "Task: 33.GOUT-CC.consensus\n",
      "Task: 33.GOUT-CC.predict\n",
      "Task: 43.IMCS-V2-NER\n",
      "Task: 81.CHIP-CDN\n",
      "Task: 99.CARDIO:DE\n",
      " - gpt-35-turbo miss: direct-5-shot\n",
      "Task: 101.IFMIR.IncidentType\n",
      "Task: 101.IFMIR.NER\n",
      "Task: 100.GraSSCo_PHI\n",
      "Task: 101.IFMIR.NER_factuality\n",
      "Task: 102.iCorpus\n",
      "Task: 103.icliniq-10k\n",
      "Task: 82.CHIP-CTC\n",
      "Task: 83.CHIP-MDCFNPC\n",
      "Task: 84.MedDG\n",
      "Task: 85.IMCS-V2-SR\n",
      "Task: 86.IMCS-V2-MRG\n",
      "Task: 87.IMCS-V2-DAC\n",
      "Task: 91-1.CAS.label\n",
      "Task: 91-2.CAS.evidence\n",
      "Task: 96.RuCCoN.NER\n",
      "Task: 96.RuCCoN.NER_Nor\n",
      "Task: 97.CLISTER\n",
      "Task: 98.BRONCO150.NER_status\n",
      "Task: 98.BRONCO150.NER_Nor\n"
     ]
    }
   ],
   "source": [
    "path_dir_save = \"result_test\"\n",
    "list_task = os.listdir(path_dir_save)\n",
    "for task_name in list_task:\n",
    "    print(f\"Task: {task_name}\")\n",
    "    path_dir_task = os.path.join(path_dir_save, task_name)\n",
    "    list_path_dir_model = os.listdir(path_dir_task)\n",
    "    # gpt-4o\n",
    "    model_name = \"gpt-4o\"\n",
    "    if model_name not in list_path_dir_model:\n",
    "        print(f\" - Missing model: {model_name}\")\n",
    "    else:\n",
    "        list_path_file = os.listdir(os.path.join(path_dir_task, model_name))\n",
    "        list_prompt_mode = [ path_file.split(task_name+'-')[1].split(\"-greedy\")[0] for path_file in list_path_file ]\n",
    "        string_missing = \"\"\n",
    "        if \"direct\" not in list_prompt_mode:\n",
    "            string_missing+= \"direct, \"\n",
    "        if \"cot\" not in list_prompt_mode:\n",
    "            string_missing+= \"cot, \"\n",
    "        if \"direct-5-shot\" not in list_prompt_mode:\n",
    "            string_missing+= \"direct-5-shot\"\n",
    "        if string_missing:\n",
    "            print(f\" - {model_name} miss: {string_missing}\")\n",
    "    # gpt-35-turbo\n",
    "    model_name = \"gpt-35-turbo\"\n",
    "    if model_name not in list_path_dir_model:\n",
    "        print(f\" - Missing model: {model_name}\")\n",
    "    else:\n",
    "        list_path_file = os.listdir(os.path.join(path_dir_task, model_name))\n",
    "        list_prompt_mode = [ path_file.split(task_name+'-')[1].split(\"-greedy\")[0] for path_file in list_path_file ]\n",
    "        string_missing = \"\"\n",
    "        if \"direct\" not in list_prompt_mode:\n",
    "            string_missing+= \"direct, \"\n",
    "        if \"cot\" not in list_prompt_mode:\n",
    "            string_missing+= \"cot, \"\n",
    "        if \"direct-5-shot\" not in list_prompt_mode:\n",
    "            string_missing+= \"direct-5-shot\"\n",
    "        if string_missing:\n",
    "            print(f\" - {model_name} miss: {string_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azure/output/file-ca075f22-6ec6-447a-bfd8-c04e9605f681.jsonl',\n",
       " 'azure/output/file-4658a44f-42c9-48ee-abe6-5d8b8b01e014.jsonl',\n",
       " 'azure/output/file-4f34fb37-fc17-4273-8823-c463092641ad.jsonl',\n",
       " 'azure/output/file-80f2b63a-1c83-40b4-99a2-ec556b4bb24a.jsonl',\n",
       " 'azure/output/file-69ffa97d-1c68-45fa-a678-547d68edc8cb.jsonl',\n",
       " 'azure/output/file-3072394f-90ab-4762-abce-65636c96f265.jsonl',\n",
       " 'azure/output/file-be494034-2a2c-4db9-ba9e-16c90f3f2b33.jsonl',\n",
       " 'azure/output/file-59b186d8-74d8-4c2a-b1df-e88ea8029225.jsonl',\n",
       " 'azure/output/file-2b078840-bc72-41e9-af6a-6924a52361a0.jsonl',\n",
       " 'azure/output/file-1ce9d616-383d-45fb-af29-9e26c958d06c.jsonl',\n",
       " 'azure/output/file-b39c2e02-2bd7-4983-8f74-045fc50fcf50.jsonl',\n",
       " 'azure/output/file-9ed9d259-3067-40dd-96b4-4a92bb31b46a.jsonl',\n",
       " 'azure/output/file-c562680f-1cde-431a-bd27-991851f8a4ce.jsonl',\n",
       " 'azure/output/file-8fd5ab91-800e-4f8f-b74a-8c0ab51bbcf3.jsonl',\n",
       " 'azure/output/file-6eed46d6-bc0d-4700-9a30-b9f236276511.jsonl',\n",
       " 'azure/output/file-128804c9-ad0b-48dc-bb43-1ddee229af22.jsonl',\n",
       " 'azure/output/file-4eef4d6f-b8fa-4061-a623-7846c41266d8.jsonl',\n",
       " 'azure/output/file-f2370c62-ee40-4851-82fc-808c0d8a10b3.jsonl',\n",
       " 'azure/output/file-d9ba2dab-7e34-4519-92ca-d6c9ecbac837.jsonl',\n",
       " 'azure/output/file-4544adb7-0240-4907-8699-9d5ca1e9f4df.jsonl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_path_file = [\n",
    "    os.path.join(path_dir_azure_result, path_file)\n",
    "    for path_file in os.listdir(path_dir_azure_result)\n",
    "    if path_file.endswith(\".jsonl\")\n",
    "]\n",
    "list_path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_model_token = {}\n",
    "for path_file in tqdm(list_path_file):\n",
    "    with open(path_file, \"r\") as f:\n",
    "        list_dict_result = [json.loads(line) for line in f]\n",
    "    dict_result = list_dict_result[0]\n",
    "    task, model_name, prompt_mode, split, id = dict_result[\"custom_id\"].split(\"|\")\n",
    "    model_name = model_name.replace(\"-batch\", \"\")\n",
    "    for dict_result in list_dict_result:\n",
    "        if model_name not in dict_model_token:\n",
    "            dict_model_token[model_name] = {\"token_input\": 0, \"token_output\": 0}\n",
    "        token_input = dict_result[\"response\"][\"body\"][\"usage\"][\"prompt_tokens\"]\n",
    "        token_output = dict_result[\"response\"][\"body\"][\"usage\"][\"completion_tokens\"]\n",
    "        dict_model_token[model_name][\"token_input\"] += token_input\n",
    "        dict_model_token[model_name][\"token_output\"] += token_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-35-turbo, Cost: $128.19, with Input token-393.04 and Output token-39.91\n",
      "Model: gpt-4o, Cost: $454.33, with Input token-187.26 and Output token-44.05\n"
     ]
    }
   ],
   "source": [
    "for model, dict_token in dict_model_token.items():\n",
    "    cost = cost_calculation_token(dict_token[\"token_input\"], dict_token[\"token_output\"], model, flag_batch=True)\n",
    "    token_input_m, token_output_m = dict_token[\"token_input\"]/1e6, dict_token[\"token_output\"]/1e6\n",
    "    print(f\"Model: {model}, Cost: ${cost:.2f}, with Input token-{token_input_m:.2f} and Output token-{token_output_m:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_task_path = {\n",
    "    \"6.Brateca.mortality\": \"dataset_raw/6.Brateca.mortality.SFT.json\",\n",
    "    \"6.Brateca.hospitalization\": \"dataset_raw/6.Brateca.hospitalization.SFT.json\",\n",
    "    \"99.CARDIO:DE\": \"dataset_raw/99.CARDIO:DE.SFT.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_task(dict_task_path, model_name, prompt_mode, split=\"test\"):\n",
    "    for task_name, path_file_task in dict_task_path.items():\n",
    "        list_dict_data_batch = create_azure_batch_data(\n",
    "            task_name=task_name,\n",
    "            model_name=model_name,\n",
    "            prompt_mode=prompt_mode,\n",
    "            split=split,\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            max_token_input=100 * 1024,\n",
    "            max_token_output=2 * 1024,\n",
    "        )\n",
    "        print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/direct/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/direct/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/direct/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the clinical outcome for this patient is survival or death. \n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Survival: status\n",
      "The optional list for \"status\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/cot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the patient will require more than seven days of hospitalization.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Hospitalization > 7 days: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/cot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following clinical document related to the cardiovascular domain in German, extract the following types of entities from the clinical text:\n",
      "- \"ACTIVEING\": The primary ingredient in the medication responsible for its therapeutic effect.\n",
      "- \"DRUG\": The name of the medication, including brand or generic name.\n",
      "- \"DURATION\": The length of time the medication is to be taken.\n",
      "- \"FORM\": The physical form of the medication, such as tablet, capsule, or liquid.\n",
      "- \"FREQUENCY\": How often the medication should be taken within a specific time period.\n",
      "- \"STRENGTH\": The concentration or dosage of the active ingredient in the medication.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...; \n",
      "... \n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"ACTIVEING\", \"DRUG\", \"DURATION\", \"FORM\", \"FREQUENCY\", \"STRENGTH\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/cot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Test split: 3170 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3170 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.mortality.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input/gpt-35-turbo-batch/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Test split: 380 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14336\n",
      " - Max token output: 2048\n",
      " - Save 380 to azure/input/gpt-35-turbo-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 6733 samples\n",
      "Total 6733 samples\n",
      "Total 3550 samples\n",
      "Total 3183 samples\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "dict_list_file = {\n",
    "    # direct\n",
    "    \"direct\": [f\"azure/input/{model_name}/direct/6.Brateca.mortality.batch.jsonl\",\n",
    "    f\"azure/input/{model_name}/direct/6.Brateca.hospitalization.batch.jsonl\",\n",
    "    f\"azure/input/{model_name}/direct/99.CARDIO:DE.batch.jsonl\"],\n",
    "    # cot\n",
    "    \"cot\": [f\"azure/input/{model_name}/cot/6.Brateca.mortality.batch.jsonl\",\n",
    "    f\"azure/input/{model_name}/cot/6.Brateca.hospitalization.batch.jsonl\",\n",
    "    f\"azure/input/{model_name}/cot/99.CARDIO:DE.batch.jsonl\"],\n",
    "    # few-shot\n",
    "    \"direct-5-shot.0\": [f\"azure/input/{model_name}/direct-5-shot/6.Brateca.mortality.batch.jsonl\",\n",
    "    f\"azure/input/{model_name}/direct-5-shot/99.CARDIO:DE.batch.jsonl\"],\n",
    "    \"direct-5-shot.1\":[f\"azure/input/{model_name}/direct-5-shot/6.Brateca.hospitalization.batch.jsonl\",]\n",
    "}\n",
    "# merge the files\n",
    "for prompt_mode, list_file in dict_list_file.items():\n",
    "    list_dict_data = []\n",
    "    for file in list_file:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            list_dict_data += [json.loads(line) for line in f.readlines()]\n",
    "    print(f\"Total {len(list_dict_data)} samples\")\n",
    "    # save the merged file\n",
    "    path_file_save = f\"azure/input_supp/{model_name}/{model_name}.{prompt_mode}.supp.jsonl\"\n",
    "    os.makedirs(os.path.dirname(path_file_save), exist_ok=True)\n",
    "    with open(path_file_save, \"w\", encoding=\"utf-8\") as f:\n",
    "        for dict_data in list_dict_data:\n",
    "            f.write(json.dumps(dict_data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_azure_result = \"azure/output_supp\"\n",
    "path_dir_save = \"result_supp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3169\n",
      " - Missing: 29355\n",
      " - Matched: 3169\n",
      " - Lost 1 samples.\n",
      " - Saved: result_supp/6.Brateca.mortality/gpt-35-turbo/6.Brateca.mortality-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_supp/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_supp/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_supp/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3169\n",
      " - Missing: 29355\n",
      " - Matched: 3169\n",
      " - Lost 1 samples.\n",
      " - Saved: result_supp/6.Brateca.mortality/gpt-35-turbo/6.Brateca.mortality-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_supp/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.mortality\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3170\n",
      " - Num of batch: 3170\n",
      " - Num of result: 3169\n",
      " - Missing: 29355\n",
      " - Matched: 3169\n",
      " - Lost 1 samples.\n",
      " - Saved: result_supp/6.Brateca.mortality/gpt-35-turbo/6.Brateca.mortality-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result_supp/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 380\n",
      " - Num of batch: 380\n",
      " - Num of result: 380\n",
      " - Matched: 380\n",
      " - All matched.\n",
      " - Saved: result_supp/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-direct-greedy-42.result.json\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "process_azure_result_to_task_result(path_dir_azure_result, path_dir_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp-again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_task_path = {\n",
    "    \"6.Brateca.hospitalization\": \"dataset_raw/6.Brateca.hospitalization.SFT.json\",\n",
    "    \"17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\": \"dataset_raw/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM.SFT.json\",\n",
    "    \"17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\": \"dataset_raw/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS.SFT.json\",\n",
    "    \"31.Ex4CDS\": \"dataset_raw/31.Ex4CDS.SFT.json\",\n",
    "    \"91-2.CAS.evidence\": \"dataset_raw/91-2.CAS.evidence.SFT.json\",\n",
    "    \"90-8.n2c2 2014 - Heart Disease Challenge - Medication\": \"dataset_raw/90-8.n2c2 2014 - Heart Disease Challenge - Medication.SFT.json\",\n",
    "    # only few-shot\n",
    "    # \"22.CLIP\": \"dataset_raw/22.CLIP.SFT.json\",\n",
    "    # \"28.MIE\": \"dataset_raw/28.MIE.SFT.json\",\n",
    "    # \"91-1.CAS.label\": \"dataset_raw/91-1.CAS.label.SFT.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_task(dict_task_path, model_name, prompt_mode, split=\"test\"):\n",
    "    for task_name, path_file_task in dict_task_path.items():\n",
    "        list_dict_data_batch = create_azure_batch_data(\n",
    "            task_name=task_name,\n",
    "            model_name=model_name,\n",
    "            prompt_mode=prompt_mode,\n",
    "            split=split,\n",
    "            path_dir_raw=\"dataset_raw\",\n",
    "            path_dir_batch=\"azure/input_supp_again\",\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            max_token_input=100 * 1024,\n",
    "            max_token_output=2 * 1024,\n",
    "        )\n",
    "        print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input_supp_again/gpt-35-turbo-batch/direct/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Test split: 250 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 250 to azure/input_supp_again/gpt-35-turbo-batch/direct/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM.batch.jsonl\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Test split: 224 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 224 to azure/input_supp_again/gpt-35-turbo-batch/direct/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 411 to azure/input_supp_again/gpt-35-turbo-batch/direct/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 696 to azure/input_supp_again/gpt-35-turbo-batch/direct/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Test split: 451 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 451 to azure/input_supp_again/gpt-35-turbo-batch/direct/90-8.n2c2 2014 - Heart Disease Challenge - Medication.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the patient will require more than seven days of hospitalization.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Hospitalization > 7 days: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input_supp_again/gpt-35-turbo-batch/cot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Test split: 250 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Spanish, extract the clinical diagnosis from the clinical records and convert each of them into ICD-10-CM codes.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "diagnosis: ..., ICD-10-CM: ...;\n",
      "...\n",
      "diagnosis: ..., ICD-10-CM: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 250 to azure/input_supp_again/gpt-35-turbo-batch/cot/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM.batch.jsonl\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Test split: 224 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Spanish, extract clinical procedures from the clinical records and convert each of them into ICD-10-PCS codes.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "procedure: ..., ICD-10-PCS: ...;\n",
      "...\n",
      "procedure: ..., ICD-10-PCS: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 224 to azure/input_supp_again/gpt-35-turbo-batch/cot/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following physician's explanation, extract the medical entities with their corresponding types. Specifically, this explanation was generated by a physician to predict negative outcomes in kidney disease patients within the next 90 days, including rejection, death-censored graft loss, and infection. The medical entities include the following types:\n",
      "- \"Condition\": A pathological medical condition of a patient, can describe for instance a symptom or a disease.\n",
      "- \"DiagLab\": Particular diagnostic procedures which have been carried out.\n",
      "- \"LabValues\": Mentions of lab values.\n",
      "- \"HealthState\": A positive condition of the patient.\n",
      "- \"Measure\": Mostly numeric values, often in the context of medications or lab values, but can also be a description if a value changes, e.g., raises.\n",
      "- \"Medication\": A medication.\n",
      "- \"Process\": Describes a particular process, such as blood pressure or heart rate, often related to vital parameters.\n",
      "- \"TimeInfo\": Describes temporal information, such as 2 weeks ago or January.\n",
      "- \"Other\": Additional relevant information which influences the health condition and the risk.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Condition\", \"DiagLab\", \"LabValues\", \"HealthState\", \"Measure\", \"Medication\", \"Process\", \"TimeInfo\", \"Other\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 411 to azure/input_supp_again/gpt-35-turbo-batch/cot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the evidence of the following medical information from the original text:\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus).\n",
      "- \"origine\": l'origine (motif de la consultation ou de l'hospitalisation) pour le dernier événement clinique ayant motivé la consultation. Cette catégorie intègre généralement les pathologies, signes et symptômes (par exemple, \"une tuméfaction lombaire droite, fébrile avec frissons\" ou \"un contexte d'asthénie et d'altération de l'état général\"), plus rarement les circonstances d'un accident (\"une chute de 12 mètres, par défénestration, avec réception ventrale\", \"un AVP moto\" ou \"pense avoir été violée\"). Le suivi clinique se trouve dans la continuité d'événements précédents. Il ne constitue pas un motif de consultation.\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "evidence of genre: ...;\n",
      "evidence of origine: ...;\n",
      "evidence of issue: ...;\n",
      "The optional evidence of \"genre\" is the word or shot phrase that indicates the genre of the person; The optional evidence of \"origine\" and \"issue\" is the sentence or shot paragraph that indicates the origine and issue of the person, respectively. If the evidence is not mentioned, return \"None\".\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 696 to azure/input_supp_again/gpt-35-turbo-batch/cot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Test split: 451 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical document of a patient, extract the indicators that are related to Medication. Then, for each extracted indicator, classify it into one of the following categories:\n",
      "- \"before DCT\": This attribute value is used to indicate that the indicator can only be stated to be present prior to the date of the record.\n",
      "- \"during DCT\": This attribute value is used to indicate that a risk factor indicator occurred the day of the date on the record.\n",
      "- \"after DCT\": This attribute value is used to indicate that the risk factor indicator applies to the days after the date of the record.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "indicator: ..., category: ...;\n",
      "...\n",
      "indicator: ..., category: ...;\n",
      "The optional list for \"category\" is [\"before DCT\", \"during DCT\", \"after DCT\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 451 to azure/input_supp_again/gpt-35-turbo-batch/cot/90-8.n2c2 2014 - Heart Disease Challenge - Medication.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input_supp_again/gpt-4o-batch/direct/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Test split: 250 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 250 to azure/input_supp_again/gpt-4o-batch/direct/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM.batch.jsonl\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Test split: 224 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 224 to azure/input_supp_again/gpt-4o-batch/direct/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 411 to azure/input_supp_again/gpt-4o-batch/direct/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 696 to azure/input_supp_again/gpt-4o-batch/direct/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Test split: 451 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 451 to azure/input_supp_again/gpt-4o-batch/direct/90-8.n2c2 2014 - Heart Disease Challenge - Medication.batch.jsonl\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Test split: 3183 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given a patient's basic information and clinical notes in Portuguese, predict whether the patient will require more than seven days of hospitalization.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "Hospitalization > 7 days: label\n",
      "The optional list for \"label\" is [\"Yes\", \"No\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 3183 to azure/input_supp_again/gpt-4o-batch/cot/6.Brateca.hospitalization.batch.jsonl\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Test split: 250 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Spanish, extract the clinical diagnosis from the clinical records and convert each of them into ICD-10-CM codes.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "diagnosis: ..., ICD-10-CM: ...;\n",
      "...\n",
      "diagnosis: ..., ICD-10-CM: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 250 to azure/input_supp_again/gpt-4o-batch/cot/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM.batch.jsonl\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Test split: 224 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical text of a patient in Spanish, extract clinical procedures from the clinical records and convert each of them into ICD-10-PCS codes.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "procedure: ..., ICD-10-PCS: ...;\n",
      "...\n",
      "procedure: ..., ICD-10-PCS: ...;\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 224 to azure/input_supp_again/gpt-4o-batch/cot/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS.batch.jsonl\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Test split: 411 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the following physician's explanation, extract the medical entities with their corresponding types. Specifically, this explanation was generated by a physician to predict negative outcomes in kidney disease patients within the next 90 days, including rejection, death-censored graft loss, and infection. The medical entities include the following types:\n",
      "- \"Condition\": A pathological medical condition of a patient, can describe for instance a symptom or a disease.\n",
      "- \"DiagLab\": Particular diagnostic procedures which have been carried out.\n",
      "- \"LabValues\": Mentions of lab values.\n",
      "- \"HealthState\": A positive condition of the patient.\n",
      "- \"Measure\": Mostly numeric values, often in the context of medications or lab values, but can also be a description if a value changes, e.g., raises.\n",
      "- \"Medication\": A medication.\n",
      "- \"Process\": Describes a particular process, such as blood pressure or heart rate, often related to vital parameters.\n",
      "- \"TimeInfo\": Describes temporal information, such as 2 weeks ago or January.\n",
      "- \"Other\": Additional relevant information which influences the health condition and the risk.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "entity: ..., type: ...;\n",
      "...\n",
      "entity: ..., type: ...;\n",
      "The optional list for \"type\" is [\"Condition\", \"DiagLab\", \"LabValues\", \"HealthState\", \"Measure\", \"Medication\", \"Process\", \"TimeInfo\", \"Other\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 411 to azure/input_supp_again/gpt-4o-batch/cot/31.Ex4CDS.batch.jsonl\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Test split: 696 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical care report in French, extract the evidence of the following medical information from the original text:\n",
      "- \"genre\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus).\n",
      "- \"origine\": l'origine (motif de la consultation ou de l'hospitalisation) pour le dernier événement clinique ayant motivé la consultation. Cette catégorie intègre généralement les pathologies, signes et symptômes (par exemple, \"une tuméfaction lombaire droite, fébrile avec frissons\" ou \"un contexte d'asthénie et d'altération de l'état général\"), plus rarement les circonstances d'un accident (\"une chute de 12 mètres, par défénestration, avec réception ventrale\", \"un AVP moto\" ou \"pense avoir été violée\"). Le suivi clinique se trouve dans la continuité d'événements précédents. Il ne constitue pas un motif de consultation.\n",
      "- \"issue\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit).\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "evidence of genre: ...;\n",
      "evidence of origine: ...;\n",
      "evidence of issue: ...;\n",
      "The optional evidence of \"genre\" is the word or shot phrase that indicates the genre of the person; The optional evidence of \"origine\" and \"issue\" is the sentence or shot paragraph that indicates the origine and issue of the person, respectively. If the evidence is not mentioned, return \"None\".\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 696 to azure/input_supp_again/gpt-4o-batch/cot/91-2.CAS.evidence.batch.jsonl\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Test split: 451 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: cot\n",
      " - Transform the instruction to the CoT format\n",
      " - Instruction: \n",
      "Given the clinical document of a patient, extract the indicators that are related to Medication. Then, for each extracted indicator, classify it into one of the following categories:\n",
      "- \"before DCT\": This attribute value is used to indicate that the indicator can only be stated to be present prior to the date of the record.\n",
      "- \"during DCT\": This attribute value is used to indicate that a risk factor indicator occurred the day of the date on the record.\n",
      "- \"after DCT\": This attribute value is used to indicate that the risk factor indicator applies to the days after the date of the record.\n",
      "Solve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\n",
      "Analysis:\n",
      "...\n",
      "Result:\n",
      "indicator: ..., category: ...;\n",
      "...\n",
      "indicator: ..., category: ...;\n",
      "The optional list for \"category\" is [\"before DCT\", \"during DCT\", \"after DCT\"].\n",
      " - No example\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 451 to azure/input_supp_again/gpt-4o-batch/cot/90-8.n2c2 2014 - Heart Disease Challenge - Medication.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input_supp_again/merged/gpt-35-turbo-batch/direct/gpt-35-turbo-batch.direct.chunk_0.jsonl with 5215 lines and size 39.63 MB\n",
      "Created: azure/input_supp_again/merged/gpt-35-turbo-batch/cot/gpt-35-turbo-batch.cot.chunk_0.jsonl with 5215 lines and size 40.00 MB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "prompt_mode = \"direct\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)\n",
    "prompt_mode = \"cot\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)\n",
    "# prompt_mode = \"direct-5-shot\"\n",
    "# merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input_supp_again/merged/gpt-4o-batch/direct/gpt-4o-batch.direct.chunk_0.jsonl with 5215 lines and size 39.71 MB\n",
      "Created: azure/input_supp_again/merged/gpt-4o-batch/cot/gpt-4o-batch.cot.chunk_0.jsonl with 5215 lines and size 40.07 MB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "prompt_mode = \"direct\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)\n",
    "prompt_mode = \"cot\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)\n",
    "# prompt_mode = \"direct-5-shot\"\n",
    "# merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=\"azure/input_supp_again\", path_dir_merged=\"azure/input_supp_again/merged\", max_lines=50000, max_size_mb=190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_azure_result = \"azure/output\"\n",
    "path_dir_task_save = \"result\"\n",
    "path_dir_raw = \"dataset_raw\"\n",
    "path_dir_batch = \"azure/input_supp_again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-35-turbo/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-35-turbo/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-35-turbo/90-8.n2c2 2014 - Heart Disease Challenge - Medication-cot-greedy-42.result.json\n",
      "========================================\n",
      "Accident at 4735\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-35-turbo/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-35-turbo/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-35-turbo/90-8.n2c2 2014 - Heart Disease Challenge - Medication-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1067\n",
      " - Num of batch: 1067\n",
      " - Num of result: 1067\n",
      " - Matched: 1067\n",
      " - All matched.\n",
      " - Saved: result/22.CLIP/gpt-35-turbo/22.CLIP-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result/28.MIE/gpt-35-turbo/28.MIE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-1.CAS.label/gpt-35-turbo/91-1.CAS.label-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-4o/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-4o/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-4o/31.Ex4CDS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-4o/90-8.n2c2 2014 - Heart Disease Challenge - Medication-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-4o/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-4o/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-4o/31.Ex4CDS-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: cot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-4o/90-8.n2c2 2014 - Heart Disease Challenge - Medication-cot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-35-turbo/6.Brateca.hospitalization-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-35-turbo/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-35-turbo/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-35-turbo/31.Ex4CDS-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-35-turbo/91-2.CAS.evidence-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-35-turbo/90-8.n2c2 2014 - Heart Disease Challenge - Medication-direct-greedy-42.result.json\n",
      "========================================\n",
      "Task: 6.Brateca.hospitalization\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 3183\n",
      " - Num of batch: 3183\n",
      " - Num of result: 3183\n",
      " - Matched: 3183\n",
      " - All matched.\n",
      " - Saved: result/6.Brateca.hospitalization/gpt-4o/6.Brateca.hospitalization-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 250\n",
      " - Num of batch: 250\n",
      " - Num of result: 250\n",
      " - Matched: 250\n",
      " - All matched.\n",
      " - Saved: result/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM/gpt-4o/17-1.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-CM-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 224\n",
      " - Num of batch: 224\n",
      " - Num of result: 224\n",
      " - Matched: 224\n",
      " - All matched.\n",
      " - Saved: result/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS/gpt-4o/17-2.CLEF_eHealth_2020_CodiEsp_corpus-ICD-10-PCS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 31.Ex4CDS\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 411\n",
      " - Num of batch: 411\n",
      " - Num of result: 411\n",
      " - Matched: 411\n",
      " - All matched.\n",
      " - Saved: result/31.Ex4CDS/gpt-4o/31.Ex4CDS-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-2.CAS.evidence\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-2.CAS.evidence/gpt-4o/91-2.CAS.evidence-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 90-8.n2c2 2014 - Heart Disease Challenge - Medication\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 451\n",
      " - Num of batch: 451\n",
      " - Num of result: 451\n",
      " - Matched: 451\n",
      " - All matched.\n",
      " - Saved: result/90-8.n2c2 2014 - Heart Disease Challenge - Medication/gpt-4o/90-8.n2c2 2014 - Heart Disease Challenge - Medication-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 22.CLIP\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 1067\n",
      " - Num of batch: 1067\n",
      " - Num of result: 1067\n",
      " - Matched: 1067\n",
      " - All matched.\n",
      " - Saved: result/22.CLIP/gpt-4o/22.CLIP-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 28.MIE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 2235\n",
      " - Num of batch: 2235\n",
      " - Num of result: 2235\n",
      " - Matched: 2235\n",
      " - All matched.\n",
      " - Saved: result/28.MIE/gpt-4o/28.MIE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 91-1.CAS.label\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 696\n",
      " - Num of batch: 696\n",
      " - Num of result: 696\n",
      " - Matched: 696\n",
      " - All matched.\n",
      " - Saved: result/91-1.CAS.label/gpt-4o/91-1.CAS.label-direct-5-shot-greedy-42.result.json\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "process_azure_result_to_task_result(\n",
    "    path_dir_azure_result=path_dir_azure_result,\n",
    "    path_dir_task_save=path_dir_task_save,\n",
    "    path_dir_raw=path_dir_raw,\n",
    "    path_dir_batch=path_dir_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supp-again-again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_batch=\"azure/input_supp_again_again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_task_path = {\n",
    "    # \"8.CARES.icd10_block\": \"dataset_raw/8.CARES.icd10_block.SFT.json\",\n",
    "    # \"8.CARES.icd10_sub_block\": \"dataset_raw/8.CARES.icd10_sub_block.SFT.json\",\n",
    "    # \"29.EHRQA.primary_department\": \"dataset_raw/29.EHRQA.primary_department.SFT.json\",\n",
    "    # \"29.EHRQA.sub_department\": \"dataset_raw/29.EHRQA.sub_department.SFT.json\",\n",
    "    # \"29.EHRQA.qa\": \"dataset_raw/29.EHRQA.qa.SFT.json\",\n",
    "    # \"33.GOUT-CC.consensus\": \"dataset_raw/33.GOUT-CC.consensus.SFT.json\",\n",
    "    # \"105.MIMIC-IV CDM\": \"dataset_raw/105.MIMIC-IV CDM.SFT.json\",\n",
    "    # \"106.MIMIC-III Outcome.LoS\": \"dataset_raw/106.MIMIC-III Outcome.LoS.SFT.json\",\n",
    "    # \"106.MIMIC-III Outcome.Mortality\": \"dataset_raw/106.MIMIC-III Outcome.Mortality.SFT.json\",\n",
    "    # \"108.MIMIC-IV DiReCT.PDD\": \"dataset_raw/108.MIMIC-IV DiReCT.PDD.SFT.json\",\n",
    "    # \"108.MIMIC-IV DiReCT.Dis\": \"dataset_raw/108.MIMIC-IV DiReCT.Dis.SFT.json\",\n",
    "    # \"107.MIMIC-IV BHC\": \"dataset_raw/107.MIMIC-IV BHC.SFT.json\",\n",
    "    # \"100.GraSSCo_PHI\": \"dataset_raw/100.GraSSCo_PHI.SFT.json\",\n",
    "    # only few-shot\n",
    "    \"99.CARDIO:DE\": \"dataset_raw/99.CARDIO:DE.SFT.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_task(dict_task_path, model_name, prompt_mode, split=\"test\"):\n",
    "    for task_name, path_file_task in dict_task_path.items():\n",
    "        list_dict_data_batch = create_azure_batch_data(\n",
    "            task_name=task_name,\n",
    "            model_name=model_name,\n",
    "            prompt_mode=prompt_mode,\n",
    "            split=split,\n",
    "            path_dir_raw=\"dataset_raw\",\n",
    "            path_dir_batch=path_dir_batch,\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            max_token_input=100 * 1024,\n",
    "            max_token_output=2 * 1024,\n",
    "        )\n",
    "        print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 99.CARDIO:DE\n",
      " - Test split: 369 samples\n",
      " - Model: gpt-35-turbo-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-35-turbo\n",
      " - Max token input: 14331\n",
      " - Max token output: 2048\n",
      " - Save 369 to azure/input_supp_again_again/gpt-35-turbo-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 99.CARDIO:DE\n",
      " - Test split: 369 samples\n",
      " - Model: gpt-4o-batch\n",
      " - Prompt: direct-5-shot\n",
      " - Prepare 5 examples\n",
      " - Loading tokenizer of gpt-4o\n",
      " - Max token input: 102400\n",
      " - Max token output: 2048\n",
      " - Save 369 to azure/input_supp_again_again/gpt-4o-batch/direct-5-shot/99.CARDIO:DE.batch.jsonl\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"direct\")\n",
    "# proceed_task(dict_task_path, model_name, prompt_mode=\"cot\")\n",
    "proceed_task(dict_task_path, model_name, prompt_mode=\"direct-5-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input_supp_again_again/merged/gpt-35-turbo-batch.direct.chunk_0.jsonl with 22032 lines and size 41.85 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-35-turbo-batch.cot.chunk_0.jsonl with 22032 lines and size 43.41 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-35-turbo-batch.direct-5-shot.chunk_0.jsonl with 22032 lines and size 178.06 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-35-turbo-batch.direct-5-shot.chunk_1.jsonl with 1819 lines and size 25.76 MB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-35-turbo-batch\"\n",
    "# prompt_mode = \"direct\"\n",
    "# merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)\n",
    "# prompt_mode = \"cot\"\n",
    "# merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)\n",
    "prompt_mode = \"direct-5-shot\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: azure/input_supp_again_again/merged/gpt-4o-batch.direct.chunk_0.jsonl with 22032 lines and size 41.62 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-4o-batch.cot.chunk_0.jsonl with 22032 lines and size 43.17 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-4o-batch.direct-5-shot.chunk_0.jsonl with 22032 lines and size 182.01 MB\n",
      "Created: azure/input_supp_again_again/merged/gpt-4o-batch.direct-5-shot.chunk_1.jsonl with 1819 lines and size 25.74 MB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-batch\"\n",
    "prompt_mode = \"direct\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)\n",
    "prompt_mode = \"cot\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)\n",
    "prompt_mode = \"direct-5-shot\"\n",
    "merge_azure_batch_data(model_name, prompt_mode, path_dir_raw=path_dir_batch, path_dir_merged=f\"{path_dir_batch}/merged\", max_lines=50000, max_size_mb=190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_azure_result = \"azure/output_99\"\n",
    "path_dir_task_save = \"result\"\n",
    "# \"result_supp_again_again\"\n",
    "path_dir_raw=\"dataset_raw\"\n",
    "path_dir_batch=\"azure/input_supp_again_again/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-4o-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 369\n",
      " - Num of batch: 369\n",
      " - Num of result: 369\n",
      " - Matched: 369\n",
      " - All matched.\n",
      " - Saved: result/99.CARDIO:DE/gpt-4o/99.CARDIO:DE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n",
      "Task: 99.CARDIO:DE\n",
      " - Model Name: gpt-35-turbo-batch\n",
      " - Prompt Mode: direct-5-shot\n",
      " - Split: test\n",
      "----------------------------------------\n",
      " - Num of data: 369\n",
      " - Num of batch: 369\n",
      " - Num of result: 369\n",
      " - Matched: 369\n",
      " - All matched.\n",
      " - Saved: result/99.CARDIO:DE/gpt-35-turbo/99.CARDIO:DE-direct-5-shot-greedy-42.result.json\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "process_azure_result_to_task_result(\n",
    "    path_dir_azure_result=path_dir_azure_result,\n",
    "    path_dir_task_save=path_dir_task_save,\n",
    "    path_dir_raw=path_dir_raw,\n",
    "    path_dir_batch=path_dir_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
